schema {
  query: query_root
  mutation: mutation_root
  subscription: subscription_root
}

"""whether this query should be cached (Hasura Cloud only)"""
directive @cached(
  """refresh the cache entry"""
  refresh: Boolean! = false

  """measured in seconds"""
  ttl: Int! = 60
) on QUERY

scalar BigInt

"""
Boolean expression to compare columns of type "Boolean". All fields are combined with logical 'AND'.
"""
input Boolean_comparison_exp {
  _eq: Boolean
  _gt: Boolean
  _gte: Boolean
  _in: [Boolean!]
  _is_null: Boolean
  _lt: Boolean
  _lte: Boolean
  _neq: Boolean
  _nin: [Boolean!]
}

input DuplicateInput {
  allowedDownloads: Int
  expiryDays: Int
  filename: String
  id: String!
  originalPassword: Boolean
  password: String
}

type File {
  contentType: String
  downloadCount: BigInt
  downloadsRemaining: BigInt
  expireAt: BigInt
  expireAtString: String
  hotlinkId: String
  id: String
  isEncrypted: Boolean
  isPasswordProtected: Boolean
  isSavedOnLocalStorage: Boolean
  name: String
  requiresClientSideDecryption: Boolean
  size: String
  sizeBytes: BigInt
  unlimitedDownloads: Boolean
  unlimitedTime: Boolean
}

"""
Boolean expression to compare columns of type "Int". All fields are combined with logical 'AND'.
"""
input Int_comparison_exp {
  _eq: Int
  _gt: Int
  _gte: Int
  _in: [Int!]
  _is_null: Boolean
  _lt: Int
  _lte: Int
  _neq: Int
  _nin: [Int!]
}

type NewApiKey {
  id: String
  result: String
}

enum Permission {
  PERM_API_MOD
  PERM_DELETE
  PERM_EDIT
  PERM_UPLOAD
  PERM_VIEW
}

enum PermissionModifier {
  GRANT
  REVOKE
}

type S3UploadOutput {
  bucket: String
  key: String
  location: String
}

"""
Boolean expression to compare columns of type "String". All fields are combined with logical 'AND'.
"""
input String_array_comparison_exp {
  """is the array contained in the given array value"""
  _contained_in: [String!]

  """does the array contain the given value"""
  _contains: [String!]
  _eq: [String!]
  _gt: [String!]
  _gte: [String!]
  _in: [[String!]!]
  _is_null: Boolean
  _lt: [String!]
  _lte: [String!]
  _neq: [String!]
  _nin: [[String!]!]
}

"""
Boolean expression to compare columns of type "String". All fields are combined with logical 'AND'.
"""
input String_comparison_exp {
  _eq: String
  _gt: String
  _gte: String

  """does the column match the given case-insensitive pattern"""
  _ilike: String
  _in: [String!]

  """
  does the column match the given POSIX regular expression, case insensitive
  """
  _iregex: String
  _is_null: Boolean

  """does the column match the given pattern"""
  _like: String
  _lt: String
  _lte: String
  _neq: String

  """does the column NOT match the given case-insensitive pattern"""
  _nilike: String
  _nin: [String!]

  """
  does the column NOT match the given POSIX regular expression, case insensitive
  """
  _niregex: String

  """does the column NOT match the given pattern"""
  _nlike: String

  """
  does the column NOT match the given POSIX regular expression, case sensitive
  """
  _nregex: String

  """does the column NOT match the given SQL regular expression"""
  _nsimilar: String

  """
  does the column match the given POSIX regular expression, case sensitive
  """
  _regex: String

  """does the column match the given SQL regular expression"""
  _similar: String
}

scalar Upload

"""广告表"""
type ads {
  created_at: timestamptz!
  custom_order: Int
  id: uuid!
  image: String!
  link: String!
  name: String

  """广告类型，0：轮播图"""
  type: Int!
  updated_at: timestamptz!
}

"""
aggregated selection of "ads"
"""
type ads_aggregate {
  aggregate: ads_aggregate_fields
  nodes: [ads!]!
}

"""
aggregate fields of "ads"
"""
type ads_aggregate_fields {
  avg: ads_avg_fields
  count(columns: [ads_select_column!], distinct: Boolean): Int!
  max: ads_max_fields
  min: ads_min_fields
  stddev: ads_stddev_fields
  stddev_pop: ads_stddev_pop_fields
  stddev_samp: ads_stddev_samp_fields
  sum: ads_sum_fields
  var_pop: ads_var_pop_fields
  var_samp: ads_var_samp_fields
  variance: ads_variance_fields
}

"""aggregate avg on columns"""
type ads_avg_fields {
  custom_order: Float

  """广告类型，0：轮播图"""
  type: Float
}

"""
Boolean expression to filter rows from the table "ads". All fields are combined with a logical 'AND'.
"""
input ads_bool_exp {
  _and: [ads_bool_exp!]
  _not: ads_bool_exp
  _or: [ads_bool_exp!]
  created_at: timestamptz_comparison_exp
  custom_order: Int_comparison_exp
  id: uuid_comparison_exp
  image: String_comparison_exp
  link: String_comparison_exp
  name: String_comparison_exp
  type: Int_comparison_exp
  updated_at: timestamptz_comparison_exp
}

"""
unique or primary key constraints on table "ads"
"""
enum ads_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  ads_pkey
}

"""
input type for incrementing numeric columns in table "ads"
"""
input ads_inc_input {
  custom_order: Int

  """广告类型，0：轮播图"""
  type: Int
}

"""
input type for inserting data into table "ads"
"""
input ads_insert_input {
  created_at: timestamptz
  custom_order: Int
  id: uuid
  image: String
  link: String
  name: String

  """广告类型，0：轮播图"""
  type: Int
  updated_at: timestamptz
}

"""aggregate max on columns"""
type ads_max_fields {
  created_at: timestamptz
  custom_order: Int
  id: uuid
  image: String
  link: String
  name: String

  """广告类型，0：轮播图"""
  type: Int
  updated_at: timestamptz
}

"""aggregate min on columns"""
type ads_min_fields {
  created_at: timestamptz
  custom_order: Int
  id: uuid
  image: String
  link: String
  name: String

  """广告类型，0：轮播图"""
  type: Int
  updated_at: timestamptz
}

"""
response of any mutation on the table "ads"
"""
type ads_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [ads!]!
}

"""
on_conflict condition type for table "ads"
"""
input ads_on_conflict {
  constraint: ads_constraint!
  update_columns: [ads_update_column!]! = []
  where: ads_bool_exp
}

"""Ordering options when selecting data from "ads"."""
input ads_order_by {
  created_at: order_by
  custom_order: order_by
  id: order_by
  image: order_by
  link: order_by
  name: order_by
  type: order_by
  updated_at: order_by
}

"""primary key columns input for table: ads"""
input ads_pk_columns_input {
  id: uuid!
}

"""
select columns of table "ads"
"""
enum ads_select_column {
  """column name"""
  created_at

  """column name"""
  custom_order

  """column name"""
  id

  """column name"""
  image

  """column name"""
  link

  """column name"""
  name

  """column name"""
  type

  """column name"""
  updated_at
}

"""
input type for updating data in table "ads"
"""
input ads_set_input {
  created_at: timestamptz
  custom_order: Int
  id: uuid
  image: String
  link: String
  name: String

  """广告类型，0：轮播图"""
  type: Int
  updated_at: timestamptz
}

"""aggregate stddev on columns"""
type ads_stddev_fields {
  custom_order: Float

  """广告类型，0：轮播图"""
  type: Float
}

"""aggregate stddev_pop on columns"""
type ads_stddev_pop_fields {
  custom_order: Float

  """广告类型，0：轮播图"""
  type: Float
}

"""aggregate stddev_samp on columns"""
type ads_stddev_samp_fields {
  custom_order: Float

  """广告类型，0：轮播图"""
  type: Float
}

"""
Streaming cursor of the table "ads"
"""
input ads_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: ads_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input ads_stream_cursor_value_input {
  created_at: timestamptz
  custom_order: Int
  id: uuid
  image: String
  link: String
  name: String

  """广告类型，0：轮播图"""
  type: Int
  updated_at: timestamptz
}

"""aggregate sum on columns"""
type ads_sum_fields {
  custom_order: Int

  """广告类型，0：轮播图"""
  type: Int
}

"""
update columns of table "ads"
"""
enum ads_update_column {
  """column name"""
  created_at

  """column name"""
  custom_order

  """column name"""
  id

  """column name"""
  image

  """column name"""
  link

  """column name"""
  name

  """column name"""
  type

  """column name"""
  updated_at
}

input ads_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: ads_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: ads_set_input

  """filter the rows which have to be updated"""
  where: ads_bool_exp!
}

"""aggregate var_pop on columns"""
type ads_var_pop_fields {
  custom_order: Float

  """广告类型，0：轮播图"""
  type: Float
}

"""aggregate var_samp on columns"""
type ads_var_samp_fields {
  custom_order: Float

  """广告类型，0：轮播图"""
  type: Float
}

"""aggregate variance on columns"""
type ads_variance_fields {
  custom_order: Float

  """广告类型，0：轮播图"""
  type: Float
}

"""
columns and relationships of "application_sign_in_experiences"
"""
type application_sign_in_experiences {
  application_id: String!
  branding(
    """JSON select path"""
    path: String
  ): jsonb!
  display_name: String
  privacy_policy_url: String
  tenant_id: String!
  terms_of_use_url: String
}

"""
aggregated selection of "application_sign_in_experiences"
"""
type application_sign_in_experiences_aggregate {
  aggregate: application_sign_in_experiences_aggregate_fields
  nodes: [application_sign_in_experiences!]!
}

"""
aggregate fields of "application_sign_in_experiences"
"""
type application_sign_in_experiences_aggregate_fields {
  count(columns: [application_sign_in_experiences_select_column!], distinct: Boolean): Int!
  max: application_sign_in_experiences_max_fields
  min: application_sign_in_experiences_min_fields
}

"""append existing jsonb value of filtered columns with new jsonb value"""
input application_sign_in_experiences_append_input {
  branding: jsonb
}

"""
Boolean expression to filter rows from the table "application_sign_in_experiences". All fields are combined with a logical 'AND'.
"""
input application_sign_in_experiences_bool_exp {
  _and: [application_sign_in_experiences_bool_exp!]
  _not: application_sign_in_experiences_bool_exp
  _or: [application_sign_in_experiences_bool_exp!]
  application_id: String_comparison_exp
  branding: jsonb_comparison_exp
  display_name: String_comparison_exp
  privacy_policy_url: String_comparison_exp
  tenant_id: String_comparison_exp
  terms_of_use_url: String_comparison_exp
}

"""
unique or primary key constraints on table "application_sign_in_experiences"
"""
enum application_sign_in_experiences_constraint {
  """
  unique or primary key constraint on columns "application_id", "tenant_id"
  """
  application_sign_in_experiences_pkey
}

"""
delete the field or element with specified path (for JSON arrays, negative integers count from the end)
"""
input application_sign_in_experiences_delete_at_path_input {
  branding: [String!]
}

"""
delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
"""
input application_sign_in_experiences_delete_elem_input {
  branding: Int
}

"""
delete key/value pair or string element. key/value pairs are matched based on their key value
"""
input application_sign_in_experiences_delete_key_input {
  branding: String
}

"""
input type for inserting data into table "application_sign_in_experiences"
"""
input application_sign_in_experiences_insert_input {
  application_id: String
  branding: jsonb
  display_name: String
  privacy_policy_url: String
  tenant_id: String
  terms_of_use_url: String
}

"""aggregate max on columns"""
type application_sign_in_experiences_max_fields {
  application_id: String
  display_name: String
  privacy_policy_url: String
  tenant_id: String
  terms_of_use_url: String
}

"""aggregate min on columns"""
type application_sign_in_experiences_min_fields {
  application_id: String
  display_name: String
  privacy_policy_url: String
  tenant_id: String
  terms_of_use_url: String
}

"""
response of any mutation on the table "application_sign_in_experiences"
"""
type application_sign_in_experiences_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [application_sign_in_experiences!]!
}

"""
on_conflict condition type for table "application_sign_in_experiences"
"""
input application_sign_in_experiences_on_conflict {
  constraint: application_sign_in_experiences_constraint!
  update_columns: [application_sign_in_experiences_update_column!]! = []
  where: application_sign_in_experiences_bool_exp
}

"""
Ordering options when selecting data from "application_sign_in_experiences".
"""
input application_sign_in_experiences_order_by {
  application_id: order_by
  branding: order_by
  display_name: order_by
  privacy_policy_url: order_by
  tenant_id: order_by
  terms_of_use_url: order_by
}

"""primary key columns input for table: application_sign_in_experiences"""
input application_sign_in_experiences_pk_columns_input {
  application_id: String!
  tenant_id: String!
}

"""prepend existing jsonb value of filtered columns with new jsonb value"""
input application_sign_in_experiences_prepend_input {
  branding: jsonb
}

"""
select columns of table "application_sign_in_experiences"
"""
enum application_sign_in_experiences_select_column {
  """column name"""
  application_id

  """column name"""
  branding

  """column name"""
  display_name

  """column name"""
  privacy_policy_url

  """column name"""
  tenant_id

  """column name"""
  terms_of_use_url
}

"""
input type for updating data in table "application_sign_in_experiences"
"""
input application_sign_in_experiences_set_input {
  application_id: String
  branding: jsonb
  display_name: String
  privacy_policy_url: String
  tenant_id: String
  terms_of_use_url: String
}

"""
Streaming cursor of the table "application_sign_in_experiences"
"""
input application_sign_in_experiences_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: application_sign_in_experiences_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input application_sign_in_experiences_stream_cursor_value_input {
  application_id: String
  branding: jsonb
  display_name: String
  privacy_policy_url: String
  tenant_id: String
  terms_of_use_url: String
}

"""
update columns of table "application_sign_in_experiences"
"""
enum application_sign_in_experiences_update_column {
  """column name"""
  application_id

  """column name"""
  branding

  """column name"""
  display_name

  """column name"""
  privacy_policy_url

  """column name"""
  tenant_id

  """column name"""
  terms_of_use_url
}

input application_sign_in_experiences_updates {
  """append existing jsonb value of filtered columns with new jsonb value"""
  _append: application_sign_in_experiences_append_input

  """
  delete the field or element with specified path (for JSON arrays, negative integers count from the end)
  """
  _delete_at_path: application_sign_in_experiences_delete_at_path_input

  """
  delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
  """
  _delete_elem: application_sign_in_experiences_delete_elem_input

  """
  delete key/value pair or string element. key/value pairs are matched based on their key value
  """
  _delete_key: application_sign_in_experiences_delete_key_input

  """prepend existing jsonb value of filtered columns with new jsonb value"""
  _prepend: application_sign_in_experiences_prepend_input

  """sets the columns of the filtered rows to the given values"""
  _set: application_sign_in_experiences_set_input

  """filter the rows which have to be updated"""
  where: application_sign_in_experiences_bool_exp!
}

scalar application_type

"""
Boolean expression to compare columns of type "application_type". All fields are combined with logical 'AND'.
"""
input application_type_comparison_exp {
  _eq: application_type
  _gt: application_type
  _gte: application_type
  _in: [application_type!]
  _is_null: Boolean
  _lt: application_type
  _lte: application_type
  _neq: application_type
  _nin: [application_type!]
}

"""
columns and relationships of "application_user_consent_organization_scopes"
"""
type application_user_consent_organization_scopes {
  application_id: String!
  organization_scope_id: String!
  tenant_id: String!
}

"""
aggregated selection of "application_user_consent_organization_scopes"
"""
type application_user_consent_organization_scopes_aggregate {
  aggregate: application_user_consent_organization_scopes_aggregate_fields
  nodes: [application_user_consent_organization_scopes!]!
}

"""
aggregate fields of "application_user_consent_organization_scopes"
"""
type application_user_consent_organization_scopes_aggregate_fields {
  count(columns: [application_user_consent_organization_scopes_select_column!], distinct: Boolean): Int!
  max: application_user_consent_organization_scopes_max_fields
  min: application_user_consent_organization_scopes_min_fields
}

"""
Boolean expression to filter rows from the table "application_user_consent_organization_scopes". All fields are combined with a logical 'AND'.
"""
input application_user_consent_organization_scopes_bool_exp {
  _and: [application_user_consent_organization_scopes_bool_exp!]
  _not: application_user_consent_organization_scopes_bool_exp
  _or: [application_user_consent_organization_scopes_bool_exp!]
  application_id: String_comparison_exp
  organization_scope_id: String_comparison_exp
  tenant_id: String_comparison_exp
}

"""
unique or primary key constraints on table "application_user_consent_organization_scopes"
"""
enum application_user_consent_organization_scopes_constraint {
  """
  unique or primary key constraint on columns "application_id", "organization_scope_id"
  """
  application_user_consent_organization_scopes_pkey
}

"""
input type for inserting data into table "application_user_consent_organization_scopes"
"""
input application_user_consent_organization_scopes_insert_input {
  application_id: String
  organization_scope_id: String
  tenant_id: String
}

"""aggregate max on columns"""
type application_user_consent_organization_scopes_max_fields {
  application_id: String
  organization_scope_id: String
  tenant_id: String
}

"""aggregate min on columns"""
type application_user_consent_organization_scopes_min_fields {
  application_id: String
  organization_scope_id: String
  tenant_id: String
}

"""
response of any mutation on the table "application_user_consent_organization_scopes"
"""
type application_user_consent_organization_scopes_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [application_user_consent_organization_scopes!]!
}

"""
on_conflict condition type for table "application_user_consent_organization_scopes"
"""
input application_user_consent_organization_scopes_on_conflict {
  constraint: application_user_consent_organization_scopes_constraint!
  update_columns: [application_user_consent_organization_scopes_update_column!]! = []
  where: application_user_consent_organization_scopes_bool_exp
}

"""
Ordering options when selecting data from "application_user_consent_organization_scopes".
"""
input application_user_consent_organization_scopes_order_by {
  application_id: order_by
  organization_scope_id: order_by
  tenant_id: order_by
}

"""
primary key columns input for table: application_user_consent_organization_scopes
"""
input application_user_consent_organization_scopes_pk_columns_input {
  application_id: String!
  organization_scope_id: String!
}

"""
select columns of table "application_user_consent_organization_scopes"
"""
enum application_user_consent_organization_scopes_select_column {
  """column name"""
  application_id

  """column name"""
  organization_scope_id

  """column name"""
  tenant_id
}

"""
input type for updating data in table "application_user_consent_organization_scopes"
"""
input application_user_consent_organization_scopes_set_input {
  application_id: String
  organization_scope_id: String
  tenant_id: String
}

"""
Streaming cursor of the table "application_user_consent_organization_scopes"
"""
input application_user_consent_organization_scopes_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: application_user_consent_organization_scopes_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input application_user_consent_organization_scopes_stream_cursor_value_input {
  application_id: String
  organization_scope_id: String
  tenant_id: String
}

"""
update columns of table "application_user_consent_organization_scopes"
"""
enum application_user_consent_organization_scopes_update_column {
  """column name"""
  application_id

  """column name"""
  organization_scope_id

  """column name"""
  tenant_id
}

input application_user_consent_organization_scopes_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: application_user_consent_organization_scopes_set_input

  """filter the rows which have to be updated"""
  where: application_user_consent_organization_scopes_bool_exp!
}

"""
columns and relationships of "application_user_consent_organizations"
"""
type application_user_consent_organizations {
  application_id: String!
  organization_id: String!
  tenant_id: String!
  user_id: String!
}

"""
aggregated selection of "application_user_consent_organizations"
"""
type application_user_consent_organizations_aggregate {
  aggregate: application_user_consent_organizations_aggregate_fields
  nodes: [application_user_consent_organizations!]!
}

"""
aggregate fields of "application_user_consent_organizations"
"""
type application_user_consent_organizations_aggregate_fields {
  count(columns: [application_user_consent_organizations_select_column!], distinct: Boolean): Int!
  max: application_user_consent_organizations_max_fields
  min: application_user_consent_organizations_min_fields
}

"""
Boolean expression to filter rows from the table "application_user_consent_organizations". All fields are combined with a logical 'AND'.
"""
input application_user_consent_organizations_bool_exp {
  _and: [application_user_consent_organizations_bool_exp!]
  _not: application_user_consent_organizations_bool_exp
  _or: [application_user_consent_organizations_bool_exp!]
  application_id: String_comparison_exp
  organization_id: String_comparison_exp
  tenant_id: String_comparison_exp
  user_id: String_comparison_exp
}

"""
unique or primary key constraints on table "application_user_consent_organizations"
"""
enum application_user_consent_organizations_constraint {
  """
  unique or primary key constraint on columns "application_id", "user_id", "tenant_id", "organization_id"
  """
  application_user_consent_organizations_pkey
}

"""
input type for inserting data into table "application_user_consent_organizations"
"""
input application_user_consent_organizations_insert_input {
  application_id: String
  organization_id: String
  tenant_id: String
  user_id: String
}

"""aggregate max on columns"""
type application_user_consent_organizations_max_fields {
  application_id: String
  organization_id: String
  tenant_id: String
  user_id: String
}

"""aggregate min on columns"""
type application_user_consent_organizations_min_fields {
  application_id: String
  organization_id: String
  tenant_id: String
  user_id: String
}

"""
response of any mutation on the table "application_user_consent_organizations"
"""
type application_user_consent_organizations_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [application_user_consent_organizations!]!
}

"""
on_conflict condition type for table "application_user_consent_organizations"
"""
input application_user_consent_organizations_on_conflict {
  constraint: application_user_consent_organizations_constraint!
  update_columns: [application_user_consent_organizations_update_column!]! = []
  where: application_user_consent_organizations_bool_exp
}

"""
Ordering options when selecting data from "application_user_consent_organizations".
"""
input application_user_consent_organizations_order_by {
  application_id: order_by
  organization_id: order_by
  tenant_id: order_by
  user_id: order_by
}

"""
primary key columns input for table: application_user_consent_organizations
"""
input application_user_consent_organizations_pk_columns_input {
  application_id: String!
  organization_id: String!
  tenant_id: String!
  user_id: String!
}

"""
select columns of table "application_user_consent_organizations"
"""
enum application_user_consent_organizations_select_column {
  """column name"""
  application_id

  """column name"""
  organization_id

  """column name"""
  tenant_id

  """column name"""
  user_id
}

"""
input type for updating data in table "application_user_consent_organizations"
"""
input application_user_consent_organizations_set_input {
  application_id: String
  organization_id: String
  tenant_id: String
  user_id: String
}

"""
Streaming cursor of the table "application_user_consent_organizations"
"""
input application_user_consent_organizations_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: application_user_consent_organizations_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input application_user_consent_organizations_stream_cursor_value_input {
  application_id: String
  organization_id: String
  tenant_id: String
  user_id: String
}

"""
update columns of table "application_user_consent_organizations"
"""
enum application_user_consent_organizations_update_column {
  """column name"""
  application_id

  """column name"""
  organization_id

  """column name"""
  tenant_id

  """column name"""
  user_id
}

input application_user_consent_organizations_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: application_user_consent_organizations_set_input

  """filter the rows which have to be updated"""
  where: application_user_consent_organizations_bool_exp!
}

"""
columns and relationships of "application_user_consent_resource_scopes"
"""
type application_user_consent_resource_scopes {
  application_id: String!
  scope_id: String!
  tenant_id: String!
}

"""
aggregated selection of "application_user_consent_resource_scopes"
"""
type application_user_consent_resource_scopes_aggregate {
  aggregate: application_user_consent_resource_scopes_aggregate_fields
  nodes: [application_user_consent_resource_scopes!]!
}

"""
aggregate fields of "application_user_consent_resource_scopes"
"""
type application_user_consent_resource_scopes_aggregate_fields {
  count(columns: [application_user_consent_resource_scopes_select_column!], distinct: Boolean): Int!
  max: application_user_consent_resource_scopes_max_fields
  min: application_user_consent_resource_scopes_min_fields
}

"""
Boolean expression to filter rows from the table "application_user_consent_resource_scopes". All fields are combined with a logical 'AND'.
"""
input application_user_consent_resource_scopes_bool_exp {
  _and: [application_user_consent_resource_scopes_bool_exp!]
  _not: application_user_consent_resource_scopes_bool_exp
  _or: [application_user_consent_resource_scopes_bool_exp!]
  application_id: String_comparison_exp
  scope_id: String_comparison_exp
  tenant_id: String_comparison_exp
}

"""
unique or primary key constraints on table "application_user_consent_resource_scopes"
"""
enum application_user_consent_resource_scopes_constraint {
  """
  unique or primary key constraint on columns "application_id", "scope_id"
  """
  application_user_consent_resource_scopes_pkey
}

"""
input type for inserting data into table "application_user_consent_resource_scopes"
"""
input application_user_consent_resource_scopes_insert_input {
  application_id: String
  scope_id: String
  tenant_id: String
}

"""aggregate max on columns"""
type application_user_consent_resource_scopes_max_fields {
  application_id: String
  scope_id: String
  tenant_id: String
}

"""aggregate min on columns"""
type application_user_consent_resource_scopes_min_fields {
  application_id: String
  scope_id: String
  tenant_id: String
}

"""
response of any mutation on the table "application_user_consent_resource_scopes"
"""
type application_user_consent_resource_scopes_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [application_user_consent_resource_scopes!]!
}

"""
on_conflict condition type for table "application_user_consent_resource_scopes"
"""
input application_user_consent_resource_scopes_on_conflict {
  constraint: application_user_consent_resource_scopes_constraint!
  update_columns: [application_user_consent_resource_scopes_update_column!]! = []
  where: application_user_consent_resource_scopes_bool_exp
}

"""
Ordering options when selecting data from "application_user_consent_resource_scopes".
"""
input application_user_consent_resource_scopes_order_by {
  application_id: order_by
  scope_id: order_by
  tenant_id: order_by
}

"""
primary key columns input for table: application_user_consent_resource_scopes
"""
input application_user_consent_resource_scopes_pk_columns_input {
  application_id: String!
  scope_id: String!
}

"""
select columns of table "application_user_consent_resource_scopes"
"""
enum application_user_consent_resource_scopes_select_column {
  """column name"""
  application_id

  """column name"""
  scope_id

  """column name"""
  tenant_id
}

"""
input type for updating data in table "application_user_consent_resource_scopes"
"""
input application_user_consent_resource_scopes_set_input {
  application_id: String
  scope_id: String
  tenant_id: String
}

"""
Streaming cursor of the table "application_user_consent_resource_scopes"
"""
input application_user_consent_resource_scopes_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: application_user_consent_resource_scopes_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input application_user_consent_resource_scopes_stream_cursor_value_input {
  application_id: String
  scope_id: String
  tenant_id: String
}

"""
update columns of table "application_user_consent_resource_scopes"
"""
enum application_user_consent_resource_scopes_update_column {
  """column name"""
  application_id

  """column name"""
  scope_id

  """column name"""
  tenant_id
}

input application_user_consent_resource_scopes_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: application_user_consent_resource_scopes_set_input

  """filter the rows which have to be updated"""
  where: application_user_consent_resource_scopes_bool_exp!
}

"""
columns and relationships of "application_user_consent_user_scopes"
"""
type application_user_consent_user_scopes {
  application_id: String!
  tenant_id: String!
  user_scope: String!
}

"""
aggregated selection of "application_user_consent_user_scopes"
"""
type application_user_consent_user_scopes_aggregate {
  aggregate: application_user_consent_user_scopes_aggregate_fields
  nodes: [application_user_consent_user_scopes!]!
}

"""
aggregate fields of "application_user_consent_user_scopes"
"""
type application_user_consent_user_scopes_aggregate_fields {
  count(columns: [application_user_consent_user_scopes_select_column!], distinct: Boolean): Int!
  max: application_user_consent_user_scopes_max_fields
  min: application_user_consent_user_scopes_min_fields
}

"""
Boolean expression to filter rows from the table "application_user_consent_user_scopes". All fields are combined with a logical 'AND'.
"""
input application_user_consent_user_scopes_bool_exp {
  _and: [application_user_consent_user_scopes_bool_exp!]
  _not: application_user_consent_user_scopes_bool_exp
  _or: [application_user_consent_user_scopes_bool_exp!]
  application_id: String_comparison_exp
  tenant_id: String_comparison_exp
  user_scope: String_comparison_exp
}

"""
unique or primary key constraints on table "application_user_consent_user_scopes"
"""
enum application_user_consent_user_scopes_constraint {
  """
  unique or primary key constraint on columns "application_id", "user_scope"
  """
  application_user_consent_user_scopes_pkey
}

"""
input type for inserting data into table "application_user_consent_user_scopes"
"""
input application_user_consent_user_scopes_insert_input {
  application_id: String
  tenant_id: String
  user_scope: String
}

"""aggregate max on columns"""
type application_user_consent_user_scopes_max_fields {
  application_id: String
  tenant_id: String
  user_scope: String
}

"""aggregate min on columns"""
type application_user_consent_user_scopes_min_fields {
  application_id: String
  tenant_id: String
  user_scope: String
}

"""
response of any mutation on the table "application_user_consent_user_scopes"
"""
type application_user_consent_user_scopes_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [application_user_consent_user_scopes!]!
}

"""
on_conflict condition type for table "application_user_consent_user_scopes"
"""
input application_user_consent_user_scopes_on_conflict {
  constraint: application_user_consent_user_scopes_constraint!
  update_columns: [application_user_consent_user_scopes_update_column!]! = []
  where: application_user_consent_user_scopes_bool_exp
}

"""
Ordering options when selecting data from "application_user_consent_user_scopes".
"""
input application_user_consent_user_scopes_order_by {
  application_id: order_by
  tenant_id: order_by
  user_scope: order_by
}

"""
primary key columns input for table: application_user_consent_user_scopes
"""
input application_user_consent_user_scopes_pk_columns_input {
  application_id: String!
  user_scope: String!
}

"""
select columns of table "application_user_consent_user_scopes"
"""
enum application_user_consent_user_scopes_select_column {
  """column name"""
  application_id

  """column name"""
  tenant_id

  """column name"""
  user_scope
}

"""
input type for updating data in table "application_user_consent_user_scopes"
"""
input application_user_consent_user_scopes_set_input {
  application_id: String
  tenant_id: String
  user_scope: String
}

"""
Streaming cursor of the table "application_user_consent_user_scopes"
"""
input application_user_consent_user_scopes_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: application_user_consent_user_scopes_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input application_user_consent_user_scopes_stream_cursor_value_input {
  application_id: String
  tenant_id: String
  user_scope: String
}

"""
update columns of table "application_user_consent_user_scopes"
"""
enum application_user_consent_user_scopes_update_column {
  """column name"""
  application_id

  """column name"""
  tenant_id

  """column name"""
  user_scope
}

input application_user_consent_user_scopes_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: application_user_consent_user_scopes_set_input

  """filter the rows which have to be updated"""
  where: application_user_consent_user_scopes_bool_exp!
}

"""
columns and relationships of "applications"
"""
type applications {
  created_at: timestamptz!
  custom_client_metadata(
    """JSON select path"""
    path: String
  ): jsonb!
  description: String
  id: String!
  is_third_party: Boolean!
  name: String!
  oidc_client_metadata(
    """JSON select path"""
    path: String
  ): jsonb!
  protected_app_metadata(
    """JSON select path"""
    path: String
  ): jsonb
  secret: String!
  tenant_id: String!
  type: application_type!
}

"""
aggregated selection of "applications"
"""
type applications_aggregate {
  aggregate: applications_aggregate_fields
  nodes: [applications!]!
}

"""
aggregate fields of "applications"
"""
type applications_aggregate_fields {
  count(columns: [applications_select_column!], distinct: Boolean): Int!
  max: applications_max_fields
  min: applications_min_fields
}

"""append existing jsonb value of filtered columns with new jsonb value"""
input applications_append_input {
  custom_client_metadata: jsonb
  oidc_client_metadata: jsonb
  protected_app_metadata: jsonb
}

"""
Boolean expression to filter rows from the table "applications". All fields are combined with a logical 'AND'.
"""
input applications_bool_exp {
  _and: [applications_bool_exp!]
  _not: applications_bool_exp
  _or: [applications_bool_exp!]
  created_at: timestamptz_comparison_exp
  custom_client_metadata: jsonb_comparison_exp
  description: String_comparison_exp
  id: String_comparison_exp
  is_third_party: Boolean_comparison_exp
  name: String_comparison_exp
  oidc_client_metadata: jsonb_comparison_exp
  protected_app_metadata: jsonb_comparison_exp
  secret: String_comparison_exp
  tenant_id: String_comparison_exp
  type: application_type_comparison_exp
}

"""
unique or primary key constraints on table "applications"
"""
enum applications_constraint {
  """unique or primary key constraint on columns """
  applications__protected_app_metadata_custom_domain

  """unique or primary key constraint on columns """
  applications__protected_app_metadata_host

  """
  unique or primary key constraint on columns "id"
  """
  applications_pkey
}

"""
delete the field or element with specified path (for JSON arrays, negative integers count from the end)
"""
input applications_delete_at_path_input {
  custom_client_metadata: [String!]
  oidc_client_metadata: [String!]
  protected_app_metadata: [String!]
}

"""
delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
"""
input applications_delete_elem_input {
  custom_client_metadata: Int
  oidc_client_metadata: Int
  protected_app_metadata: Int
}

"""
delete key/value pair or string element. key/value pairs are matched based on their key value
"""
input applications_delete_key_input {
  custom_client_metadata: String
  oidc_client_metadata: String
  protected_app_metadata: String
}

"""
input type for inserting data into table "applications"
"""
input applications_insert_input {
  created_at: timestamptz
  custom_client_metadata: jsonb
  description: String
  id: String
  is_third_party: Boolean
  name: String
  oidc_client_metadata: jsonb
  protected_app_metadata: jsonb
  secret: String
  tenant_id: String
  type: application_type
}

"""aggregate max on columns"""
type applications_max_fields {
  created_at: timestamptz
  description: String
  id: String
  name: String
  secret: String
  tenant_id: String
  type: application_type
}

"""aggregate min on columns"""
type applications_min_fields {
  created_at: timestamptz
  description: String
  id: String
  name: String
  secret: String
  tenant_id: String
  type: application_type
}

"""
response of any mutation on the table "applications"
"""
type applications_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [applications!]!
}

"""
on_conflict condition type for table "applications"
"""
input applications_on_conflict {
  constraint: applications_constraint!
  update_columns: [applications_update_column!]! = []
  where: applications_bool_exp
}

"""Ordering options when selecting data from "applications"."""
input applications_order_by {
  created_at: order_by
  custom_client_metadata: order_by
  description: order_by
  id: order_by
  is_third_party: order_by
  name: order_by
  oidc_client_metadata: order_by
  protected_app_metadata: order_by
  secret: order_by
  tenant_id: order_by
  type: order_by
}

"""primary key columns input for table: applications"""
input applications_pk_columns_input {
  id: String!
}

"""prepend existing jsonb value of filtered columns with new jsonb value"""
input applications_prepend_input {
  custom_client_metadata: jsonb
  oidc_client_metadata: jsonb
  protected_app_metadata: jsonb
}

"""
columns and relationships of "applications_roles"
"""
type applications_roles {
  application_id: String!
  id: String!
  role_id: String!
  tenant_id: String!
}

"""
aggregated selection of "applications_roles"
"""
type applications_roles_aggregate {
  aggregate: applications_roles_aggregate_fields
  nodes: [applications_roles!]!
}

"""
aggregate fields of "applications_roles"
"""
type applications_roles_aggregate_fields {
  count(columns: [applications_roles_select_column!], distinct: Boolean): Int!
  max: applications_roles_max_fields
  min: applications_roles_min_fields
}

"""
Boolean expression to filter rows from the table "applications_roles". All fields are combined with a logical 'AND'.
"""
input applications_roles_bool_exp {
  _and: [applications_roles_bool_exp!]
  _not: applications_roles_bool_exp
  _or: [applications_roles_bool_exp!]
  application_id: String_comparison_exp
  id: String_comparison_exp
  role_id: String_comparison_exp
  tenant_id: String_comparison_exp
}

"""
unique or primary key constraints on table "applications_roles"
"""
enum applications_roles_constraint {
  """
  unique or primary key constraint on columns "role_id", "application_id", "tenant_id"
  """
  applications_roles__application_id_role_id

  """
  unique or primary key constraint on columns "id"
  """
  applications_roles_pkey
}

"""
input type for inserting data into table "applications_roles"
"""
input applications_roles_insert_input {
  application_id: String
  id: String
  role_id: String
  tenant_id: String
}

"""aggregate max on columns"""
type applications_roles_max_fields {
  application_id: String
  id: String
  role_id: String
  tenant_id: String
}

"""aggregate min on columns"""
type applications_roles_min_fields {
  application_id: String
  id: String
  role_id: String
  tenant_id: String
}

"""
response of any mutation on the table "applications_roles"
"""
type applications_roles_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [applications_roles!]!
}

"""
on_conflict condition type for table "applications_roles"
"""
input applications_roles_on_conflict {
  constraint: applications_roles_constraint!
  update_columns: [applications_roles_update_column!]! = []
  where: applications_roles_bool_exp
}

"""Ordering options when selecting data from "applications_roles"."""
input applications_roles_order_by {
  application_id: order_by
  id: order_by
  role_id: order_by
  tenant_id: order_by
}

"""primary key columns input for table: applications_roles"""
input applications_roles_pk_columns_input {
  id: String!
}

"""
select columns of table "applications_roles"
"""
enum applications_roles_select_column {
  """column name"""
  application_id

  """column name"""
  id

  """column name"""
  role_id

  """column name"""
  tenant_id
}

"""
input type for updating data in table "applications_roles"
"""
input applications_roles_set_input {
  application_id: String
  id: String
  role_id: String
  tenant_id: String
}

"""
Streaming cursor of the table "applications_roles"
"""
input applications_roles_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: applications_roles_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input applications_roles_stream_cursor_value_input {
  application_id: String
  id: String
  role_id: String
  tenant_id: String
}

"""
update columns of table "applications_roles"
"""
enum applications_roles_update_column {
  """column name"""
  application_id

  """column name"""
  id

  """column name"""
  role_id

  """column name"""
  tenant_id
}

input applications_roles_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: applications_roles_set_input

  """filter the rows which have to be updated"""
  where: applications_roles_bool_exp!
}

"""
select columns of table "applications"
"""
enum applications_select_column {
  """column name"""
  created_at

  """column name"""
  custom_client_metadata

  """column name"""
  description

  """column name"""
  id

  """column name"""
  is_third_party

  """column name"""
  name

  """column name"""
  oidc_client_metadata

  """column name"""
  protected_app_metadata

  """column name"""
  secret

  """column name"""
  tenant_id

  """column name"""
  type
}

"""
input type for updating data in table "applications"
"""
input applications_set_input {
  created_at: timestamptz
  custom_client_metadata: jsonb
  description: String
  id: String
  is_third_party: Boolean
  name: String
  oidc_client_metadata: jsonb
  protected_app_metadata: jsonb
  secret: String
  tenant_id: String
  type: application_type
}

"""
Streaming cursor of the table "applications"
"""
input applications_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: applications_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input applications_stream_cursor_value_input {
  created_at: timestamptz
  custom_client_metadata: jsonb
  description: String
  id: String
  is_third_party: Boolean
  name: String
  oidc_client_metadata: jsonb
  protected_app_metadata: jsonb
  secret: String
  tenant_id: String
  type: application_type
}

"""
update columns of table "applications"
"""
enum applications_update_column {
  """column name"""
  created_at

  """column name"""
  custom_client_metadata

  """column name"""
  description

  """column name"""
  id

  """column name"""
  is_third_party

  """column name"""
  name

  """column name"""
  oidc_client_metadata

  """column name"""
  protected_app_metadata

  """column name"""
  secret

  """column name"""
  tenant_id

  """column name"""
  type
}

input applications_updates {
  """append existing jsonb value of filtered columns with new jsonb value"""
  _append: applications_append_input

  """
  delete the field or element with specified path (for JSON arrays, negative integers count from the end)
  """
  _delete_at_path: applications_delete_at_path_input

  """
  delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
  """
  _delete_elem: applications_delete_elem_input

  """
  delete key/value pair or string element. key/value pairs are matched based on their key value
  """
  _delete_key: applications_delete_key_input

  """prepend existing jsonb value of filtered columns with new jsonb value"""
  _prepend: applications_prepend_input

  """sets the columns of the filtered rows to the given values"""
  _set: applications_set_input

  """filter the rows which have to be updated"""
  where: applications_bool_exp!
}

scalar bigint

"""
Boolean expression to compare columns of type "bigint". All fields are combined with logical 'AND'.
"""
input bigint_comparison_exp {
  _eq: bigint
  _gt: bigint
  _gte: bigint
  _in: [bigint!]
  _is_null: Boolean
  _lt: bigint
  _lte: bigint
  _neq: bigint
  _nin: [bigint!]
}

""" 签到设置表"""
type check_in_settings {
  """之后连续签到天数"""
  following: numeric!
  following_url: String
  id: uuid!

  """首次连续签到天数"""
  inaugural: numeric!
  inaugural_url: String
}

"""
aggregated selection of "check_in_settings"
"""
type check_in_settings_aggregate {
  aggregate: check_in_settings_aggregate_fields
  nodes: [check_in_settings!]!
}

"""
aggregate fields of "check_in_settings"
"""
type check_in_settings_aggregate_fields {
  avg: check_in_settings_avg_fields
  count(columns: [check_in_settings_select_column!], distinct: Boolean): Int!
  max: check_in_settings_max_fields
  min: check_in_settings_min_fields
  stddev: check_in_settings_stddev_fields
  stddev_pop: check_in_settings_stddev_pop_fields
  stddev_samp: check_in_settings_stddev_samp_fields
  sum: check_in_settings_sum_fields
  var_pop: check_in_settings_var_pop_fields
  var_samp: check_in_settings_var_samp_fields
  variance: check_in_settings_variance_fields
}

"""aggregate avg on columns"""
type check_in_settings_avg_fields {
  """之后连续签到天数"""
  following: Float

  """首次连续签到天数"""
  inaugural: Float
}

"""
Boolean expression to filter rows from the table "check_in_settings". All fields are combined with a logical 'AND'.
"""
input check_in_settings_bool_exp {
  _and: [check_in_settings_bool_exp!]
  _not: check_in_settings_bool_exp
  _or: [check_in_settings_bool_exp!]
  following: numeric_comparison_exp
  following_url: String_comparison_exp
  id: uuid_comparison_exp
  inaugural: numeric_comparison_exp
  inaugural_url: String_comparison_exp
}

"""
unique or primary key constraints on table "check_in_settings"
"""
enum check_in_settings_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  check_in_settings_pkey
}

"""
input type for incrementing numeric columns in table "check_in_settings"
"""
input check_in_settings_inc_input {
  """之后连续签到天数"""
  following: numeric

  """首次连续签到天数"""
  inaugural: numeric
}

"""
input type for inserting data into table "check_in_settings"
"""
input check_in_settings_insert_input {
  """之后连续签到天数"""
  following: numeric
  following_url: String
  id: uuid

  """首次连续签到天数"""
  inaugural: numeric
  inaugural_url: String
}

"""aggregate max on columns"""
type check_in_settings_max_fields {
  """之后连续签到天数"""
  following: numeric
  following_url: String
  id: uuid

  """首次连续签到天数"""
  inaugural: numeric
  inaugural_url: String
}

"""aggregate min on columns"""
type check_in_settings_min_fields {
  """之后连续签到天数"""
  following: numeric
  following_url: String
  id: uuid

  """首次连续签到天数"""
  inaugural: numeric
  inaugural_url: String
}

"""
response of any mutation on the table "check_in_settings"
"""
type check_in_settings_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [check_in_settings!]!
}

"""
on_conflict condition type for table "check_in_settings"
"""
input check_in_settings_on_conflict {
  constraint: check_in_settings_constraint!
  update_columns: [check_in_settings_update_column!]! = []
  where: check_in_settings_bool_exp
}

"""Ordering options when selecting data from "check_in_settings"."""
input check_in_settings_order_by {
  following: order_by
  following_url: order_by
  id: order_by
  inaugural: order_by
  inaugural_url: order_by
}

"""primary key columns input for table: check_in_settings"""
input check_in_settings_pk_columns_input {
  id: uuid!
}

"""
select columns of table "check_in_settings"
"""
enum check_in_settings_select_column {
  """column name"""
  following

  """column name"""
  following_url

  """column name"""
  id

  """column name"""
  inaugural

  """column name"""
  inaugural_url
}

"""
input type for updating data in table "check_in_settings"
"""
input check_in_settings_set_input {
  """之后连续签到天数"""
  following: numeric
  following_url: String
  id: uuid

  """首次连续签到天数"""
  inaugural: numeric
  inaugural_url: String
}

"""aggregate stddev on columns"""
type check_in_settings_stddev_fields {
  """之后连续签到天数"""
  following: Float

  """首次连续签到天数"""
  inaugural: Float
}

"""aggregate stddev_pop on columns"""
type check_in_settings_stddev_pop_fields {
  """之后连续签到天数"""
  following: Float

  """首次连续签到天数"""
  inaugural: Float
}

"""aggregate stddev_samp on columns"""
type check_in_settings_stddev_samp_fields {
  """之后连续签到天数"""
  following: Float

  """首次连续签到天数"""
  inaugural: Float
}

"""
Streaming cursor of the table "check_in_settings"
"""
input check_in_settings_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: check_in_settings_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input check_in_settings_stream_cursor_value_input {
  """之后连续签到天数"""
  following: numeric
  following_url: String
  id: uuid

  """首次连续签到天数"""
  inaugural: numeric
  inaugural_url: String
}

"""aggregate sum on columns"""
type check_in_settings_sum_fields {
  """之后连续签到天数"""
  following: numeric

  """首次连续签到天数"""
  inaugural: numeric
}

"""
update columns of table "check_in_settings"
"""
enum check_in_settings_update_column {
  """column name"""
  following

  """column name"""
  following_url

  """column name"""
  id

  """column name"""
  inaugural

  """column name"""
  inaugural_url
}

input check_in_settings_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: check_in_settings_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: check_in_settings_set_input

  """filter the rows which have to be updated"""
  where: check_in_settings_bool_exp!
}

"""aggregate var_pop on columns"""
type check_in_settings_var_pop_fields {
  """之后连续签到天数"""
  following: Float

  """首次连续签到天数"""
  inaugural: Float
}

"""aggregate var_samp on columns"""
type check_in_settings_var_samp_fields {
  """之后连续签到天数"""
  following: Float

  """首次连续签到天数"""
  inaugural: Float
}

"""aggregate variance on columns"""
type check_in_settings_variance_fields {
  """之后连续签到天数"""
  following: Float

  """首次连续签到天数"""
  inaugural: Float
}

"""打卡签到表"""
type check_ins {
  check_in_date: date!
  consecutive_days: Int!
  created_at: timestamptz
  id: uuid!

  """是否连续签到"""
  is_continuation: Boolean!

  """是否完成首次连续签到"""
  is_first_consecutive_completed: Boolean
  user_id: String!
}

"""
aggregated selection of "check_ins"
"""
type check_ins_aggregate {
  aggregate: check_ins_aggregate_fields
  nodes: [check_ins!]!
}

"""
aggregate fields of "check_ins"
"""
type check_ins_aggregate_fields {
  avg: check_ins_avg_fields
  count(columns: [check_ins_select_column!], distinct: Boolean): Int!
  max: check_ins_max_fields
  min: check_ins_min_fields
  stddev: check_ins_stddev_fields
  stddev_pop: check_ins_stddev_pop_fields
  stddev_samp: check_ins_stddev_samp_fields
  sum: check_ins_sum_fields
  var_pop: check_ins_var_pop_fields
  var_samp: check_ins_var_samp_fields
  variance: check_ins_variance_fields
}

"""aggregate avg on columns"""
type check_ins_avg_fields {
  consecutive_days: Float
}

"""
Boolean expression to filter rows from the table "check_ins". All fields are combined with a logical 'AND'.
"""
input check_ins_bool_exp {
  _and: [check_ins_bool_exp!]
  _not: check_ins_bool_exp
  _or: [check_ins_bool_exp!]
  check_in_date: date_comparison_exp
  consecutive_days: Int_comparison_exp
  created_at: timestamptz_comparison_exp
  id: uuid_comparison_exp
  is_continuation: Boolean_comparison_exp
  is_first_consecutive_completed: Boolean_comparison_exp
  user_id: String_comparison_exp
}

"""
unique or primary key constraints on table "check_ins"
"""
enum check_ins_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  check_ins_id_key

  """
  unique or primary key constraint on columns "id"
  """
  check_ins_pkey
}

"""
input type for incrementing numeric columns in table "check_ins"
"""
input check_ins_inc_input {
  consecutive_days: Int
}

"""
input type for inserting data into table "check_ins"
"""
input check_ins_insert_input {
  check_in_date: date
  consecutive_days: Int
  created_at: timestamptz
  id: uuid

  """是否连续签到"""
  is_continuation: Boolean

  """是否完成首次连续签到"""
  is_first_consecutive_completed: Boolean
  user_id: String
}

"""aggregate max on columns"""
type check_ins_max_fields {
  check_in_date: date
  consecutive_days: Int
  created_at: timestamptz
  id: uuid
  user_id: String
}

"""aggregate min on columns"""
type check_ins_min_fields {
  check_in_date: date
  consecutive_days: Int
  created_at: timestamptz
  id: uuid
  user_id: String
}

"""
response of any mutation on the table "check_ins"
"""
type check_ins_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [check_ins!]!
}

"""
on_conflict condition type for table "check_ins"
"""
input check_ins_on_conflict {
  constraint: check_ins_constraint!
  update_columns: [check_ins_update_column!]! = []
  where: check_ins_bool_exp
}

"""Ordering options when selecting data from "check_ins"."""
input check_ins_order_by {
  check_in_date: order_by
  consecutive_days: order_by
  created_at: order_by
  id: order_by
  is_continuation: order_by
  is_first_consecutive_completed: order_by
  user_id: order_by
}

"""primary key columns input for table: check_ins"""
input check_ins_pk_columns_input {
  id: uuid!
}

"""
select columns of table "check_ins"
"""
enum check_ins_select_column {
  """column name"""
  check_in_date

  """column name"""
  consecutive_days

  """column name"""
  created_at

  """column name"""
  id

  """column name"""
  is_continuation

  """column name"""
  is_first_consecutive_completed

  """column name"""
  user_id
}

"""
input type for updating data in table "check_ins"
"""
input check_ins_set_input {
  check_in_date: date
  consecutive_days: Int
  created_at: timestamptz
  id: uuid

  """是否连续签到"""
  is_continuation: Boolean

  """是否完成首次连续签到"""
  is_first_consecutive_completed: Boolean
  user_id: String
}

"""aggregate stddev on columns"""
type check_ins_stddev_fields {
  consecutive_days: Float
}

"""aggregate stddev_pop on columns"""
type check_ins_stddev_pop_fields {
  consecutive_days: Float
}

"""aggregate stddev_samp on columns"""
type check_ins_stddev_samp_fields {
  consecutive_days: Float
}

"""
Streaming cursor of the table "check_ins"
"""
input check_ins_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: check_ins_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input check_ins_stream_cursor_value_input {
  check_in_date: date
  consecutive_days: Int
  created_at: timestamptz
  id: uuid

  """是否连续签到"""
  is_continuation: Boolean

  """是否完成首次连续签到"""
  is_first_consecutive_completed: Boolean
  user_id: String
}

"""aggregate sum on columns"""
type check_ins_sum_fields {
  consecutive_days: Int
}

"""
update columns of table "check_ins"
"""
enum check_ins_update_column {
  """column name"""
  check_in_date

  """column name"""
  consecutive_days

  """column name"""
  created_at

  """column name"""
  id

  """column name"""
  is_continuation

  """column name"""
  is_first_consecutive_completed

  """column name"""
  user_id
}

input check_ins_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: check_ins_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: check_ins_set_input

  """filter the rows which have to be updated"""
  where: check_ins_bool_exp!
}

"""aggregate var_pop on columns"""
type check_ins_var_pop_fields {
  consecutive_days: Float
}

"""aggregate var_samp on columns"""
type check_ins_var_samp_fields {
  consecutive_days: Float
}

"""aggregate variance on columns"""
type check_ins_variance_fields {
  consecutive_days: Float
}

"""血压记录表"""
type cholesterol_records {
  created_at: timestamptz!

  """舒张压（低压）"""
  diastolic_pressure: numeric!
  id: uuid!

  """
  A computed field, executes function "calculate_cholesterol_exception"
  """
  is_exception: Boolean

  """测量时段，1：上午、2：中午、3：下午、4：睡前"""
  measurement_period: Int

  """用药记录"""
  medication_record: String

  """脉搏（心率）"""
  pulse_rate: numeric!

  """记录时间"""
  record_time: timestamptz!
  remarks: String

  """症状，1：早搏、2：心率不齐、3：心颤"""
  symptoms(
    """JSON select path"""
    path: String
  ): jsonb

  """收缩压（高压）"""
  systolic_pressure: numeric!

  """
  A computed field, executes function "calculate_cholesterol_too_large"
  """
  too_large: Boolean

  """
  A computed field, executes function "calculate_cholesterol_too_small"
  """
  too_small: Boolean
  updated_at: timestamptz!
  user_id: String!
}

"""
aggregated selection of "cholesterol_records"
"""
type cholesterol_records_aggregate {
  aggregate: cholesterol_records_aggregate_fields
  nodes: [cholesterol_records!]!
}

"""
aggregate fields of "cholesterol_records"
"""
type cholesterol_records_aggregate_fields {
  avg: cholesterol_records_avg_fields
  count(columns: [cholesterol_records_select_column!], distinct: Boolean): Int!
  max: cholesterol_records_max_fields
  min: cholesterol_records_min_fields
  stddev: cholesterol_records_stddev_fields
  stddev_pop: cholesterol_records_stddev_pop_fields
  stddev_samp: cholesterol_records_stddev_samp_fields
  sum: cholesterol_records_sum_fields
  var_pop: cholesterol_records_var_pop_fields
  var_samp: cholesterol_records_var_samp_fields
  variance: cholesterol_records_variance_fields
}

"""append existing jsonb value of filtered columns with new jsonb value"""
input cholesterol_records_append_input {
  """症状，1：早搏、2：心率不齐、3：心颤"""
  symptoms: jsonb
}

"""aggregate avg on columns"""
type cholesterol_records_avg_fields {
  """舒张压（低压）"""
  diastolic_pressure: Float

  """测量时段，1：上午、2：中午、3：下午、4：睡前"""
  measurement_period: Float

  """脉搏（心率）"""
  pulse_rate: Float

  """收缩压（高压）"""
  systolic_pressure: Float
}

"""
Boolean expression to filter rows from the table "cholesterol_records". All fields are combined with a logical 'AND'.
"""
input cholesterol_records_bool_exp {
  _and: [cholesterol_records_bool_exp!]
  _not: cholesterol_records_bool_exp
  _or: [cholesterol_records_bool_exp!]
  created_at: timestamptz_comparison_exp
  diastolic_pressure: numeric_comparison_exp
  id: uuid_comparison_exp
  is_exception: Boolean_comparison_exp
  measurement_period: Int_comparison_exp
  medication_record: String_comparison_exp
  pulse_rate: numeric_comparison_exp
  record_time: timestamptz_comparison_exp
  remarks: String_comparison_exp
  symptoms: jsonb_comparison_exp
  systolic_pressure: numeric_comparison_exp
  too_large: Boolean_comparison_exp
  too_small: Boolean_comparison_exp
  updated_at: timestamptz_comparison_exp
  user_id: String_comparison_exp
}

"""
unique or primary key constraints on table "cholesterol_records"
"""
enum cholesterol_records_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  cholesterol_records_id_key

  """
  unique or primary key constraint on columns "id"
  """
  cholesterol_records_pkey
}

"""
delete the field or element with specified path (for JSON arrays, negative integers count from the end)
"""
input cholesterol_records_delete_at_path_input {
  """症状，1：早搏、2：心率不齐、3：心颤"""
  symptoms: [String!]
}

"""
delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
"""
input cholesterol_records_delete_elem_input {
  """症状，1：早搏、2：心率不齐、3：心颤"""
  symptoms: Int
}

"""
delete key/value pair or string element. key/value pairs are matched based on their key value
"""
input cholesterol_records_delete_key_input {
  """症状，1：早搏、2：心率不齐、3：心颤"""
  symptoms: String
}

"""
input type for incrementing numeric columns in table "cholesterol_records"
"""
input cholesterol_records_inc_input {
  """舒张压（低压）"""
  diastolic_pressure: numeric

  """测量时段，1：上午、2：中午、3：下午、4：睡前"""
  measurement_period: Int

  """脉搏（心率）"""
  pulse_rate: numeric

  """收缩压（高压）"""
  systolic_pressure: numeric
}

"""
input type for inserting data into table "cholesterol_records"
"""
input cholesterol_records_insert_input {
  created_at: timestamptz

  """舒张压（低压）"""
  diastolic_pressure: numeric
  id: uuid

  """测量时段，1：上午、2：中午、3：下午、4：睡前"""
  measurement_period: Int

  """用药记录"""
  medication_record: String

  """脉搏（心率）"""
  pulse_rate: numeric

  """记录时间"""
  record_time: timestamptz
  remarks: String

  """症状，1：早搏、2：心率不齐、3：心颤"""
  symptoms: jsonb

  """收缩压（高压）"""
  systolic_pressure: numeric
  updated_at: timestamptz
  user_id: String
}

"""aggregate max on columns"""
type cholesterol_records_max_fields {
  created_at: timestamptz

  """舒张压（低压）"""
  diastolic_pressure: numeric
  id: uuid

  """测量时段，1：上午、2：中午、3：下午、4：睡前"""
  measurement_period: Int

  """用药记录"""
  medication_record: String

  """脉搏（心率）"""
  pulse_rate: numeric

  """记录时间"""
  record_time: timestamptz
  remarks: String

  """收缩压（高压）"""
  systolic_pressure: numeric
  updated_at: timestamptz
  user_id: String
}

"""aggregate min on columns"""
type cholesterol_records_min_fields {
  created_at: timestamptz

  """舒张压（低压）"""
  diastolic_pressure: numeric
  id: uuid

  """测量时段，1：上午、2：中午、3：下午、4：睡前"""
  measurement_period: Int

  """用药记录"""
  medication_record: String

  """脉搏（心率）"""
  pulse_rate: numeric

  """记录时间"""
  record_time: timestamptz
  remarks: String

  """收缩压（高压）"""
  systolic_pressure: numeric
  updated_at: timestamptz
  user_id: String
}

"""
response of any mutation on the table "cholesterol_records"
"""
type cholesterol_records_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [cholesterol_records!]!
}

"""
on_conflict condition type for table "cholesterol_records"
"""
input cholesterol_records_on_conflict {
  constraint: cholesterol_records_constraint!
  update_columns: [cholesterol_records_update_column!]! = []
  where: cholesterol_records_bool_exp
}

"""Ordering options when selecting data from "cholesterol_records"."""
input cholesterol_records_order_by {
  created_at: order_by
  diastolic_pressure: order_by
  id: order_by
  is_exception: order_by
  measurement_period: order_by
  medication_record: order_by
  pulse_rate: order_by
  record_time: order_by
  remarks: order_by
  symptoms: order_by
  systolic_pressure: order_by
  too_large: order_by
  too_small: order_by
  updated_at: order_by
  user_id: order_by
}

"""primary key columns input for table: cholesterol_records"""
input cholesterol_records_pk_columns_input {
  id: uuid!
}

"""prepend existing jsonb value of filtered columns with new jsonb value"""
input cholesterol_records_prepend_input {
  """症状，1：早搏、2：心率不齐、3：心颤"""
  symptoms: jsonb
}

"""
select columns of table "cholesterol_records"
"""
enum cholesterol_records_select_column {
  """column name"""
  created_at

  """column name"""
  diastolic_pressure

  """column name"""
  id

  """column name"""
  measurement_period

  """column name"""
  medication_record

  """column name"""
  pulse_rate

  """column name"""
  record_time

  """column name"""
  remarks

  """column name"""
  symptoms

  """column name"""
  systolic_pressure

  """column name"""
  updated_at

  """column name"""
  user_id
}

"""
input type for updating data in table "cholesterol_records"
"""
input cholesterol_records_set_input {
  created_at: timestamptz

  """舒张压（低压）"""
  diastolic_pressure: numeric
  id: uuid

  """测量时段，1：上午、2：中午、3：下午、4：睡前"""
  measurement_period: Int

  """用药记录"""
  medication_record: String

  """脉搏（心率）"""
  pulse_rate: numeric

  """记录时间"""
  record_time: timestamptz
  remarks: String

  """症状，1：早搏、2：心率不齐、3：心颤"""
  symptoms: jsonb

  """收缩压（高压）"""
  systolic_pressure: numeric
  updated_at: timestamptz
  user_id: String
}

"""aggregate stddev on columns"""
type cholesterol_records_stddev_fields {
  """舒张压（低压）"""
  diastolic_pressure: Float

  """测量时段，1：上午、2：中午、3：下午、4：睡前"""
  measurement_period: Float

  """脉搏（心率）"""
  pulse_rate: Float

  """收缩压（高压）"""
  systolic_pressure: Float
}

"""aggregate stddev_pop on columns"""
type cholesterol_records_stddev_pop_fields {
  """舒张压（低压）"""
  diastolic_pressure: Float

  """测量时段，1：上午、2：中午、3：下午、4：睡前"""
  measurement_period: Float

  """脉搏（心率）"""
  pulse_rate: Float

  """收缩压（高压）"""
  systolic_pressure: Float
}

"""aggregate stddev_samp on columns"""
type cholesterol_records_stddev_samp_fields {
  """舒张压（低压）"""
  diastolic_pressure: Float

  """测量时段，1：上午、2：中午、3：下午、4：睡前"""
  measurement_period: Float

  """脉搏（心率）"""
  pulse_rate: Float

  """收缩压（高压）"""
  systolic_pressure: Float
}

"""
Streaming cursor of the table "cholesterol_records"
"""
input cholesterol_records_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: cholesterol_records_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input cholesterol_records_stream_cursor_value_input {
  created_at: timestamptz

  """舒张压（低压）"""
  diastolic_pressure: numeric
  id: uuid

  """测量时段，1：上午、2：中午、3：下午、4：睡前"""
  measurement_period: Int

  """用药记录"""
  medication_record: String

  """脉搏（心率）"""
  pulse_rate: numeric

  """记录时间"""
  record_time: timestamptz
  remarks: String

  """症状，1：早搏、2：心率不齐、3：心颤"""
  symptoms: jsonb

  """收缩压（高压）"""
  systolic_pressure: numeric
  updated_at: timestamptz
  user_id: String
}

"""aggregate sum on columns"""
type cholesterol_records_sum_fields {
  """舒张压（低压）"""
  diastolic_pressure: numeric

  """测量时段，1：上午、2：中午、3：下午、4：睡前"""
  measurement_period: Int

  """脉搏（心率）"""
  pulse_rate: numeric

  """收缩压（高压）"""
  systolic_pressure: numeric
}

"""
update columns of table "cholesterol_records"
"""
enum cholesterol_records_update_column {
  """column name"""
  created_at

  """column name"""
  diastolic_pressure

  """column name"""
  id

  """column name"""
  measurement_period

  """column name"""
  medication_record

  """column name"""
  pulse_rate

  """column name"""
  record_time

  """column name"""
  remarks

  """column name"""
  symptoms

  """column name"""
  systolic_pressure

  """column name"""
  updated_at

  """column name"""
  user_id
}

input cholesterol_records_updates {
  """append existing jsonb value of filtered columns with new jsonb value"""
  _append: cholesterol_records_append_input

  """
  delete the field or element with specified path (for JSON arrays, negative integers count from the end)
  """
  _delete_at_path: cholesterol_records_delete_at_path_input

  """
  delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
  """
  _delete_elem: cholesterol_records_delete_elem_input

  """
  delete key/value pair or string element. key/value pairs are matched based on their key value
  """
  _delete_key: cholesterol_records_delete_key_input

  """increments the numeric columns with given value of the filtered values"""
  _inc: cholesterol_records_inc_input

  """prepend existing jsonb value of filtered columns with new jsonb value"""
  _prepend: cholesterol_records_prepend_input

  """sets the columns of the filtered rows to the given values"""
  _set: cholesterol_records_set_input

  """filter the rows which have to be updated"""
  where: cholesterol_records_bool_exp!
}

"""aggregate var_pop on columns"""
type cholesterol_records_var_pop_fields {
  """舒张压（低压）"""
  diastolic_pressure: Float

  """测量时段，1：上午、2：中午、3：下午、4：睡前"""
  measurement_period: Float

  """脉搏（心率）"""
  pulse_rate: Float

  """收缩压（高压）"""
  systolic_pressure: Float
}

"""aggregate var_samp on columns"""
type cholesterol_records_var_samp_fields {
  """舒张压（低压）"""
  diastolic_pressure: Float

  """测量时段，1：上午、2：中午、3：下午、4：睡前"""
  measurement_period: Float

  """脉搏（心率）"""
  pulse_rate: Float

  """收缩压（高压）"""
  systolic_pressure: Float
}

"""aggregate variance on columns"""
type cholesterol_records_variance_fields {
  """舒张压（低压）"""
  diastolic_pressure: Float

  """测量时段，1：上午、2：中午、3：下午、4：睡前"""
  measurement_period: Float

  """脉搏（心率）"""
  pulse_rate: Float

  """收缩压（高压）"""
  systolic_pressure: Float
}

"""血压标准表"""
type cholesterol_standards {
  diastolic_pressure: numeric!
  enabled: Boolean!
  id: uuid!
  systolic_pressure: numeric!
}

"""
aggregated selection of "cholesterol_standards"
"""
type cholesterol_standards_aggregate {
  aggregate: cholesterol_standards_aggregate_fields
  nodes: [cholesterol_standards!]!
}

"""
aggregate fields of "cholesterol_standards"
"""
type cholesterol_standards_aggregate_fields {
  avg: cholesterol_standards_avg_fields
  count(columns: [cholesterol_standards_select_column!], distinct: Boolean): Int!
  max: cholesterol_standards_max_fields
  min: cholesterol_standards_min_fields
  stddev: cholesterol_standards_stddev_fields
  stddev_pop: cholesterol_standards_stddev_pop_fields
  stddev_samp: cholesterol_standards_stddev_samp_fields
  sum: cholesterol_standards_sum_fields
  var_pop: cholesterol_standards_var_pop_fields
  var_samp: cholesterol_standards_var_samp_fields
  variance: cholesterol_standards_variance_fields
}

"""aggregate avg on columns"""
type cholesterol_standards_avg_fields {
  diastolic_pressure: Float
  systolic_pressure: Float
}

"""
Boolean expression to filter rows from the table "cholesterol_standards". All fields are combined with a logical 'AND'.
"""
input cholesterol_standards_bool_exp {
  _and: [cholesterol_standards_bool_exp!]
  _not: cholesterol_standards_bool_exp
  _or: [cholesterol_standards_bool_exp!]
  diastolic_pressure: numeric_comparison_exp
  enabled: Boolean_comparison_exp
  id: uuid_comparison_exp
  systolic_pressure: numeric_comparison_exp
}

"""
unique or primary key constraints on table "cholesterol_standards"
"""
enum cholesterol_standards_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  cholesterol_standards_pkey
}

"""
input type for incrementing numeric columns in table "cholesterol_standards"
"""
input cholesterol_standards_inc_input {
  diastolic_pressure: numeric
  systolic_pressure: numeric
}

"""
input type for inserting data into table "cholesterol_standards"
"""
input cholesterol_standards_insert_input {
  diastolic_pressure: numeric
  enabled: Boolean
  id: uuid
  systolic_pressure: numeric
}

"""aggregate max on columns"""
type cholesterol_standards_max_fields {
  diastolic_pressure: numeric
  id: uuid
  systolic_pressure: numeric
}

"""aggregate min on columns"""
type cholesterol_standards_min_fields {
  diastolic_pressure: numeric
  id: uuid
  systolic_pressure: numeric
}

"""
response of any mutation on the table "cholesterol_standards"
"""
type cholesterol_standards_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [cholesterol_standards!]!
}

"""
on_conflict condition type for table "cholesterol_standards"
"""
input cholesterol_standards_on_conflict {
  constraint: cholesterol_standards_constraint!
  update_columns: [cholesterol_standards_update_column!]! = []
  where: cholesterol_standards_bool_exp
}

"""Ordering options when selecting data from "cholesterol_standards"."""
input cholesterol_standards_order_by {
  diastolic_pressure: order_by
  enabled: order_by
  id: order_by
  systolic_pressure: order_by
}

"""primary key columns input for table: cholesterol_standards"""
input cholesterol_standards_pk_columns_input {
  id: uuid!
}

"""
select columns of table "cholesterol_standards"
"""
enum cholesterol_standards_select_column {
  """column name"""
  diastolic_pressure

  """column name"""
  enabled

  """column name"""
  id

  """column name"""
  systolic_pressure
}

"""
input type for updating data in table "cholesterol_standards"
"""
input cholesterol_standards_set_input {
  diastolic_pressure: numeric
  enabled: Boolean
  id: uuid
  systolic_pressure: numeric
}

"""aggregate stddev on columns"""
type cholesterol_standards_stddev_fields {
  diastolic_pressure: Float
  systolic_pressure: Float
}

"""aggregate stddev_pop on columns"""
type cholesterol_standards_stddev_pop_fields {
  diastolic_pressure: Float
  systolic_pressure: Float
}

"""aggregate stddev_samp on columns"""
type cholesterol_standards_stddev_samp_fields {
  diastolic_pressure: Float
  systolic_pressure: Float
}

"""
Streaming cursor of the table "cholesterol_standards"
"""
input cholesterol_standards_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: cholesterol_standards_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input cholesterol_standards_stream_cursor_value_input {
  diastolic_pressure: numeric
  enabled: Boolean
  id: uuid
  systolic_pressure: numeric
}

"""aggregate sum on columns"""
type cholesterol_standards_sum_fields {
  diastolic_pressure: numeric
  systolic_pressure: numeric
}

"""
update columns of table "cholesterol_standards"
"""
enum cholesterol_standards_update_column {
  """column name"""
  diastolic_pressure

  """column name"""
  enabled

  """column name"""
  id

  """column name"""
  systolic_pressure
}

input cholesterol_standards_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: cholesterol_standards_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: cholesterol_standards_set_input

  """filter the rows which have to be updated"""
  where: cholesterol_standards_bool_exp!
}

"""aggregate var_pop on columns"""
type cholesterol_standards_var_pop_fields {
  diastolic_pressure: Float
  systolic_pressure: Float
}

"""aggregate var_samp on columns"""
type cholesterol_standards_var_samp_fields {
  diastolic_pressure: Float
  systolic_pressure: Float
}

"""aggregate variance on columns"""
type cholesterol_standards_variance_fields {
  diastolic_pressure: Float
  systolic_pressure: Float
}

"""
columns and relationships of "connectors"
"""
type connectors {
  config(
    """JSON select path"""
    path: String
  ): jsonb!
  connector_id: String!
  created_at: timestamptz!
  id: String!
  metadata(
    """JSON select path"""
    path: String
  ): jsonb!
  sync_profile: Boolean!
  tenant_id: String!
}

"""
aggregated selection of "connectors"
"""
type connectors_aggregate {
  aggregate: connectors_aggregate_fields
  nodes: [connectors!]!
}

"""
aggregate fields of "connectors"
"""
type connectors_aggregate_fields {
  count(columns: [connectors_select_column!], distinct: Boolean): Int!
  max: connectors_max_fields
  min: connectors_min_fields
}

"""append existing jsonb value of filtered columns with new jsonb value"""
input connectors_append_input {
  config: jsonb
  metadata: jsonb
}

"""
Boolean expression to filter rows from the table "connectors". All fields are combined with a logical 'AND'.
"""
input connectors_bool_exp {
  _and: [connectors_bool_exp!]
  _not: connectors_bool_exp
  _or: [connectors_bool_exp!]
  config: jsonb_comparison_exp
  connector_id: String_comparison_exp
  created_at: timestamptz_comparison_exp
  id: String_comparison_exp
  metadata: jsonb_comparison_exp
  sync_profile: Boolean_comparison_exp
  tenant_id: String_comparison_exp
}

"""
unique or primary key constraints on table "connectors"
"""
enum connectors_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  connectors_pkey
}

"""
delete the field or element with specified path (for JSON arrays, negative integers count from the end)
"""
input connectors_delete_at_path_input {
  config: [String!]
  metadata: [String!]
}

"""
delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
"""
input connectors_delete_elem_input {
  config: Int
  metadata: Int
}

"""
delete key/value pair or string element. key/value pairs are matched based on their key value
"""
input connectors_delete_key_input {
  config: String
  metadata: String
}

"""
input type for inserting data into table "connectors"
"""
input connectors_insert_input {
  config: jsonb
  connector_id: String
  created_at: timestamptz
  id: String
  metadata: jsonb
  sync_profile: Boolean
  tenant_id: String
}

"""aggregate max on columns"""
type connectors_max_fields {
  connector_id: String
  created_at: timestamptz
  id: String
  tenant_id: String
}

"""aggregate min on columns"""
type connectors_min_fields {
  connector_id: String
  created_at: timestamptz
  id: String
  tenant_id: String
}

"""
response of any mutation on the table "connectors"
"""
type connectors_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [connectors!]!
}

"""
on_conflict condition type for table "connectors"
"""
input connectors_on_conflict {
  constraint: connectors_constraint!
  update_columns: [connectors_update_column!]! = []
  where: connectors_bool_exp
}

"""Ordering options when selecting data from "connectors"."""
input connectors_order_by {
  config: order_by
  connector_id: order_by
  created_at: order_by
  id: order_by
  metadata: order_by
  sync_profile: order_by
  tenant_id: order_by
}

"""primary key columns input for table: connectors"""
input connectors_pk_columns_input {
  id: String!
}

"""prepend existing jsonb value of filtered columns with new jsonb value"""
input connectors_prepend_input {
  config: jsonb
  metadata: jsonb
}

"""
select columns of table "connectors"
"""
enum connectors_select_column {
  """column name"""
  config

  """column name"""
  connector_id

  """column name"""
  created_at

  """column name"""
  id

  """column name"""
  metadata

  """column name"""
  sync_profile

  """column name"""
  tenant_id
}

"""
input type for updating data in table "connectors"
"""
input connectors_set_input {
  config: jsonb
  connector_id: String
  created_at: timestamptz
  id: String
  metadata: jsonb
  sync_profile: Boolean
  tenant_id: String
}

"""
Streaming cursor of the table "connectors"
"""
input connectors_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: connectors_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input connectors_stream_cursor_value_input {
  config: jsonb
  connector_id: String
  created_at: timestamptz
  id: String
  metadata: jsonb
  sync_profile: Boolean
  tenant_id: String
}

"""
update columns of table "connectors"
"""
enum connectors_update_column {
  """column name"""
  config

  """column name"""
  connector_id

  """column name"""
  created_at

  """column name"""
  id

  """column name"""
  metadata

  """column name"""
  sync_profile

  """column name"""
  tenant_id
}

input connectors_updates {
  """append existing jsonb value of filtered columns with new jsonb value"""
  _append: connectors_append_input

  """
  delete the field or element with specified path (for JSON arrays, negative integers count from the end)
  """
  _delete_at_path: connectors_delete_at_path_input

  """
  delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
  """
  _delete_elem: connectors_delete_elem_input

  """
  delete key/value pair or string element. key/value pairs are matched based on their key value
  """
  _delete_key: connectors_delete_key_input

  """prepend existing jsonb value of filtered columns with new jsonb value"""
  _prepend: connectors_prepend_input

  """sets the columns of the filtered rows to the given values"""
  _set: connectors_set_input

  """filter the rows which have to be updated"""
  where: connectors_bool_exp!
}

"""ordering argument of a cursor"""
enum cursor_ordering {
  """ascending ordering of the cursor"""
  ASC

  """descending ordering of the cursor"""
  DESC
}

"""
columns and relationships of "custom_phrases"
"""
type custom_phrases {
  id: String!
  language_tag: String!
  tenant_id: String!
  translation(
    """JSON select path"""
    path: String
  ): jsonb!
}

"""
aggregated selection of "custom_phrases"
"""
type custom_phrases_aggregate {
  aggregate: custom_phrases_aggregate_fields
  nodes: [custom_phrases!]!
}

"""
aggregate fields of "custom_phrases"
"""
type custom_phrases_aggregate_fields {
  count(columns: [custom_phrases_select_column!], distinct: Boolean): Int!
  max: custom_phrases_max_fields
  min: custom_phrases_min_fields
}

"""append existing jsonb value of filtered columns with new jsonb value"""
input custom_phrases_append_input {
  translation: jsonb
}

"""
Boolean expression to filter rows from the table "custom_phrases". All fields are combined with a logical 'AND'.
"""
input custom_phrases_bool_exp {
  _and: [custom_phrases_bool_exp!]
  _not: custom_phrases_bool_exp
  _or: [custom_phrases_bool_exp!]
  id: String_comparison_exp
  language_tag: String_comparison_exp
  tenant_id: String_comparison_exp
  translation: jsonb_comparison_exp
}

"""
unique or primary key constraints on table "custom_phrases"
"""
enum custom_phrases_constraint {
  """
  unique or primary key constraint on columns "language_tag", "tenant_id"
  """
  custom_phrases__language_tag

  """
  unique or primary key constraint on columns "id"
  """
  custom_phrases_pkey
}

"""
delete the field or element with specified path (for JSON arrays, negative integers count from the end)
"""
input custom_phrases_delete_at_path_input {
  translation: [String!]
}

"""
delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
"""
input custom_phrases_delete_elem_input {
  translation: Int
}

"""
delete key/value pair or string element. key/value pairs are matched based on their key value
"""
input custom_phrases_delete_key_input {
  translation: String
}

"""
input type for inserting data into table "custom_phrases"
"""
input custom_phrases_insert_input {
  id: String
  language_tag: String
  tenant_id: String
  translation: jsonb
}

"""aggregate max on columns"""
type custom_phrases_max_fields {
  id: String
  language_tag: String
  tenant_id: String
}

"""aggregate min on columns"""
type custom_phrases_min_fields {
  id: String
  language_tag: String
  tenant_id: String
}

"""
response of any mutation on the table "custom_phrases"
"""
type custom_phrases_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [custom_phrases!]!
}

"""
on_conflict condition type for table "custom_phrases"
"""
input custom_phrases_on_conflict {
  constraint: custom_phrases_constraint!
  update_columns: [custom_phrases_update_column!]! = []
  where: custom_phrases_bool_exp
}

"""Ordering options when selecting data from "custom_phrases"."""
input custom_phrases_order_by {
  id: order_by
  language_tag: order_by
  tenant_id: order_by
  translation: order_by
}

"""primary key columns input for table: custom_phrases"""
input custom_phrases_pk_columns_input {
  id: String!
}

"""prepend existing jsonb value of filtered columns with new jsonb value"""
input custom_phrases_prepend_input {
  translation: jsonb
}

"""
select columns of table "custom_phrases"
"""
enum custom_phrases_select_column {
  """column name"""
  id

  """column name"""
  language_tag

  """column name"""
  tenant_id

  """column name"""
  translation
}

"""
input type for updating data in table "custom_phrases"
"""
input custom_phrases_set_input {
  id: String
  language_tag: String
  tenant_id: String
  translation: jsonb
}

"""
Streaming cursor of the table "custom_phrases"
"""
input custom_phrases_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: custom_phrases_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input custom_phrases_stream_cursor_value_input {
  id: String
  language_tag: String
  tenant_id: String
  translation: jsonb
}

"""
update columns of table "custom_phrases"
"""
enum custom_phrases_update_column {
  """column name"""
  id

  """column name"""
  language_tag

  """column name"""
  tenant_id

  """column name"""
  translation
}

input custom_phrases_updates {
  """append existing jsonb value of filtered columns with new jsonb value"""
  _append: custom_phrases_append_input

  """
  delete the field or element with specified path (for JSON arrays, negative integers count from the end)
  """
  _delete_at_path: custom_phrases_delete_at_path_input

  """
  delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
  """
  _delete_elem: custom_phrases_delete_elem_input

  """
  delete key/value pair or string element. key/value pairs are matched based on their key value
  """
  _delete_key: custom_phrases_delete_key_input

  """prepend existing jsonb value of filtered columns with new jsonb value"""
  _prepend: custom_phrases_prepend_input

  """sets the columns of the filtered rows to the given values"""
  _set: custom_phrases_set_input

  """filter the rows which have to be updated"""
  where: custom_phrases_bool_exp!
}

"""
columns and relationships of "daily_active_users"
"""
type daily_active_users {
  date: timestamptz!
  id: String!
  tenant_id: String!
  user_id: String!
}

"""
aggregated selection of "daily_active_users"
"""
type daily_active_users_aggregate {
  aggregate: daily_active_users_aggregate_fields
  nodes: [daily_active_users!]!
}

"""
aggregate fields of "daily_active_users"
"""
type daily_active_users_aggregate_fields {
  count(columns: [daily_active_users_select_column!], distinct: Boolean): Int!
  max: daily_active_users_max_fields
  min: daily_active_users_min_fields
}

"""
Boolean expression to filter rows from the table "daily_active_users". All fields are combined with a logical 'AND'.
"""
input daily_active_users_bool_exp {
  _and: [daily_active_users_bool_exp!]
  _not: daily_active_users_bool_exp
  _or: [daily_active_users_bool_exp!]
  date: timestamptz_comparison_exp
  id: String_comparison_exp
  tenant_id: String_comparison_exp
  user_id: String_comparison_exp
}

"""
unique or primary key constraints on table "daily_active_users"
"""
enum daily_active_users_constraint {
  """
  unique or primary key constraint on columns "user_id", "date"
  """
  daily_active_users__user_id_date

  """
  unique or primary key constraint on columns "id"
  """
  daily_active_users_pkey
}

"""
input type for inserting data into table "daily_active_users"
"""
input daily_active_users_insert_input {
  date: timestamptz
  id: String
  tenant_id: String
  user_id: String
}

"""aggregate max on columns"""
type daily_active_users_max_fields {
  date: timestamptz
  id: String
  tenant_id: String
  user_id: String
}

"""aggregate min on columns"""
type daily_active_users_min_fields {
  date: timestamptz
  id: String
  tenant_id: String
  user_id: String
}

"""
response of any mutation on the table "daily_active_users"
"""
type daily_active_users_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [daily_active_users!]!
}

"""
on_conflict condition type for table "daily_active_users"
"""
input daily_active_users_on_conflict {
  constraint: daily_active_users_constraint!
  update_columns: [daily_active_users_update_column!]! = []
  where: daily_active_users_bool_exp
}

"""Ordering options when selecting data from "daily_active_users"."""
input daily_active_users_order_by {
  date: order_by
  id: order_by
  tenant_id: order_by
  user_id: order_by
}

"""primary key columns input for table: daily_active_users"""
input daily_active_users_pk_columns_input {
  id: String!
}

"""
select columns of table "daily_active_users"
"""
enum daily_active_users_select_column {
  """column name"""
  date

  """column name"""
  id

  """column name"""
  tenant_id

  """column name"""
  user_id
}

"""
input type for updating data in table "daily_active_users"
"""
input daily_active_users_set_input {
  date: timestamptz
  id: String
  tenant_id: String
  user_id: String
}

"""
Streaming cursor of the table "daily_active_users"
"""
input daily_active_users_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: daily_active_users_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input daily_active_users_stream_cursor_value_input {
  date: timestamptz
  id: String
  tenant_id: String
  user_id: String
}

"""
update columns of table "daily_active_users"
"""
enum daily_active_users_update_column {
  """column name"""
  date

  """column name"""
  id

  """column name"""
  tenant_id

  """column name"""
  user_id
}

input daily_active_users_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: daily_active_users_set_input

  """filter the rows which have to be updated"""
  where: daily_active_users_bool_exp!
}

"""
columns and relationships of "daily_token_usage"
"""
type daily_token_usage {
  date: timestamptz!
  id: String!
  tenant_id: String!
  usage: bigint!
}

"""
aggregated selection of "daily_token_usage"
"""
type daily_token_usage_aggregate {
  aggregate: daily_token_usage_aggregate_fields
  nodes: [daily_token_usage!]!
}

"""
aggregate fields of "daily_token_usage"
"""
type daily_token_usage_aggregate_fields {
  avg: daily_token_usage_avg_fields
  count(columns: [daily_token_usage_select_column!], distinct: Boolean): Int!
  max: daily_token_usage_max_fields
  min: daily_token_usage_min_fields
  stddev: daily_token_usage_stddev_fields
  stddev_pop: daily_token_usage_stddev_pop_fields
  stddev_samp: daily_token_usage_stddev_samp_fields
  sum: daily_token_usage_sum_fields
  var_pop: daily_token_usage_var_pop_fields
  var_samp: daily_token_usage_var_samp_fields
  variance: daily_token_usage_variance_fields
}

"""aggregate avg on columns"""
type daily_token_usage_avg_fields {
  usage: Float
}

"""
Boolean expression to filter rows from the table "daily_token_usage". All fields are combined with a logical 'AND'.
"""
input daily_token_usage_bool_exp {
  _and: [daily_token_usage_bool_exp!]
  _not: daily_token_usage_bool_exp
  _or: [daily_token_usage_bool_exp!]
  date: timestamptz_comparison_exp
  id: String_comparison_exp
  tenant_id: String_comparison_exp
  usage: bigint_comparison_exp
}

"""
unique or primary key constraints on table "daily_token_usage"
"""
enum daily_token_usage_constraint {
  """
  unique or primary key constraint on columns "date", "tenant_id"
  """
  daily_token_usage__date

  """
  unique or primary key constraint on columns "id"
  """
  daily_token_usage_pkey
}

"""
input type for incrementing numeric columns in table "daily_token_usage"
"""
input daily_token_usage_inc_input {
  usage: bigint
}

"""
input type for inserting data into table "daily_token_usage"
"""
input daily_token_usage_insert_input {
  date: timestamptz
  id: String
  tenant_id: String
  usage: bigint
}

"""aggregate max on columns"""
type daily_token_usage_max_fields {
  date: timestamptz
  id: String
  tenant_id: String
  usage: bigint
}

"""aggregate min on columns"""
type daily_token_usage_min_fields {
  date: timestamptz
  id: String
  tenant_id: String
  usage: bigint
}

"""
response of any mutation on the table "daily_token_usage"
"""
type daily_token_usage_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [daily_token_usage!]!
}

"""
on_conflict condition type for table "daily_token_usage"
"""
input daily_token_usage_on_conflict {
  constraint: daily_token_usage_constraint!
  update_columns: [daily_token_usage_update_column!]! = []
  where: daily_token_usage_bool_exp
}

"""Ordering options when selecting data from "daily_token_usage"."""
input daily_token_usage_order_by {
  date: order_by
  id: order_by
  tenant_id: order_by
  usage: order_by
}

"""primary key columns input for table: daily_token_usage"""
input daily_token_usage_pk_columns_input {
  id: String!
}

"""
select columns of table "daily_token_usage"
"""
enum daily_token_usage_select_column {
  """column name"""
  date

  """column name"""
  id

  """column name"""
  tenant_id

  """column name"""
  usage
}

"""
input type for updating data in table "daily_token_usage"
"""
input daily_token_usage_set_input {
  date: timestamptz
  id: String
  tenant_id: String
  usage: bigint
}

"""aggregate stddev on columns"""
type daily_token_usage_stddev_fields {
  usage: Float
}

"""aggregate stddev_pop on columns"""
type daily_token_usage_stddev_pop_fields {
  usage: Float
}

"""aggregate stddev_samp on columns"""
type daily_token_usage_stddev_samp_fields {
  usage: Float
}

"""
Streaming cursor of the table "daily_token_usage"
"""
input daily_token_usage_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: daily_token_usage_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input daily_token_usage_stream_cursor_value_input {
  date: timestamptz
  id: String
  tenant_id: String
  usage: bigint
}

"""aggregate sum on columns"""
type daily_token_usage_sum_fields {
  usage: bigint
}

"""
update columns of table "daily_token_usage"
"""
enum daily_token_usage_update_column {
  """column name"""
  date

  """column name"""
  id

  """column name"""
  tenant_id

  """column name"""
  usage
}

input daily_token_usage_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: daily_token_usage_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: daily_token_usage_set_input

  """filter the rows which have to be updated"""
  where: daily_token_usage_bool_exp!
}

"""aggregate var_pop on columns"""
type daily_token_usage_var_pop_fields {
  usage: Float
}

"""aggregate var_samp on columns"""
type daily_token_usage_var_samp_fields {
  usage: Float
}

"""aggregate variance on columns"""
type daily_token_usage_variance_fields {
  usage: Float
}

scalar date

"""
Boolean expression to compare columns of type "date". All fields are combined with logical 'AND'.
"""
input date_comparison_exp {
  _eq: date
  _gt: date
  _gte: date
  _in: [date!]
  _is_null: Boolean
  _lt: date
  _lte: date
  _neq: date
  _nin: [date!]
}

"""
columns and relationships of "domains"
"""
type domains {
  cloudflare_data(
    """JSON select path"""
    path: String
  ): jsonb
  created_at: timestamptz!
  dns_records(
    """JSON select path"""
    path: String
  ): jsonb!
  domain: String!
  error_message: String
  id: String!
  status: String!
  tenant_id: String!
  updated_at: timestamptz!
}

"""
aggregated selection of "domains"
"""
type domains_aggregate {
  aggregate: domains_aggregate_fields
  nodes: [domains!]!
}

"""
aggregate fields of "domains"
"""
type domains_aggregate_fields {
  count(columns: [domains_select_column!], distinct: Boolean): Int!
  max: domains_max_fields
  min: domains_min_fields
}

"""append existing jsonb value of filtered columns with new jsonb value"""
input domains_append_input {
  cloudflare_data: jsonb
  dns_records: jsonb
}

"""
Boolean expression to filter rows from the table "domains". All fields are combined with a logical 'AND'.
"""
input domains_bool_exp {
  _and: [domains_bool_exp!]
  _not: domains_bool_exp
  _or: [domains_bool_exp!]
  cloudflare_data: jsonb_comparison_exp
  created_at: timestamptz_comparison_exp
  dns_records: jsonb_comparison_exp
  domain: String_comparison_exp
  error_message: String_comparison_exp
  id: String_comparison_exp
  status: String_comparison_exp
  tenant_id: String_comparison_exp
  updated_at: timestamptz_comparison_exp
}

"""
unique or primary key constraints on table "domains"
"""
enum domains_constraint {
  """
  unique or primary key constraint on columns "domain", "tenant_id"
  """
  domains__domain

  """
  unique or primary key constraint on columns "id"
  """
  domains_pkey
}

"""
delete the field or element with specified path (for JSON arrays, negative integers count from the end)
"""
input domains_delete_at_path_input {
  cloudflare_data: [String!]
  dns_records: [String!]
}

"""
delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
"""
input domains_delete_elem_input {
  cloudflare_data: Int
  dns_records: Int
}

"""
delete key/value pair or string element. key/value pairs are matched based on their key value
"""
input domains_delete_key_input {
  cloudflare_data: String
  dns_records: String
}

"""
input type for inserting data into table "domains"
"""
input domains_insert_input {
  cloudflare_data: jsonb
  created_at: timestamptz
  dns_records: jsonb
  domain: String
  error_message: String
  id: String
  status: String
  tenant_id: String
  updated_at: timestamptz
}

"""aggregate max on columns"""
type domains_max_fields {
  created_at: timestamptz
  domain: String
  error_message: String
  id: String
  status: String
  tenant_id: String
  updated_at: timestamptz
}

"""aggregate min on columns"""
type domains_min_fields {
  created_at: timestamptz
  domain: String
  error_message: String
  id: String
  status: String
  tenant_id: String
  updated_at: timestamptz
}

"""
response of any mutation on the table "domains"
"""
type domains_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [domains!]!
}

"""
on_conflict condition type for table "domains"
"""
input domains_on_conflict {
  constraint: domains_constraint!
  update_columns: [domains_update_column!]! = []
  where: domains_bool_exp
}

"""Ordering options when selecting data from "domains"."""
input domains_order_by {
  cloudflare_data: order_by
  created_at: order_by
  dns_records: order_by
  domain: order_by
  error_message: order_by
  id: order_by
  status: order_by
  tenant_id: order_by
  updated_at: order_by
}

"""primary key columns input for table: domains"""
input domains_pk_columns_input {
  id: String!
}

"""prepend existing jsonb value of filtered columns with new jsonb value"""
input domains_prepend_input {
  cloudflare_data: jsonb
  dns_records: jsonb
}

"""
select columns of table "domains"
"""
enum domains_select_column {
  """column name"""
  cloudflare_data

  """column name"""
  created_at

  """column name"""
  dns_records

  """column name"""
  domain

  """column name"""
  error_message

  """column name"""
  id

  """column name"""
  status

  """column name"""
  tenant_id

  """column name"""
  updated_at
}

"""
input type for updating data in table "domains"
"""
input domains_set_input {
  cloudflare_data: jsonb
  created_at: timestamptz
  dns_records: jsonb
  domain: String
  error_message: String
  id: String
  status: String
  tenant_id: String
  updated_at: timestamptz
}

"""
Streaming cursor of the table "domains"
"""
input domains_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: domains_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input domains_stream_cursor_value_input {
  cloudflare_data: jsonb
  created_at: timestamptz
  dns_records: jsonb
  domain: String
  error_message: String
  id: String
  status: String
  tenant_id: String
  updated_at: timestamptz
}

"""
update columns of table "domains"
"""
enum domains_update_column {
  """column name"""
  cloudflare_data

  """column name"""
  created_at

  """column name"""
  dns_records

  """column name"""
  domain

  """column name"""
  error_message

  """column name"""
  id

  """column name"""
  status

  """column name"""
  tenant_id

  """column name"""
  updated_at
}

input domains_updates {
  """append existing jsonb value of filtered columns with new jsonb value"""
  _append: domains_append_input

  """
  delete the field or element with specified path (for JSON arrays, negative integers count from the end)
  """
  _delete_at_path: domains_delete_at_path_input

  """
  delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
  """
  _delete_elem: domains_delete_elem_input

  """
  delete key/value pair or string element. key/value pairs are matched based on their key value
  """
  _delete_key: domains_delete_key_input

  """prepend existing jsonb value of filtered columns with new jsonb value"""
  _prepend: domains_prepend_input

  """sets the columns of the filtered rows to the given values"""
  _set: domains_set_input

  """filter the rows which have to be updated"""
  where: domains_bool_exp!
}

scalar float8

"""
Boolean expression to compare columns of type "float8". All fields are combined with logical 'AND'.
"""
input float8_comparison_exp {
  _eq: float8
  _gt: float8
  _gte: float8
  _in: [float8!]
  _is_null: Boolean
  _lt: float8
  _lte: float8
  _neq: float8
  _nin: [float8!]
}

"""血糖记录表"""
type glucose_records {
  created_at: timestamptz!

  """饮食记录"""
  diet_record: String

  """运动记录"""
  exercise_record: String

  """血糖值"""
  glucose_value: numeric!
  id: uuid!

  """
  A computed field, executes function "calculate_glucose_exception"
  """
  is_exception: Boolean

  """血糖测量时段，1：早餐前、2：早餐后、3：午餐前、4：午餐后、5：晚餐前、6：晚餐后、7：其他"""
  measurement_period: Int!

  """用药记录"""
  medication_record: String
  record_time: timestamptz!
  remarks: String

  """
  A computed field, executes function "calculate_glucose_exception_too_large"
  """
  too_large: Boolean

  """
  A computed field, executes function "calculate_glucose_exception_too_small"
  """
  too_small: Boolean
  updated_at: timestamptz!
  user_id: String!
}

"""
aggregated selection of "glucose_records"
"""
type glucose_records_aggregate {
  aggregate: glucose_records_aggregate_fields
  nodes: [glucose_records!]!
}

"""
aggregate fields of "glucose_records"
"""
type glucose_records_aggregate_fields {
  avg: glucose_records_avg_fields
  count(columns: [glucose_records_select_column!], distinct: Boolean): Int!
  max: glucose_records_max_fields
  min: glucose_records_min_fields
  stddev: glucose_records_stddev_fields
  stddev_pop: glucose_records_stddev_pop_fields
  stddev_samp: glucose_records_stddev_samp_fields
  sum: glucose_records_sum_fields
  var_pop: glucose_records_var_pop_fields
  var_samp: glucose_records_var_samp_fields
  variance: glucose_records_variance_fields
}

"""aggregate avg on columns"""
type glucose_records_avg_fields {
  """血糖值"""
  glucose_value: Float

  """血糖测量时段，1：早餐前、2：早餐后、3：午餐前、4：午餐后、5：晚餐前、6：晚餐后、7：其他"""
  measurement_period: Float
}

"""
Boolean expression to filter rows from the table "glucose_records". All fields are combined with a logical 'AND'.
"""
input glucose_records_bool_exp {
  _and: [glucose_records_bool_exp!]
  _not: glucose_records_bool_exp
  _or: [glucose_records_bool_exp!]
  created_at: timestamptz_comparison_exp
  diet_record: String_comparison_exp
  exercise_record: String_comparison_exp
  glucose_value: numeric_comparison_exp
  id: uuid_comparison_exp
  is_exception: Boolean_comparison_exp
  measurement_period: Int_comparison_exp
  medication_record: String_comparison_exp
  record_time: timestamptz_comparison_exp
  remarks: String_comparison_exp
  too_large: Boolean_comparison_exp
  too_small: Boolean_comparison_exp
  updated_at: timestamptz_comparison_exp
  user_id: String_comparison_exp
}

"""
unique or primary key constraints on table "glucose_records"
"""
enum glucose_records_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  glucose_records_pkey
}

"""
input type for incrementing numeric columns in table "glucose_records"
"""
input glucose_records_inc_input {
  """血糖值"""
  glucose_value: numeric

  """血糖测量时段，1：早餐前、2：早餐后、3：午餐前、4：午餐后、5：晚餐前、6：晚餐后、7：其他"""
  measurement_period: Int
}

"""
input type for inserting data into table "glucose_records"
"""
input glucose_records_insert_input {
  created_at: timestamptz

  """饮食记录"""
  diet_record: String

  """运动记录"""
  exercise_record: String

  """血糖值"""
  glucose_value: numeric
  id: uuid

  """血糖测量时段，1：早餐前、2：早餐后、3：午餐前、4：午餐后、5：晚餐前、6：晚餐后、7：其他"""
  measurement_period: Int

  """用药记录"""
  medication_record: String
  record_time: timestamptz
  remarks: String
  updated_at: timestamptz
  user_id: String
}

"""aggregate max on columns"""
type glucose_records_max_fields {
  created_at: timestamptz

  """饮食记录"""
  diet_record: String

  """运动记录"""
  exercise_record: String

  """血糖值"""
  glucose_value: numeric
  id: uuid

  """血糖测量时段，1：早餐前、2：早餐后、3：午餐前、4：午餐后、5：晚餐前、6：晚餐后、7：其他"""
  measurement_period: Int

  """用药记录"""
  medication_record: String
  record_time: timestamptz
  remarks: String
  updated_at: timestamptz
  user_id: String
}

"""aggregate min on columns"""
type glucose_records_min_fields {
  created_at: timestamptz

  """饮食记录"""
  diet_record: String

  """运动记录"""
  exercise_record: String

  """血糖值"""
  glucose_value: numeric
  id: uuid

  """血糖测量时段，1：早餐前、2：早餐后、3：午餐前、4：午餐后、5：晚餐前、6：晚餐后、7：其他"""
  measurement_period: Int

  """用药记录"""
  medication_record: String
  record_time: timestamptz
  remarks: String
  updated_at: timestamptz
  user_id: String
}

"""
response of any mutation on the table "glucose_records"
"""
type glucose_records_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [glucose_records!]!
}

"""
on_conflict condition type for table "glucose_records"
"""
input glucose_records_on_conflict {
  constraint: glucose_records_constraint!
  update_columns: [glucose_records_update_column!]! = []
  where: glucose_records_bool_exp
}

"""Ordering options when selecting data from "glucose_records"."""
input glucose_records_order_by {
  created_at: order_by
  diet_record: order_by
  exercise_record: order_by
  glucose_value: order_by
  id: order_by
  is_exception: order_by
  measurement_period: order_by
  medication_record: order_by
  record_time: order_by
  remarks: order_by
  too_large: order_by
  too_small: order_by
  updated_at: order_by
  user_id: order_by
}

"""primary key columns input for table: glucose_records"""
input glucose_records_pk_columns_input {
  id: uuid!
}

"""
select columns of table "glucose_records"
"""
enum glucose_records_select_column {
  """column name"""
  created_at

  """column name"""
  diet_record

  """column name"""
  exercise_record

  """column name"""
  glucose_value

  """column name"""
  id

  """column name"""
  measurement_period

  """column name"""
  medication_record

  """column name"""
  record_time

  """column name"""
  remarks

  """column name"""
  updated_at

  """column name"""
  user_id
}

"""
input type for updating data in table "glucose_records"
"""
input glucose_records_set_input {
  created_at: timestamptz

  """饮食记录"""
  diet_record: String

  """运动记录"""
  exercise_record: String

  """血糖值"""
  glucose_value: numeric
  id: uuid

  """血糖测量时段，1：早餐前、2：早餐后、3：午餐前、4：午餐后、5：晚餐前、6：晚餐后、7：其他"""
  measurement_period: Int

  """用药记录"""
  medication_record: String
  record_time: timestamptz
  remarks: String
  updated_at: timestamptz
  user_id: String
}

"""aggregate stddev on columns"""
type glucose_records_stddev_fields {
  """血糖值"""
  glucose_value: Float

  """血糖测量时段，1：早餐前、2：早餐后、3：午餐前、4：午餐后、5：晚餐前、6：晚餐后、7：其他"""
  measurement_period: Float
}

"""aggregate stddev_pop on columns"""
type glucose_records_stddev_pop_fields {
  """血糖值"""
  glucose_value: Float

  """血糖测量时段，1：早餐前、2：早餐后、3：午餐前、4：午餐后、5：晚餐前、6：晚餐后、7：其他"""
  measurement_period: Float
}

"""aggregate stddev_samp on columns"""
type glucose_records_stddev_samp_fields {
  """血糖值"""
  glucose_value: Float

  """血糖测量时段，1：早餐前、2：早餐后、3：午餐前、4：午餐后、5：晚餐前、6：晚餐后、7：其他"""
  measurement_period: Float
}

"""
Streaming cursor of the table "glucose_records"
"""
input glucose_records_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: glucose_records_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input glucose_records_stream_cursor_value_input {
  created_at: timestamptz

  """饮食记录"""
  diet_record: String

  """运动记录"""
  exercise_record: String

  """血糖值"""
  glucose_value: numeric
  id: uuid

  """血糖测量时段，1：早餐前、2：早餐后、3：午餐前、4：午餐后、5：晚餐前、6：晚餐后、7：其他"""
  measurement_period: Int

  """用药记录"""
  medication_record: String
  record_time: timestamptz
  remarks: String
  updated_at: timestamptz
  user_id: String
}

"""aggregate sum on columns"""
type glucose_records_sum_fields {
  """血糖值"""
  glucose_value: numeric

  """血糖测量时段，1：早餐前、2：早餐后、3：午餐前、4：午餐后、5：晚餐前、6：晚餐后、7：其他"""
  measurement_period: Int
}

"""
update columns of table "glucose_records"
"""
enum glucose_records_update_column {
  """column name"""
  created_at

  """column name"""
  diet_record

  """column name"""
  exercise_record

  """column name"""
  glucose_value

  """column name"""
  id

  """column name"""
  measurement_period

  """column name"""
  medication_record

  """column name"""
  record_time

  """column name"""
  remarks

  """column name"""
  updated_at

  """column name"""
  user_id
}

input glucose_records_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: glucose_records_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: glucose_records_set_input

  """filter the rows which have to be updated"""
  where: glucose_records_bool_exp!
}

"""aggregate var_pop on columns"""
type glucose_records_var_pop_fields {
  """血糖值"""
  glucose_value: Float

  """血糖测量时段，1：早餐前、2：早餐后、3：午餐前、4：午餐后、5：晚餐前、6：晚餐后、7：其他"""
  measurement_period: Float
}

"""aggregate var_samp on columns"""
type glucose_records_var_samp_fields {
  """血糖值"""
  glucose_value: Float

  """血糖测量时段，1：早餐前、2：早餐后、3：午餐前、4：午餐后、5：晚餐前、6：晚餐后、7：其他"""
  measurement_period: Float
}

"""aggregate variance on columns"""
type glucose_records_variance_fields {
  """血糖值"""
  glucose_value: Float

  """血糖测量时段，1：早餐前、2：早餐后、3：午餐前、4：午餐后、5：晚餐前、6：晚餐后、7：其他"""
  measurement_period: Float
}

"""血糖标准表"""
type glucose_standards {
  id: uuid!
  max: numeric!
  min: numeric!
  title: String!
  type: Int!
}

"""
aggregated selection of "glucose_standards"
"""
type glucose_standards_aggregate {
  aggregate: glucose_standards_aggregate_fields
  nodes: [glucose_standards!]!
}

"""
aggregate fields of "glucose_standards"
"""
type glucose_standards_aggregate_fields {
  avg: glucose_standards_avg_fields
  count(columns: [glucose_standards_select_column!], distinct: Boolean): Int!
  max: glucose_standards_max_fields
  min: glucose_standards_min_fields
  stddev: glucose_standards_stddev_fields
  stddev_pop: glucose_standards_stddev_pop_fields
  stddev_samp: glucose_standards_stddev_samp_fields
  sum: glucose_standards_sum_fields
  var_pop: glucose_standards_var_pop_fields
  var_samp: glucose_standards_var_samp_fields
  variance: glucose_standards_variance_fields
}

"""aggregate avg on columns"""
type glucose_standards_avg_fields {
  max: Float
  min: Float
  type: Float
}

"""
Boolean expression to filter rows from the table "glucose_standards". All fields are combined with a logical 'AND'.
"""
input glucose_standards_bool_exp {
  _and: [glucose_standards_bool_exp!]
  _not: glucose_standards_bool_exp
  _or: [glucose_standards_bool_exp!]
  id: uuid_comparison_exp
  max: numeric_comparison_exp
  min: numeric_comparison_exp
  title: String_comparison_exp
  type: Int_comparison_exp
}

"""
unique or primary key constraints on table "glucose_standards"
"""
enum glucose_standards_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  glucose_standards_pkey
}

"""
input type for incrementing numeric columns in table "glucose_standards"
"""
input glucose_standards_inc_input {
  max: numeric
  min: numeric
  type: Int
}

"""
input type for inserting data into table "glucose_standards"
"""
input glucose_standards_insert_input {
  id: uuid
  max: numeric
  min: numeric
  title: String
  type: Int
}

"""aggregate max on columns"""
type glucose_standards_max_fields {
  id: uuid
  max: numeric
  min: numeric
  title: String
  type: Int
}

"""aggregate min on columns"""
type glucose_standards_min_fields {
  id: uuid
  max: numeric
  min: numeric
  title: String
  type: Int
}

"""
response of any mutation on the table "glucose_standards"
"""
type glucose_standards_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [glucose_standards!]!
}

"""
on_conflict condition type for table "glucose_standards"
"""
input glucose_standards_on_conflict {
  constraint: glucose_standards_constraint!
  update_columns: [glucose_standards_update_column!]! = []
  where: glucose_standards_bool_exp
}

"""Ordering options when selecting data from "glucose_standards"."""
input glucose_standards_order_by {
  id: order_by
  max: order_by
  min: order_by
  title: order_by
  type: order_by
}

"""primary key columns input for table: glucose_standards"""
input glucose_standards_pk_columns_input {
  id: uuid!
}

"""
select columns of table "glucose_standards"
"""
enum glucose_standards_select_column {
  """column name"""
  id

  """column name"""
  max

  """column name"""
  min

  """column name"""
  title

  """column name"""
  type
}

"""
input type for updating data in table "glucose_standards"
"""
input glucose_standards_set_input {
  id: uuid
  max: numeric
  min: numeric
  title: String
  type: Int
}

"""aggregate stddev on columns"""
type glucose_standards_stddev_fields {
  max: Float
  min: Float
  type: Float
}

"""aggregate stddev_pop on columns"""
type glucose_standards_stddev_pop_fields {
  max: Float
  min: Float
  type: Float
}

"""aggregate stddev_samp on columns"""
type glucose_standards_stddev_samp_fields {
  max: Float
  min: Float
  type: Float
}

"""
Streaming cursor of the table "glucose_standards"
"""
input glucose_standards_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: glucose_standards_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input glucose_standards_stream_cursor_value_input {
  id: uuid
  max: numeric
  min: numeric
  title: String
  type: Int
}

"""aggregate sum on columns"""
type glucose_standards_sum_fields {
  max: numeric
  min: numeric
  type: Int
}

"""
update columns of table "glucose_standards"
"""
enum glucose_standards_update_column {
  """column name"""
  id

  """column name"""
  max

  """column name"""
  min

  """column name"""
  title

  """column name"""
  type
}

input glucose_standards_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: glucose_standards_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: glucose_standards_set_input

  """filter the rows which have to be updated"""
  where: glucose_standards_bool_exp!
}

"""aggregate var_pop on columns"""
type glucose_standards_var_pop_fields {
  max: Float
  min: Float
  type: Float
}

"""aggregate var_samp on columns"""
type glucose_standards_var_samp_fields {
  max: Float
  min: Float
  type: Float
}

"""aggregate variance on columns"""
type glucose_standards_variance_fields {
  max: Float
  min: Float
  type: Float
}

"""
columns and relationships of "hooks"
"""
type hooks {
  config(
    """JSON select path"""
    path: String
  ): jsonb!
  created_at: timestamptz!
  enabled: Boolean!
  event: String
  events(
    """JSON select path"""
    path: String
  ): jsonb!
  id: String!
  name: String!
  signing_key: String!
  tenant_id: String!
}

"""
aggregated selection of "hooks"
"""
type hooks_aggregate {
  aggregate: hooks_aggregate_fields
  nodes: [hooks!]!
}

"""
aggregate fields of "hooks"
"""
type hooks_aggregate_fields {
  count(columns: [hooks_select_column!], distinct: Boolean): Int!
  max: hooks_max_fields
  min: hooks_min_fields
}

"""append existing jsonb value of filtered columns with new jsonb value"""
input hooks_append_input {
  config: jsonb
  events: jsonb
}

"""
Boolean expression to filter rows from the table "hooks". All fields are combined with a logical 'AND'.
"""
input hooks_bool_exp {
  _and: [hooks_bool_exp!]
  _not: hooks_bool_exp
  _or: [hooks_bool_exp!]
  config: jsonb_comparison_exp
  created_at: timestamptz_comparison_exp
  enabled: Boolean_comparison_exp
  event: String_comparison_exp
  events: jsonb_comparison_exp
  id: String_comparison_exp
  name: String_comparison_exp
  signing_key: String_comparison_exp
  tenant_id: String_comparison_exp
}

"""
unique or primary key constraints on table "hooks"
"""
enum hooks_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  hooks_pkey
}

"""
delete the field or element with specified path (for JSON arrays, negative integers count from the end)
"""
input hooks_delete_at_path_input {
  config: [String!]
  events: [String!]
}

"""
delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
"""
input hooks_delete_elem_input {
  config: Int
  events: Int
}

"""
delete key/value pair or string element. key/value pairs are matched based on their key value
"""
input hooks_delete_key_input {
  config: String
  events: String
}

"""
input type for inserting data into table "hooks"
"""
input hooks_insert_input {
  config: jsonb
  created_at: timestamptz
  enabled: Boolean
  event: String
  events: jsonb
  id: String
  name: String
  signing_key: String
  tenant_id: String
}

"""aggregate max on columns"""
type hooks_max_fields {
  created_at: timestamptz
  event: String
  id: String
  name: String
  signing_key: String
  tenant_id: String
}

"""aggregate min on columns"""
type hooks_min_fields {
  created_at: timestamptz
  event: String
  id: String
  name: String
  signing_key: String
  tenant_id: String
}

"""
response of any mutation on the table "hooks"
"""
type hooks_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [hooks!]!
}

"""
on_conflict condition type for table "hooks"
"""
input hooks_on_conflict {
  constraint: hooks_constraint!
  update_columns: [hooks_update_column!]! = []
  where: hooks_bool_exp
}

"""Ordering options when selecting data from "hooks"."""
input hooks_order_by {
  config: order_by
  created_at: order_by
  enabled: order_by
  event: order_by
  events: order_by
  id: order_by
  name: order_by
  signing_key: order_by
  tenant_id: order_by
}

"""primary key columns input for table: hooks"""
input hooks_pk_columns_input {
  id: String!
}

"""prepend existing jsonb value of filtered columns with new jsonb value"""
input hooks_prepend_input {
  config: jsonb
  events: jsonb
}

"""
select columns of table "hooks"
"""
enum hooks_select_column {
  """column name"""
  config

  """column name"""
  created_at

  """column name"""
  enabled

  """column name"""
  event

  """column name"""
  events

  """column name"""
  id

  """column name"""
  name

  """column name"""
  signing_key

  """column name"""
  tenant_id
}

"""
input type for updating data in table "hooks"
"""
input hooks_set_input {
  config: jsonb
  created_at: timestamptz
  enabled: Boolean
  event: String
  events: jsonb
  id: String
  name: String
  signing_key: String
  tenant_id: String
}

"""
Streaming cursor of the table "hooks"
"""
input hooks_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: hooks_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input hooks_stream_cursor_value_input {
  config: jsonb
  created_at: timestamptz
  enabled: Boolean
  event: String
  events: jsonb
  id: String
  name: String
  signing_key: String
  tenant_id: String
}

"""
update columns of table "hooks"
"""
enum hooks_update_column {
  """column name"""
  config

  """column name"""
  created_at

  """column name"""
  enabled

  """column name"""
  event

  """column name"""
  events

  """column name"""
  id

  """column name"""
  name

  """column name"""
  signing_key

  """column name"""
  tenant_id
}

input hooks_updates {
  """append existing jsonb value of filtered columns with new jsonb value"""
  _append: hooks_append_input

  """
  delete the field or element with specified path (for JSON arrays, negative integers count from the end)
  """
  _delete_at_path: hooks_delete_at_path_input

  """
  delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
  """
  _delete_elem: hooks_delete_elem_input

  """
  delete key/value pair or string element. key/value pairs are matched based on their key value
  """
  _delete_key: hooks_delete_key_input

  """prepend existing jsonb value of filtered columns with new jsonb value"""
  _prepend: hooks_prepend_input

  """sets the columns of the filtered rows to the given values"""
  _set: hooks_set_input

  """filter the rows which have to be updated"""
  where: hooks_bool_exp!
}

scalar jsonb

input jsonb_cast_exp {
  String: String_comparison_exp
}

"""
Boolean expression to compare columns of type "jsonb". All fields are combined with logical 'AND'.
"""
input jsonb_comparison_exp {
  _cast: jsonb_cast_exp

  """is the column contained in the given json value"""
  _contained_in: jsonb

  """does the column contain the given json value at the top level"""
  _contains: jsonb
  _eq: jsonb
  _gt: jsonb
  _gte: jsonb

  """does the string exist as a top-level key in the column"""
  _has_key: String

  """do all of these strings exist as top-level keys in the column"""
  _has_keys_all: [String!]

  """do any of these strings exist as top-level keys in the column"""
  _has_keys_any: [String!]
  _in: [jsonb!]
  _is_null: Boolean
  _lt: jsonb
  _lte: jsonb
  _neq: jsonb
  _nin: [jsonb!]
}

"""化验报告记录表"""
type lab_report_records {
  """化验时间"""
  assay_date: date!
  created_at: timestamptz!
  id: uuid!
  images: [String!]!
  remarks: String

  """化验报告类型，1：血常规、2：尿常规、3：大便常规、4：肠胃镜报告、5：病理报告、6：其他"""
  report_type: Int!
  updated_at: timestamptz!
  user_id: String!
}

"""
aggregated selection of "lab_report_records"
"""
type lab_report_records_aggregate {
  aggregate: lab_report_records_aggregate_fields
  nodes: [lab_report_records!]!
}

"""
aggregate fields of "lab_report_records"
"""
type lab_report_records_aggregate_fields {
  avg: lab_report_records_avg_fields
  count(columns: [lab_report_records_select_column!], distinct: Boolean): Int!
  max: lab_report_records_max_fields
  min: lab_report_records_min_fields
  stddev: lab_report_records_stddev_fields
  stddev_pop: lab_report_records_stddev_pop_fields
  stddev_samp: lab_report_records_stddev_samp_fields
  sum: lab_report_records_sum_fields
  var_pop: lab_report_records_var_pop_fields
  var_samp: lab_report_records_var_samp_fields
  variance: lab_report_records_variance_fields
}

"""aggregate avg on columns"""
type lab_report_records_avg_fields {
  """化验报告类型，1：血常规、2：尿常规、3：大便常规、4：肠胃镜报告、5：病理报告、6：其他"""
  report_type: Float
}

"""
Boolean expression to filter rows from the table "lab_report_records". All fields are combined with a logical 'AND'.
"""
input lab_report_records_bool_exp {
  _and: [lab_report_records_bool_exp!]
  _not: lab_report_records_bool_exp
  _or: [lab_report_records_bool_exp!]
  assay_date: date_comparison_exp
  created_at: timestamptz_comparison_exp
  id: uuid_comparison_exp
  images: String_array_comparison_exp
  remarks: String_comparison_exp
  report_type: Int_comparison_exp
  updated_at: timestamptz_comparison_exp
  user_id: String_comparison_exp
}

"""
unique or primary key constraints on table "lab_report_records"
"""
enum lab_report_records_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  lab_report_records_pkey
}

"""
input type for incrementing numeric columns in table "lab_report_records"
"""
input lab_report_records_inc_input {
  """化验报告类型，1：血常规、2：尿常规、3：大便常规、4：肠胃镜报告、5：病理报告、6：其他"""
  report_type: Int
}

"""
input type for inserting data into table "lab_report_records"
"""
input lab_report_records_insert_input {
  """化验时间"""
  assay_date: date
  created_at: timestamptz
  id: uuid
  images: [String!]
  remarks: String

  """化验报告类型，1：血常规、2：尿常规、3：大便常规、4：肠胃镜报告、5：病理报告、6：其他"""
  report_type: Int
  updated_at: timestamptz
  user_id: String
}

"""aggregate max on columns"""
type lab_report_records_max_fields {
  """化验时间"""
  assay_date: date
  created_at: timestamptz
  id: uuid
  images: [String!]
  remarks: String

  """化验报告类型，1：血常规、2：尿常规、3：大便常规、4：肠胃镜报告、5：病理报告、6：其他"""
  report_type: Int
  updated_at: timestamptz
  user_id: String
}

"""aggregate min on columns"""
type lab_report_records_min_fields {
  """化验时间"""
  assay_date: date
  created_at: timestamptz
  id: uuid
  images: [String!]
  remarks: String

  """化验报告类型，1：血常规、2：尿常规、3：大便常规、4：肠胃镜报告、5：病理报告、6：其他"""
  report_type: Int
  updated_at: timestamptz
  user_id: String
}

"""
response of any mutation on the table "lab_report_records"
"""
type lab_report_records_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [lab_report_records!]!
}

"""
on_conflict condition type for table "lab_report_records"
"""
input lab_report_records_on_conflict {
  constraint: lab_report_records_constraint!
  update_columns: [lab_report_records_update_column!]! = []
  where: lab_report_records_bool_exp
}

"""Ordering options when selecting data from "lab_report_records"."""
input lab_report_records_order_by {
  assay_date: order_by
  created_at: order_by
  id: order_by
  images: order_by
  remarks: order_by
  report_type: order_by
  updated_at: order_by
  user_id: order_by
}

"""primary key columns input for table: lab_report_records"""
input lab_report_records_pk_columns_input {
  id: uuid!
}

"""
select columns of table "lab_report_records"
"""
enum lab_report_records_select_column {
  """column name"""
  assay_date

  """column name"""
  created_at

  """column name"""
  id

  """column name"""
  images

  """column name"""
  remarks

  """column name"""
  report_type

  """column name"""
  updated_at

  """column name"""
  user_id
}

"""
input type for updating data in table "lab_report_records"
"""
input lab_report_records_set_input {
  """化验时间"""
  assay_date: date
  created_at: timestamptz
  id: uuid
  images: [String!]
  remarks: String

  """化验报告类型，1：血常规、2：尿常规、3：大便常规、4：肠胃镜报告、5：病理报告、6：其他"""
  report_type: Int
  updated_at: timestamptz
  user_id: String
}

"""aggregate stddev on columns"""
type lab_report_records_stddev_fields {
  """化验报告类型，1：血常规、2：尿常规、3：大便常规、4：肠胃镜报告、5：病理报告、6：其他"""
  report_type: Float
}

"""aggregate stddev_pop on columns"""
type lab_report_records_stddev_pop_fields {
  """化验报告类型，1：血常规、2：尿常规、3：大便常规、4：肠胃镜报告、5：病理报告、6：其他"""
  report_type: Float
}

"""aggregate stddev_samp on columns"""
type lab_report_records_stddev_samp_fields {
  """化验报告类型，1：血常规、2：尿常规、3：大便常规、4：肠胃镜报告、5：病理报告、6：其他"""
  report_type: Float
}

"""
Streaming cursor of the table "lab_report_records"
"""
input lab_report_records_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: lab_report_records_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input lab_report_records_stream_cursor_value_input {
  """化验时间"""
  assay_date: date
  created_at: timestamptz
  id: uuid
  images: [String!]
  remarks: String

  """化验报告类型，1：血常规、2：尿常规、3：大便常规、4：肠胃镜报告、5：病理报告、6：其他"""
  report_type: Int
  updated_at: timestamptz
  user_id: String
}

"""aggregate sum on columns"""
type lab_report_records_sum_fields {
  """化验报告类型，1：血常规、2：尿常规、3：大便常规、4：肠胃镜报告、5：病理报告、6：其他"""
  report_type: Int
}

"""
update columns of table "lab_report_records"
"""
enum lab_report_records_update_column {
  """column name"""
  assay_date

  """column name"""
  created_at

  """column name"""
  id

  """column name"""
  images

  """column name"""
  remarks

  """column name"""
  report_type

  """column name"""
  updated_at

  """column name"""
  user_id
}

input lab_report_records_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: lab_report_records_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: lab_report_records_set_input

  """filter the rows which have to be updated"""
  where: lab_report_records_bool_exp!
}

"""aggregate var_pop on columns"""
type lab_report_records_var_pop_fields {
  """化验报告类型，1：血常规、2：尿常规、3：大便常规、4：肠胃镜报告、5：病理报告、6：其他"""
  report_type: Float
}

"""aggregate var_samp on columns"""
type lab_report_records_var_samp_fields {
  """化验报告类型，1：血常规、2：尿常规、3：大便常规、4：肠胃镜报告、5：病理报告、6：其他"""
  report_type: Float
}

"""aggregate variance on columns"""
type lab_report_records_variance_fields {
  """化验报告类型，1：血常规、2：尿常规、3：大便常规、4：肠胃镜报告、5：病理报告、6：其他"""
  report_type: Float
}

"""
columns and relationships of "logs"
"""
type logs {
  created_at: timestamptz!
  id: String!
  key: String!
  payload(
    """JSON select path"""
    path: String
  ): jsonb!
  tenant_id: String!
}

"""
aggregated selection of "logs"
"""
type logs_aggregate {
  aggregate: logs_aggregate_fields
  nodes: [logs!]!
}

"""
aggregate fields of "logs"
"""
type logs_aggregate_fields {
  count(columns: [logs_select_column!], distinct: Boolean): Int!
  max: logs_max_fields
  min: logs_min_fields
}

"""append existing jsonb value of filtered columns with new jsonb value"""
input logs_append_input {
  payload: jsonb
}

"""
Boolean expression to filter rows from the table "logs". All fields are combined with a logical 'AND'.
"""
input logs_bool_exp {
  _and: [logs_bool_exp!]
  _not: logs_bool_exp
  _or: [logs_bool_exp!]
  created_at: timestamptz_comparison_exp
  id: String_comparison_exp
  key: String_comparison_exp
  payload: jsonb_comparison_exp
  tenant_id: String_comparison_exp
}

"""
unique or primary key constraints on table "logs"
"""
enum logs_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  logs_pkey
}

"""
delete the field or element with specified path (for JSON arrays, negative integers count from the end)
"""
input logs_delete_at_path_input {
  payload: [String!]
}

"""
delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
"""
input logs_delete_elem_input {
  payload: Int
}

"""
delete key/value pair or string element. key/value pairs are matched based on their key value
"""
input logs_delete_key_input {
  payload: String
}

"""
input type for inserting data into table "logs"
"""
input logs_insert_input {
  created_at: timestamptz
  id: String
  key: String
  payload: jsonb
  tenant_id: String
}

"""aggregate max on columns"""
type logs_max_fields {
  created_at: timestamptz
  id: String
  key: String
  tenant_id: String
}

"""aggregate min on columns"""
type logs_min_fields {
  created_at: timestamptz
  id: String
  key: String
  tenant_id: String
}

"""
response of any mutation on the table "logs"
"""
type logs_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [logs!]!
}

"""
on_conflict condition type for table "logs"
"""
input logs_on_conflict {
  constraint: logs_constraint!
  update_columns: [logs_update_column!]! = []
  where: logs_bool_exp
}

"""Ordering options when selecting data from "logs"."""
input logs_order_by {
  created_at: order_by
  id: order_by
  key: order_by
  payload: order_by
  tenant_id: order_by
}

"""primary key columns input for table: logs"""
input logs_pk_columns_input {
  id: String!
}

"""prepend existing jsonb value of filtered columns with new jsonb value"""
input logs_prepend_input {
  payload: jsonb
}

"""
select columns of table "logs"
"""
enum logs_select_column {
  """column name"""
  created_at

  """column name"""
  id

  """column name"""
  key

  """column name"""
  payload

  """column name"""
  tenant_id
}

"""
input type for updating data in table "logs"
"""
input logs_set_input {
  created_at: timestamptz
  id: String
  key: String
  payload: jsonb
  tenant_id: String
}

"""
Streaming cursor of the table "logs"
"""
input logs_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: logs_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input logs_stream_cursor_value_input {
  created_at: timestamptz
  id: String
  key: String
  payload: jsonb
  tenant_id: String
}

"""
update columns of table "logs"
"""
enum logs_update_column {
  """column name"""
  created_at

  """column name"""
  id

  """column name"""
  key

  """column name"""
  payload

  """column name"""
  tenant_id
}

input logs_updates {
  """append existing jsonb value of filtered columns with new jsonb value"""
  _append: logs_append_input

  """
  delete the field or element with specified path (for JSON arrays, negative integers count from the end)
  """
  _delete_at_path: logs_delete_at_path_input

  """
  delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
  """
  _delete_elem: logs_delete_elem_input

  """
  delete key/value pair or string element. key/value pairs are matched based on their key value
  """
  _delete_key: logs_delete_key_input

  """prepend existing jsonb value of filtered columns with new jsonb value"""
  _prepend: logs_prepend_input

  """sets the columns of the filtered rows to the given values"""
  _set: logs_set_input

  """filter the rows which have to be updated"""
  where: logs_bool_exp!
}

"""
columns and relationships of "logto_configs"
"""
type logto_configs {
  key: String!
  tenant_id: String!
  value(
    """JSON select path"""
    path: String
  ): jsonb!
}

"""
aggregated selection of "logto_configs"
"""
type logto_configs_aggregate {
  aggregate: logto_configs_aggregate_fields
  nodes: [logto_configs!]!
}

"""
aggregate fields of "logto_configs"
"""
type logto_configs_aggregate_fields {
  count(columns: [logto_configs_select_column!], distinct: Boolean): Int!
  max: logto_configs_max_fields
  min: logto_configs_min_fields
}

"""append existing jsonb value of filtered columns with new jsonb value"""
input logto_configs_append_input {
  value: jsonb
}

"""
Boolean expression to filter rows from the table "logto_configs". All fields are combined with a logical 'AND'.
"""
input logto_configs_bool_exp {
  _and: [logto_configs_bool_exp!]
  _not: logto_configs_bool_exp
  _or: [logto_configs_bool_exp!]
  key: String_comparison_exp
  tenant_id: String_comparison_exp
  value: jsonb_comparison_exp
}

"""
unique or primary key constraints on table "logto_configs"
"""
enum logto_configs_constraint {
  """
  unique or primary key constraint on columns "key", "tenant_id"
  """
  logto_configs_pkey
}

"""
delete the field or element with specified path (for JSON arrays, negative integers count from the end)
"""
input logto_configs_delete_at_path_input {
  value: [String!]
}

"""
delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
"""
input logto_configs_delete_elem_input {
  value: Int
}

"""
delete key/value pair or string element. key/value pairs are matched based on their key value
"""
input logto_configs_delete_key_input {
  value: String
}

"""
input type for inserting data into table "logto_configs"
"""
input logto_configs_insert_input {
  key: String
  tenant_id: String
  value: jsonb
}

"""aggregate max on columns"""
type logto_configs_max_fields {
  key: String
  tenant_id: String
}

"""aggregate min on columns"""
type logto_configs_min_fields {
  key: String
  tenant_id: String
}

"""
response of any mutation on the table "logto_configs"
"""
type logto_configs_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [logto_configs!]!
}

"""
on_conflict condition type for table "logto_configs"
"""
input logto_configs_on_conflict {
  constraint: logto_configs_constraint!
  update_columns: [logto_configs_update_column!]! = []
  where: logto_configs_bool_exp
}

"""Ordering options when selecting data from "logto_configs"."""
input logto_configs_order_by {
  key: order_by
  tenant_id: order_by
  value: order_by
}

"""primary key columns input for table: logto_configs"""
input logto_configs_pk_columns_input {
  key: String!
  tenant_id: String!
}

"""prepend existing jsonb value of filtered columns with new jsonb value"""
input logto_configs_prepend_input {
  value: jsonb
}

"""
select columns of table "logto_configs"
"""
enum logto_configs_select_column {
  """column name"""
  key

  """column name"""
  tenant_id

  """column name"""
  value
}

"""
input type for updating data in table "logto_configs"
"""
input logto_configs_set_input {
  key: String
  tenant_id: String
  value: jsonb
}

"""
Streaming cursor of the table "logto_configs"
"""
input logto_configs_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: logto_configs_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input logto_configs_stream_cursor_value_input {
  key: String
  tenant_id: String
  value: jsonb
}

"""
update columns of table "logto_configs"
"""
enum logto_configs_update_column {
  """column name"""
  key

  """column name"""
  tenant_id

  """column name"""
  value
}

input logto_configs_updates {
  """append existing jsonb value of filtered columns with new jsonb value"""
  _append: logto_configs_append_input

  """
  delete the field or element with specified path (for JSON arrays, negative integers count from the end)
  """
  _delete_at_path: logto_configs_delete_at_path_input

  """
  delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
  """
  _delete_elem: logto_configs_delete_elem_input

  """
  delete key/value pair or string element. key/value pairs are matched based on their key value
  """
  _delete_key: logto_configs_delete_key_input

  """prepend existing jsonb value of filtered columns with new jsonb value"""
  _prepend: logto_configs_prepend_input

  """sets the columns of the filtered rows to the given values"""
  _set: logto_configs_set_input

  """filter the rows which have to be updated"""
  where: logto_configs_bool_exp!
}

"""体检报告记录表"""
type medical_examination_records {
  created_at: timestamptz!

  """检查时间"""
  exam_date: date!
  id: uuid!
  images: [String!]!
  remarks: String
  updated_at: timestamptz!
  user_id: String!
}

"""
aggregated selection of "medical_examination_records"
"""
type medical_examination_records_aggregate {
  aggregate: medical_examination_records_aggregate_fields
  nodes: [medical_examination_records!]!
}

"""
aggregate fields of "medical_examination_records"
"""
type medical_examination_records_aggregate_fields {
  count(columns: [medical_examination_records_select_column!], distinct: Boolean): Int!
  max: medical_examination_records_max_fields
  min: medical_examination_records_min_fields
}

"""
Boolean expression to filter rows from the table "medical_examination_records". All fields are combined with a logical 'AND'.
"""
input medical_examination_records_bool_exp {
  _and: [medical_examination_records_bool_exp!]
  _not: medical_examination_records_bool_exp
  _or: [medical_examination_records_bool_exp!]
  created_at: timestamptz_comparison_exp
  exam_date: date_comparison_exp
  id: uuid_comparison_exp
  images: String_array_comparison_exp
  remarks: String_comparison_exp
  updated_at: timestamptz_comparison_exp
  user_id: String_comparison_exp
}

"""
unique or primary key constraints on table "medical_examination_records"
"""
enum medical_examination_records_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  medical_examination_records_pkey
}

"""
input type for inserting data into table "medical_examination_records"
"""
input medical_examination_records_insert_input {
  created_at: timestamptz

  """检查时间"""
  exam_date: date
  id: uuid
  images: [String!]
  remarks: String
  updated_at: timestamptz
  user_id: String
}

"""aggregate max on columns"""
type medical_examination_records_max_fields {
  created_at: timestamptz

  """检查时间"""
  exam_date: date
  id: uuid
  images: [String!]
  remarks: String
  updated_at: timestamptz
  user_id: String
}

"""aggregate min on columns"""
type medical_examination_records_min_fields {
  created_at: timestamptz

  """检查时间"""
  exam_date: date
  id: uuid
  images: [String!]
  remarks: String
  updated_at: timestamptz
  user_id: String
}

"""
response of any mutation on the table "medical_examination_records"
"""
type medical_examination_records_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [medical_examination_records!]!
}

"""
on_conflict condition type for table "medical_examination_records"
"""
input medical_examination_records_on_conflict {
  constraint: medical_examination_records_constraint!
  update_columns: [medical_examination_records_update_column!]! = []
  where: medical_examination_records_bool_exp
}

"""
Ordering options when selecting data from "medical_examination_records".
"""
input medical_examination_records_order_by {
  created_at: order_by
  exam_date: order_by
  id: order_by
  images: order_by
  remarks: order_by
  updated_at: order_by
  user_id: order_by
}

"""primary key columns input for table: medical_examination_records"""
input medical_examination_records_pk_columns_input {
  id: uuid!
}

"""
select columns of table "medical_examination_records"
"""
enum medical_examination_records_select_column {
  """column name"""
  created_at

  """column name"""
  exam_date

  """column name"""
  id

  """column name"""
  images

  """column name"""
  remarks

  """column name"""
  updated_at

  """column name"""
  user_id
}

"""
input type for updating data in table "medical_examination_records"
"""
input medical_examination_records_set_input {
  created_at: timestamptz

  """检查时间"""
  exam_date: date
  id: uuid
  images: [String!]
  remarks: String
  updated_at: timestamptz
  user_id: String
}

"""
Streaming cursor of the table "medical_examination_records"
"""
input medical_examination_records_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: medical_examination_records_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input medical_examination_records_stream_cursor_value_input {
  created_at: timestamptz

  """检查时间"""
  exam_date: date
  id: uuid
  images: [String!]
  remarks: String
  updated_at: timestamptz
  user_id: String
}

"""
update columns of table "medical_examination_records"
"""
enum medical_examination_records_update_column {
  """column name"""
  created_at

  """column name"""
  exam_date

  """column name"""
  id

  """column name"""
  images

  """column name"""
  remarks

  """column name"""
  updated_at

  """column name"""
  user_id
}

input medical_examination_records_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: medical_examination_records_set_input

  """filter the rows which have to be updated"""
  where: medical_examination_records_bool_exp!
}

"""用药提醒"""
type medication_reminders {
  created_at: timestamptz!

  """每天用药次数"""
  doses_per_day: Int
  id: uuid!

  """生产厂家"""
  manufacturer: String
  name: String!
  phone_number: String

  """提醒时间数组"""
  reminder_times: [String!]!
  spec: String

  """用法用量"""
  usage_dosage: String
  user_id: String!
}

"""
aggregated selection of "medication_reminders"
"""
type medication_reminders_aggregate {
  aggregate: medication_reminders_aggregate_fields
  nodes: [medication_reminders!]!
}

"""
aggregate fields of "medication_reminders"
"""
type medication_reminders_aggregate_fields {
  avg: medication_reminders_avg_fields
  count(columns: [medication_reminders_select_column!], distinct: Boolean): Int!
  max: medication_reminders_max_fields
  min: medication_reminders_min_fields
  stddev: medication_reminders_stddev_fields
  stddev_pop: medication_reminders_stddev_pop_fields
  stddev_samp: medication_reminders_stddev_samp_fields
  sum: medication_reminders_sum_fields
  var_pop: medication_reminders_var_pop_fields
  var_samp: medication_reminders_var_samp_fields
  variance: medication_reminders_variance_fields
}

"""aggregate avg on columns"""
type medication_reminders_avg_fields {
  """每天用药次数"""
  doses_per_day: Float
}

"""
Boolean expression to filter rows from the table "medication_reminders". All fields are combined with a logical 'AND'.
"""
input medication_reminders_bool_exp {
  _and: [medication_reminders_bool_exp!]
  _not: medication_reminders_bool_exp
  _or: [medication_reminders_bool_exp!]
  created_at: timestamptz_comparison_exp
  doses_per_day: Int_comparison_exp
  id: uuid_comparison_exp
  manufacturer: String_comparison_exp
  name: String_comparison_exp
  phone_number: String_comparison_exp
  reminder_times: String_array_comparison_exp
  spec: String_comparison_exp
  usage_dosage: String_comparison_exp
  user_id: String_comparison_exp
}

"""
unique or primary key constraints on table "medication_reminders"
"""
enum medication_reminders_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  medication_reminders_pkey
}

"""
input type for incrementing numeric columns in table "medication_reminders"
"""
input medication_reminders_inc_input {
  """每天用药次数"""
  doses_per_day: Int
}

"""
input type for inserting data into table "medication_reminders"
"""
input medication_reminders_insert_input {
  created_at: timestamptz

  """每天用药次数"""
  doses_per_day: Int
  id: uuid

  """生产厂家"""
  manufacturer: String
  name: String
  phone_number: String

  """提醒时间数组"""
  reminder_times: [String!]
  spec: String

  """用法用量"""
  usage_dosage: String
  user_id: String
}

"""aggregate max on columns"""
type medication_reminders_max_fields {
  created_at: timestamptz

  """每天用药次数"""
  doses_per_day: Int
  id: uuid

  """生产厂家"""
  manufacturer: String
  name: String
  phone_number: String

  """提醒时间数组"""
  reminder_times: [String!]
  spec: String

  """用法用量"""
  usage_dosage: String
  user_id: String
}

"""aggregate min on columns"""
type medication_reminders_min_fields {
  created_at: timestamptz

  """每天用药次数"""
  doses_per_day: Int
  id: uuid

  """生产厂家"""
  manufacturer: String
  name: String
  phone_number: String

  """提醒时间数组"""
  reminder_times: [String!]
  spec: String

  """用法用量"""
  usage_dosage: String
  user_id: String
}

"""
response of any mutation on the table "medication_reminders"
"""
type medication_reminders_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [medication_reminders!]!
}

"""
on_conflict condition type for table "medication_reminders"
"""
input medication_reminders_on_conflict {
  constraint: medication_reminders_constraint!
  update_columns: [medication_reminders_update_column!]! = []
  where: medication_reminders_bool_exp
}

"""Ordering options when selecting data from "medication_reminders"."""
input medication_reminders_order_by {
  created_at: order_by
  doses_per_day: order_by
  id: order_by
  manufacturer: order_by
  name: order_by
  phone_number: order_by
  reminder_times: order_by
  spec: order_by
  usage_dosage: order_by
  user_id: order_by
}

"""primary key columns input for table: medication_reminders"""
input medication_reminders_pk_columns_input {
  id: uuid!
}

"""
select columns of table "medication_reminders"
"""
enum medication_reminders_select_column {
  """column name"""
  created_at

  """column name"""
  doses_per_day

  """column name"""
  id

  """column name"""
  manufacturer

  """column name"""
  name

  """column name"""
  phone_number

  """column name"""
  reminder_times

  """column name"""
  spec

  """column name"""
  usage_dosage

  """column name"""
  user_id
}

"""
input type for updating data in table "medication_reminders"
"""
input medication_reminders_set_input {
  created_at: timestamptz

  """每天用药次数"""
  doses_per_day: Int
  id: uuid

  """生产厂家"""
  manufacturer: String
  name: String
  phone_number: String

  """提醒时间数组"""
  reminder_times: [String!]
  spec: String

  """用法用量"""
  usage_dosage: String
  user_id: String
}

"""aggregate stddev on columns"""
type medication_reminders_stddev_fields {
  """每天用药次数"""
  doses_per_day: Float
}

"""aggregate stddev_pop on columns"""
type medication_reminders_stddev_pop_fields {
  """每天用药次数"""
  doses_per_day: Float
}

"""aggregate stddev_samp on columns"""
type medication_reminders_stddev_samp_fields {
  """每天用药次数"""
  doses_per_day: Float
}

"""
Streaming cursor of the table "medication_reminders"
"""
input medication_reminders_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: medication_reminders_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input medication_reminders_stream_cursor_value_input {
  created_at: timestamptz

  """每天用药次数"""
  doses_per_day: Int
  id: uuid

  """生产厂家"""
  manufacturer: String
  name: String
  phone_number: String

  """提醒时间数组"""
  reminder_times: [String!]
  spec: String

  """用法用量"""
  usage_dosage: String
  user_id: String
}

"""aggregate sum on columns"""
type medication_reminders_sum_fields {
  """每天用药次数"""
  doses_per_day: Int
}

"""
update columns of table "medication_reminders"
"""
enum medication_reminders_update_column {
  """column name"""
  created_at

  """column name"""
  doses_per_day

  """column name"""
  id

  """column name"""
  manufacturer

  """column name"""
  name

  """column name"""
  phone_number

  """column name"""
  reminder_times

  """column name"""
  spec

  """column name"""
  usage_dosage

  """column name"""
  user_id
}

input medication_reminders_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: medication_reminders_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: medication_reminders_set_input

  """filter the rows which have to be updated"""
  where: medication_reminders_bool_exp!
}

"""aggregate var_pop on columns"""
type medication_reminders_var_pop_fields {
  """每天用药次数"""
  doses_per_day: Float
}

"""aggregate var_samp on columns"""
type medication_reminders_var_samp_fields {
  """每天用药次数"""
  doses_per_day: Float
}

"""aggregate variance on columns"""
type medication_reminders_variance_fields {
  """每天用药次数"""
  doses_per_day: Float
}

"""mutation root"""
type mutation_root {
  """
  This API call returns a new API key. The new key does not have any permissions. Requires permission API_MOD
  """
  create(friendlyName: String): NewApiKey

  """
  This API call deletes the selected file and runs the clean-up procedure which purges all expired files from the data directory immediately. Requires permission DELETE
  """
  delete(id: String!): String!

  """
  delete data from the table: "ads"
  """
  delete_ads(
    """filter the rows which have to be deleted"""
    where: ads_bool_exp!
  ): ads_mutation_response

  """
  delete single row from the table: "ads"
  """
  delete_ads_by_pk(id: uuid!): ads

  """
  delete data from the table: "application_sign_in_experiences"
  """
  delete_application_sign_in_experiences(
    """filter the rows which have to be deleted"""
    where: application_sign_in_experiences_bool_exp!
  ): application_sign_in_experiences_mutation_response

  """
  delete single row from the table: "application_sign_in_experiences"
  """
  delete_application_sign_in_experiences_by_pk(application_id: String!, tenant_id: String!): application_sign_in_experiences

  """
  delete data from the table: "application_user_consent_organization_scopes"
  """
  delete_application_user_consent_organization_scopes(
    """filter the rows which have to be deleted"""
    where: application_user_consent_organization_scopes_bool_exp!
  ): application_user_consent_organization_scopes_mutation_response

  """
  delete single row from the table: "application_user_consent_organization_scopes"
  """
  delete_application_user_consent_organization_scopes_by_pk(application_id: String!, organization_scope_id: String!): application_user_consent_organization_scopes

  """
  delete data from the table: "application_user_consent_organizations"
  """
  delete_application_user_consent_organizations(
    """filter the rows which have to be deleted"""
    where: application_user_consent_organizations_bool_exp!
  ): application_user_consent_organizations_mutation_response

  """
  delete single row from the table: "application_user_consent_organizations"
  """
  delete_application_user_consent_organizations_by_pk(application_id: String!, organization_id: String!, tenant_id: String!, user_id: String!): application_user_consent_organizations

  """
  delete data from the table: "application_user_consent_resource_scopes"
  """
  delete_application_user_consent_resource_scopes(
    """filter the rows which have to be deleted"""
    where: application_user_consent_resource_scopes_bool_exp!
  ): application_user_consent_resource_scopes_mutation_response

  """
  delete single row from the table: "application_user_consent_resource_scopes"
  """
  delete_application_user_consent_resource_scopes_by_pk(application_id: String!, scope_id: String!): application_user_consent_resource_scopes

  """
  delete data from the table: "application_user_consent_user_scopes"
  """
  delete_application_user_consent_user_scopes(
    """filter the rows which have to be deleted"""
    where: application_user_consent_user_scopes_bool_exp!
  ): application_user_consent_user_scopes_mutation_response

  """
  delete single row from the table: "application_user_consent_user_scopes"
  """
  delete_application_user_consent_user_scopes_by_pk(application_id: String!, user_scope: String!): application_user_consent_user_scopes

  """
  delete data from the table: "applications"
  """
  delete_applications(
    """filter the rows which have to be deleted"""
    where: applications_bool_exp!
  ): applications_mutation_response

  """
  delete single row from the table: "applications"
  """
  delete_applications_by_pk(id: String!): applications

  """
  delete data from the table: "applications_roles"
  """
  delete_applications_roles(
    """filter the rows which have to be deleted"""
    where: applications_roles_bool_exp!
  ): applications_roles_mutation_response

  """
  delete single row from the table: "applications_roles"
  """
  delete_applications_roles_by_pk(id: String!): applications_roles

  """
  delete data from the table: "check_in_settings"
  """
  delete_check_in_settings(
    """filter the rows which have to be deleted"""
    where: check_in_settings_bool_exp!
  ): check_in_settings_mutation_response

  """
  delete single row from the table: "check_in_settings"
  """
  delete_check_in_settings_by_pk(id: uuid!): check_in_settings

  """
  delete data from the table: "check_ins"
  """
  delete_check_ins(
    """filter the rows which have to be deleted"""
    where: check_ins_bool_exp!
  ): check_ins_mutation_response

  """
  delete single row from the table: "check_ins"
  """
  delete_check_ins_by_pk(id: uuid!): check_ins

  """
  delete data from the table: "cholesterol_records"
  """
  delete_cholesterol_records(
    """filter the rows which have to be deleted"""
    where: cholesterol_records_bool_exp!
  ): cholesterol_records_mutation_response

  """
  delete single row from the table: "cholesterol_records"
  """
  delete_cholesterol_records_by_pk(id: uuid!): cholesterol_records

  """
  delete data from the table: "cholesterol_standards"
  """
  delete_cholesterol_standards(
    """filter the rows which have to be deleted"""
    where: cholesterol_standards_bool_exp!
  ): cholesterol_standards_mutation_response

  """
  delete single row from the table: "cholesterol_standards"
  """
  delete_cholesterol_standards_by_pk(id: uuid!): cholesterol_standards

  """
  delete data from the table: "connectors"
  """
  delete_connectors(
    """filter the rows which have to be deleted"""
    where: connectors_bool_exp!
  ): connectors_mutation_response

  """
  delete single row from the table: "connectors"
  """
  delete_connectors_by_pk(id: String!): connectors

  """
  delete data from the table: "custom_phrases"
  """
  delete_custom_phrases(
    """filter the rows which have to be deleted"""
    where: custom_phrases_bool_exp!
  ): custom_phrases_mutation_response

  """
  delete single row from the table: "custom_phrases"
  """
  delete_custom_phrases_by_pk(id: String!): custom_phrases

  """
  delete data from the table: "daily_active_users"
  """
  delete_daily_active_users(
    """filter the rows which have to be deleted"""
    where: daily_active_users_bool_exp!
  ): daily_active_users_mutation_response

  """
  delete single row from the table: "daily_active_users"
  """
  delete_daily_active_users_by_pk(id: String!): daily_active_users

  """
  delete data from the table: "daily_token_usage"
  """
  delete_daily_token_usage(
    """filter the rows which have to be deleted"""
    where: daily_token_usage_bool_exp!
  ): daily_token_usage_mutation_response

  """
  delete single row from the table: "daily_token_usage"
  """
  delete_daily_token_usage_by_pk(id: String!): daily_token_usage

  """
  delete data from the table: "domains"
  """
  delete_domains(
    """filter the rows which have to be deleted"""
    where: domains_bool_exp!
  ): domains_mutation_response

  """
  delete single row from the table: "domains"
  """
  delete_domains_by_pk(id: String!): domains

  """
  delete data from the table: "glucose_records"
  """
  delete_glucose_records(
    """filter the rows which have to be deleted"""
    where: glucose_records_bool_exp!
  ): glucose_records_mutation_response

  """
  delete single row from the table: "glucose_records"
  """
  delete_glucose_records_by_pk(id: uuid!): glucose_records

  """
  delete data from the table: "glucose_standards"
  """
  delete_glucose_standards(
    """filter the rows which have to be deleted"""
    where: glucose_standards_bool_exp!
  ): glucose_standards_mutation_response

  """
  delete single row from the table: "glucose_standards"
  """
  delete_glucose_standards_by_pk(id: uuid!): glucose_standards

  """
  delete data from the table: "hooks"
  """
  delete_hooks(
    """filter the rows which have to be deleted"""
    where: hooks_bool_exp!
  ): hooks_mutation_response

  """
  delete single row from the table: "hooks"
  """
  delete_hooks_by_pk(id: String!): hooks

  """
  delete data from the table: "lab_report_records"
  """
  delete_lab_report_records(
    """filter the rows which have to be deleted"""
    where: lab_report_records_bool_exp!
  ): lab_report_records_mutation_response

  """
  delete single row from the table: "lab_report_records"
  """
  delete_lab_report_records_by_pk(id: uuid!): lab_report_records

  """
  delete data from the table: "logs"
  """
  delete_logs(
    """filter the rows which have to be deleted"""
    where: logs_bool_exp!
  ): logs_mutation_response

  """
  delete single row from the table: "logs"
  """
  delete_logs_by_pk(id: String!): logs

  """
  delete data from the table: "logto_configs"
  """
  delete_logto_configs(
    """filter the rows which have to be deleted"""
    where: logto_configs_bool_exp!
  ): logto_configs_mutation_response

  """
  delete single row from the table: "logto_configs"
  """
  delete_logto_configs_by_pk(key: String!, tenant_id: String!): logto_configs

  """
  delete data from the table: "medical_examination_records"
  """
  delete_medical_examination_records(
    """filter the rows which have to be deleted"""
    where: medical_examination_records_bool_exp!
  ): medical_examination_records_mutation_response

  """
  delete single row from the table: "medical_examination_records"
  """
  delete_medical_examination_records_by_pk(id: uuid!): medical_examination_records

  """
  delete data from the table: "medication_reminders"
  """
  delete_medication_reminders(
    """filter the rows which have to be deleted"""
    where: medication_reminders_bool_exp!
  ): medication_reminders_mutation_response

  """
  delete single row from the table: "medication_reminders"
  """
  delete_medication_reminders_by_pk(id: uuid!): medication_reminders

  """
  delete data from the table: "oidc_model_instances"
  """
  delete_oidc_model_instances(
    """filter the rows which have to be deleted"""
    where: oidc_model_instances_bool_exp!
  ): oidc_model_instances_mutation_response

  """
  delete single row from the table: "oidc_model_instances"
  """
  delete_oidc_model_instances_by_pk(id: String!): oidc_model_instances

  """
  delete data from the table: "organization_invitation_role_relations"
  """
  delete_organization_invitation_role_relations(
    """filter the rows which have to be deleted"""
    where: organization_invitation_role_relations_bool_exp!
  ): organization_invitation_role_relations_mutation_response

  """
  delete single row from the table: "organization_invitation_role_relations"
  """
  delete_organization_invitation_role_relations_by_pk(organization_invitation_id: String!, organization_role_id: String!, tenant_id: String!): organization_invitation_role_relations

  """
  delete data from the table: "organization_invitations"
  """
  delete_organization_invitations(
    """filter the rows which have to be deleted"""
    where: organization_invitations_bool_exp!
  ): organization_invitations_mutation_response

  """
  delete single row from the table: "organization_invitations"
  """
  delete_organization_invitations_by_pk(id: String!): organization_invitations

  """
  delete data from the table: "organization_role_scope_relations"
  """
  delete_organization_role_scope_relations(
    """filter the rows which have to be deleted"""
    where: organization_role_scope_relations_bool_exp!
  ): organization_role_scope_relations_mutation_response

  """
  delete single row from the table: "organization_role_scope_relations"
  """
  delete_organization_role_scope_relations_by_pk(organization_role_id: String!, organization_scope_id: String!, tenant_id: String!): organization_role_scope_relations

  """
  delete data from the table: "organization_role_user_relations"
  """
  delete_organization_role_user_relations(
    """filter the rows which have to be deleted"""
    where: organization_role_user_relations_bool_exp!
  ): organization_role_user_relations_mutation_response

  """
  delete single row from the table: "organization_role_user_relations"
  """
  delete_organization_role_user_relations_by_pk(organization_id: String!, organization_role_id: String!, tenant_id: String!, user_id: String!): organization_role_user_relations

  """
  delete data from the table: "organization_roles"
  """
  delete_organization_roles(
    """filter the rows which have to be deleted"""
    where: organization_roles_bool_exp!
  ): organization_roles_mutation_response

  """
  delete single row from the table: "organization_roles"
  """
  delete_organization_roles_by_pk(id: String!): organization_roles

  """
  delete data from the table: "organization_scopes"
  """
  delete_organization_scopes(
    """filter the rows which have to be deleted"""
    where: organization_scopes_bool_exp!
  ): organization_scopes_mutation_response

  """
  delete single row from the table: "organization_scopes"
  """
  delete_organization_scopes_by_pk(id: String!): organization_scopes

  """
  delete data from the table: "organization_user_relations"
  """
  delete_organization_user_relations(
    """filter the rows which have to be deleted"""
    where: organization_user_relations_bool_exp!
  ): organization_user_relations_mutation_response

  """
  delete single row from the table: "organization_user_relations"
  """
  delete_organization_user_relations_by_pk(organization_id: String!, tenant_id: String!, user_id: String!): organization_user_relations

  """
  delete data from the table: "organizations"
  """
  delete_organizations(
    """filter the rows which have to be deleted"""
    where: organizations_bool_exp!
  ): organizations_mutation_response

  """
  delete single row from the table: "organizations"
  """
  delete_organizations_by_pk(id: String!): organizations

  """
  delete data from the table: "passcodes"
  """
  delete_passcodes(
    """filter the rows which have to be deleted"""
    where: passcodes_bool_exp!
  ): passcodes_mutation_response

  """
  delete single row from the table: "passcodes"
  """
  delete_passcodes_by_pk(id: String!): passcodes

  """
  delete data from the table: "resources"
  """
  delete_resources(
    """filter the rows which have to be deleted"""
    where: resources_bool_exp!
  ): resources_mutation_response

  """
  delete single row from the table: "resources"
  """
  delete_resources_by_pk(id: String!): resources

  """
  delete data from the table: "roles"
  """
  delete_roles(
    """filter the rows which have to be deleted"""
    where: roles_bool_exp!
  ): roles_mutation_response

  """
  delete single row from the table: "roles"
  """
  delete_roles_by_pk(id: String!): roles

  """
  delete data from the table: "roles_scopes"
  """
  delete_roles_scopes(
    """filter the rows which have to be deleted"""
    where: roles_scopes_bool_exp!
  ): roles_scopes_mutation_response

  """
  delete single row from the table: "roles_scopes"
  """
  delete_roles_scopes_by_pk(id: String!): roles_scopes

  """
  delete data from the table: "scopes"
  """
  delete_scopes(
    """filter the rows which have to be deleted"""
    where: scopes_bool_exp!
  ): scopes_mutation_response

  """
  delete single row from the table: "scopes"
  """
  delete_scopes_by_pk(id: String!): scopes

  """
  delete data from the table: "sentinel_activities"
  """
  delete_sentinel_activities(
    """filter the rows which have to be deleted"""
    where: sentinel_activities_bool_exp!
  ): sentinel_activities_mutation_response

  """
  delete single row from the table: "sentinel_activities"
  """
  delete_sentinel_activities_by_pk(id: String!): sentinel_activities

  """
  delete data from the table: "service_logs"
  """
  delete_service_logs(
    """filter the rows which have to be deleted"""
    where: service_logs_bool_exp!
  ): service_logs_mutation_response

  """
  delete single row from the table: "service_logs"
  """
  delete_service_logs_by_pk(id: String!): service_logs

  """
  delete data from the table: "sign_in_experiences"
  """
  delete_sign_in_experiences(
    """filter the rows which have to be deleted"""
    where: sign_in_experiences_bool_exp!
  ): sign_in_experiences_mutation_response

  """
  delete single row from the table: "sign_in_experiences"
  """
  delete_sign_in_experiences_by_pk(id: String!, tenant_id: String!): sign_in_experiences

  """
  delete data from the table: "sms_codes"
  """
  delete_sms_codes(
    """filter the rows which have to be deleted"""
    where: sms_codes_bool_exp!
  ): sms_codes_mutation_response

  """
  delete single row from the table: "sms_codes"
  """
  delete_sms_codes_by_pk(id: uuid!): sms_codes

  """
  delete data from the table: "sso_connectors"
  """
  delete_sso_connectors(
    """filter the rows which have to be deleted"""
    where: sso_connectors_bool_exp!
  ): sso_connectors_mutation_response

  """
  delete single row from the table: "sso_connectors"
  """
  delete_sso_connectors_by_pk(id: String!): sso_connectors

  """
  delete data from the table: "systems"
  """
  delete_systems(
    """filter the rows which have to be deleted"""
    where: systems_bool_exp!
  ): systems_mutation_response

  """
  delete single row from the table: "systems"
  """
  delete_systems_by_pk(key: String!): systems

  """
  delete data from the table: "tenants"
  """
  delete_tenants(
    """filter the rows which have to be deleted"""
    where: tenants_bool_exp!
  ): tenants_mutation_response

  """
  delete single row from the table: "tenants"
  """
  delete_tenants_by_pk(id: String!): tenants

  """
  delete data from the table: "user_cholesterol_standards"
  """
  delete_user_cholesterol_standards(
    """filter the rows which have to be deleted"""
    where: user_cholesterol_standards_bool_exp!
  ): user_cholesterol_standards_mutation_response

  """
  delete single row from the table: "user_cholesterol_standards"
  """
  delete_user_cholesterol_standards_by_pk(id: uuid!): user_cholesterol_standards

  """
  delete data from the table: "user_glucose_standards"
  """
  delete_user_glucose_standards(
    """filter the rows which have to be deleted"""
    where: user_glucose_standards_bool_exp!
  ): user_glucose_standards_mutation_response

  """
  delete single row from the table: "user_glucose_standards"
  """
  delete_user_glucose_standards_by_pk(id: uuid!): user_glucose_standards

  """
  delete data from the table: "user_sso_identities"
  """
  delete_user_sso_identities(
    """filter the rows which have to be deleted"""
    where: user_sso_identities_bool_exp!
  ): user_sso_identities_mutation_response

  """
  delete single row from the table: "user_sso_identities"
  """
  delete_user_sso_identities_by_pk(id: String!): user_sso_identities

  """
  delete data from the table: "users"
  """
  delete_users(
    """filter the rows which have to be deleted"""
    where: users_bool_exp!
  ): users_mutation_response

  """
  delete single row from the table: "users"
  """
  delete_users_by_pk(id: String!): users

  """
  delete data from the table: "users_roles"
  """
  delete_users_roles(
    """filter the rows which have to be deleted"""
    where: users_roles_bool_exp!
  ): users_roles_mutation_response

  """
  delete single row from the table: "users_roles"
  """
  delete_users_roles_by_pk(id: String!): users_roles

  """
  delete data from the table: "verification_statuses"
  """
  delete_verification_statuses(
    """filter the rows which have to be deleted"""
    where: verification_statuses_bool_exp!
  ): verification_statuses_mutation_response

  """
  delete single row from the table: "verification_statuses"
  """
  delete_verification_statuses_by_pk(id: String!): verification_statuses

  """
  This API call duplicates an existing file with new parameters. Requires permission UPLOAD
  """
  duplicate(duplicateInput: DuplicateInput!): File

  """
  This API call changes the name of the API key that is shown in the API overview. Requires permission API_MOD
  """
  friendlyname(apiKeyToModify: String!, friendlyName: String!): String!

  """
  insert data into the table: "ads"
  """
  insert_ads(
    """the rows to be inserted"""
    objects: [ads_insert_input!]!

    """upsert condition"""
    on_conflict: ads_on_conflict
  ): ads_mutation_response

  """
  insert a single row into the table: "ads"
  """
  insert_ads_one(
    """the row to be inserted"""
    object: ads_insert_input!

    """upsert condition"""
    on_conflict: ads_on_conflict
  ): ads

  """
  insert data into the table: "application_sign_in_experiences"
  """
  insert_application_sign_in_experiences(
    """the rows to be inserted"""
    objects: [application_sign_in_experiences_insert_input!]!

    """upsert condition"""
    on_conflict: application_sign_in_experiences_on_conflict
  ): application_sign_in_experiences_mutation_response

  """
  insert a single row into the table: "application_sign_in_experiences"
  """
  insert_application_sign_in_experiences_one(
    """the row to be inserted"""
    object: application_sign_in_experiences_insert_input!

    """upsert condition"""
    on_conflict: application_sign_in_experiences_on_conflict
  ): application_sign_in_experiences

  """
  insert data into the table: "application_user_consent_organization_scopes"
  """
  insert_application_user_consent_organization_scopes(
    """the rows to be inserted"""
    objects: [application_user_consent_organization_scopes_insert_input!]!

    """upsert condition"""
    on_conflict: application_user_consent_organization_scopes_on_conflict
  ): application_user_consent_organization_scopes_mutation_response

  """
  insert a single row into the table: "application_user_consent_organization_scopes"
  """
  insert_application_user_consent_organization_scopes_one(
    """the row to be inserted"""
    object: application_user_consent_organization_scopes_insert_input!

    """upsert condition"""
    on_conflict: application_user_consent_organization_scopes_on_conflict
  ): application_user_consent_organization_scopes

  """
  insert data into the table: "application_user_consent_organizations"
  """
  insert_application_user_consent_organizations(
    """the rows to be inserted"""
    objects: [application_user_consent_organizations_insert_input!]!

    """upsert condition"""
    on_conflict: application_user_consent_organizations_on_conflict
  ): application_user_consent_organizations_mutation_response

  """
  insert a single row into the table: "application_user_consent_organizations"
  """
  insert_application_user_consent_organizations_one(
    """the row to be inserted"""
    object: application_user_consent_organizations_insert_input!

    """upsert condition"""
    on_conflict: application_user_consent_organizations_on_conflict
  ): application_user_consent_organizations

  """
  insert data into the table: "application_user_consent_resource_scopes"
  """
  insert_application_user_consent_resource_scopes(
    """the rows to be inserted"""
    objects: [application_user_consent_resource_scopes_insert_input!]!

    """upsert condition"""
    on_conflict: application_user_consent_resource_scopes_on_conflict
  ): application_user_consent_resource_scopes_mutation_response

  """
  insert a single row into the table: "application_user_consent_resource_scopes"
  """
  insert_application_user_consent_resource_scopes_one(
    """the row to be inserted"""
    object: application_user_consent_resource_scopes_insert_input!

    """upsert condition"""
    on_conflict: application_user_consent_resource_scopes_on_conflict
  ): application_user_consent_resource_scopes

  """
  insert data into the table: "application_user_consent_user_scopes"
  """
  insert_application_user_consent_user_scopes(
    """the rows to be inserted"""
    objects: [application_user_consent_user_scopes_insert_input!]!

    """upsert condition"""
    on_conflict: application_user_consent_user_scopes_on_conflict
  ): application_user_consent_user_scopes_mutation_response

  """
  insert a single row into the table: "application_user_consent_user_scopes"
  """
  insert_application_user_consent_user_scopes_one(
    """the row to be inserted"""
    object: application_user_consent_user_scopes_insert_input!

    """upsert condition"""
    on_conflict: application_user_consent_user_scopes_on_conflict
  ): application_user_consent_user_scopes

  """
  insert data into the table: "applications"
  """
  insert_applications(
    """the rows to be inserted"""
    objects: [applications_insert_input!]!

    """upsert condition"""
    on_conflict: applications_on_conflict
  ): applications_mutation_response

  """
  insert a single row into the table: "applications"
  """
  insert_applications_one(
    """the row to be inserted"""
    object: applications_insert_input!

    """upsert condition"""
    on_conflict: applications_on_conflict
  ): applications

  """
  insert data into the table: "applications_roles"
  """
  insert_applications_roles(
    """the rows to be inserted"""
    objects: [applications_roles_insert_input!]!

    """upsert condition"""
    on_conflict: applications_roles_on_conflict
  ): applications_roles_mutation_response

  """
  insert a single row into the table: "applications_roles"
  """
  insert_applications_roles_one(
    """the row to be inserted"""
    object: applications_roles_insert_input!

    """upsert condition"""
    on_conflict: applications_roles_on_conflict
  ): applications_roles

  """
  insert data into the table: "check_in_settings"
  """
  insert_check_in_settings(
    """the rows to be inserted"""
    objects: [check_in_settings_insert_input!]!

    """upsert condition"""
    on_conflict: check_in_settings_on_conflict
  ): check_in_settings_mutation_response

  """
  insert a single row into the table: "check_in_settings"
  """
  insert_check_in_settings_one(
    """the row to be inserted"""
    object: check_in_settings_insert_input!

    """upsert condition"""
    on_conflict: check_in_settings_on_conflict
  ): check_in_settings

  """
  insert data into the table: "check_ins"
  """
  insert_check_ins(
    """the rows to be inserted"""
    objects: [check_ins_insert_input!]!

    """upsert condition"""
    on_conflict: check_ins_on_conflict
  ): check_ins_mutation_response

  """
  insert a single row into the table: "check_ins"
  """
  insert_check_ins_one(
    """the row to be inserted"""
    object: check_ins_insert_input!

    """upsert condition"""
    on_conflict: check_ins_on_conflict
  ): check_ins

  """
  insert data into the table: "cholesterol_records"
  """
  insert_cholesterol_records(
    """the rows to be inserted"""
    objects: [cholesterol_records_insert_input!]!

    """upsert condition"""
    on_conflict: cholesterol_records_on_conflict
  ): cholesterol_records_mutation_response

  """
  insert a single row into the table: "cholesterol_records"
  """
  insert_cholesterol_records_one(
    """the row to be inserted"""
    object: cholesterol_records_insert_input!

    """upsert condition"""
    on_conflict: cholesterol_records_on_conflict
  ): cholesterol_records

  """
  insert data into the table: "cholesterol_standards"
  """
  insert_cholesterol_standards(
    """the rows to be inserted"""
    objects: [cholesterol_standards_insert_input!]!

    """upsert condition"""
    on_conflict: cholesterol_standards_on_conflict
  ): cholesterol_standards_mutation_response

  """
  insert a single row into the table: "cholesterol_standards"
  """
  insert_cholesterol_standards_one(
    """the row to be inserted"""
    object: cholesterol_standards_insert_input!

    """upsert condition"""
    on_conflict: cholesterol_standards_on_conflict
  ): cholesterol_standards

  """
  insert data into the table: "connectors"
  """
  insert_connectors(
    """the rows to be inserted"""
    objects: [connectors_insert_input!]!

    """upsert condition"""
    on_conflict: connectors_on_conflict
  ): connectors_mutation_response

  """
  insert a single row into the table: "connectors"
  """
  insert_connectors_one(
    """the row to be inserted"""
    object: connectors_insert_input!

    """upsert condition"""
    on_conflict: connectors_on_conflict
  ): connectors

  """
  insert data into the table: "custom_phrases"
  """
  insert_custom_phrases(
    """the rows to be inserted"""
    objects: [custom_phrases_insert_input!]!

    """upsert condition"""
    on_conflict: custom_phrases_on_conflict
  ): custom_phrases_mutation_response

  """
  insert a single row into the table: "custom_phrases"
  """
  insert_custom_phrases_one(
    """the row to be inserted"""
    object: custom_phrases_insert_input!

    """upsert condition"""
    on_conflict: custom_phrases_on_conflict
  ): custom_phrases

  """
  insert data into the table: "daily_active_users"
  """
  insert_daily_active_users(
    """the rows to be inserted"""
    objects: [daily_active_users_insert_input!]!

    """upsert condition"""
    on_conflict: daily_active_users_on_conflict
  ): daily_active_users_mutation_response

  """
  insert a single row into the table: "daily_active_users"
  """
  insert_daily_active_users_one(
    """the row to be inserted"""
    object: daily_active_users_insert_input!

    """upsert condition"""
    on_conflict: daily_active_users_on_conflict
  ): daily_active_users

  """
  insert data into the table: "daily_token_usage"
  """
  insert_daily_token_usage(
    """the rows to be inserted"""
    objects: [daily_token_usage_insert_input!]!

    """upsert condition"""
    on_conflict: daily_token_usage_on_conflict
  ): daily_token_usage_mutation_response

  """
  insert a single row into the table: "daily_token_usage"
  """
  insert_daily_token_usage_one(
    """the row to be inserted"""
    object: daily_token_usage_insert_input!

    """upsert condition"""
    on_conflict: daily_token_usage_on_conflict
  ): daily_token_usage

  """
  insert data into the table: "domains"
  """
  insert_domains(
    """the rows to be inserted"""
    objects: [domains_insert_input!]!

    """upsert condition"""
    on_conflict: domains_on_conflict
  ): domains_mutation_response

  """
  insert a single row into the table: "domains"
  """
  insert_domains_one(
    """the row to be inserted"""
    object: domains_insert_input!

    """upsert condition"""
    on_conflict: domains_on_conflict
  ): domains

  """
  insert data into the table: "glucose_records"
  """
  insert_glucose_records(
    """the rows to be inserted"""
    objects: [glucose_records_insert_input!]!

    """upsert condition"""
    on_conflict: glucose_records_on_conflict
  ): glucose_records_mutation_response

  """
  insert a single row into the table: "glucose_records"
  """
  insert_glucose_records_one(
    """the row to be inserted"""
    object: glucose_records_insert_input!

    """upsert condition"""
    on_conflict: glucose_records_on_conflict
  ): glucose_records

  """
  insert data into the table: "glucose_standards"
  """
  insert_glucose_standards(
    """the rows to be inserted"""
    objects: [glucose_standards_insert_input!]!

    """upsert condition"""
    on_conflict: glucose_standards_on_conflict
  ): glucose_standards_mutation_response

  """
  insert a single row into the table: "glucose_standards"
  """
  insert_glucose_standards_one(
    """the row to be inserted"""
    object: glucose_standards_insert_input!

    """upsert condition"""
    on_conflict: glucose_standards_on_conflict
  ): glucose_standards

  """
  insert data into the table: "hooks"
  """
  insert_hooks(
    """the rows to be inserted"""
    objects: [hooks_insert_input!]!

    """upsert condition"""
    on_conflict: hooks_on_conflict
  ): hooks_mutation_response

  """
  insert a single row into the table: "hooks"
  """
  insert_hooks_one(
    """the row to be inserted"""
    object: hooks_insert_input!

    """upsert condition"""
    on_conflict: hooks_on_conflict
  ): hooks

  """
  insert data into the table: "lab_report_records"
  """
  insert_lab_report_records(
    """the rows to be inserted"""
    objects: [lab_report_records_insert_input!]!

    """upsert condition"""
    on_conflict: lab_report_records_on_conflict
  ): lab_report_records_mutation_response

  """
  insert a single row into the table: "lab_report_records"
  """
  insert_lab_report_records_one(
    """the row to be inserted"""
    object: lab_report_records_insert_input!

    """upsert condition"""
    on_conflict: lab_report_records_on_conflict
  ): lab_report_records

  """
  insert data into the table: "logs"
  """
  insert_logs(
    """the rows to be inserted"""
    objects: [logs_insert_input!]!

    """upsert condition"""
    on_conflict: logs_on_conflict
  ): logs_mutation_response

  """
  insert a single row into the table: "logs"
  """
  insert_logs_one(
    """the row to be inserted"""
    object: logs_insert_input!

    """upsert condition"""
    on_conflict: logs_on_conflict
  ): logs

  """
  insert data into the table: "logto_configs"
  """
  insert_logto_configs(
    """the rows to be inserted"""
    objects: [logto_configs_insert_input!]!

    """upsert condition"""
    on_conflict: logto_configs_on_conflict
  ): logto_configs_mutation_response

  """
  insert a single row into the table: "logto_configs"
  """
  insert_logto_configs_one(
    """the row to be inserted"""
    object: logto_configs_insert_input!

    """upsert condition"""
    on_conflict: logto_configs_on_conflict
  ): logto_configs

  """
  insert data into the table: "medical_examination_records"
  """
  insert_medical_examination_records(
    """the rows to be inserted"""
    objects: [medical_examination_records_insert_input!]!

    """upsert condition"""
    on_conflict: medical_examination_records_on_conflict
  ): medical_examination_records_mutation_response

  """
  insert a single row into the table: "medical_examination_records"
  """
  insert_medical_examination_records_one(
    """the row to be inserted"""
    object: medical_examination_records_insert_input!

    """upsert condition"""
    on_conflict: medical_examination_records_on_conflict
  ): medical_examination_records

  """
  insert data into the table: "medication_reminders"
  """
  insert_medication_reminders(
    """the rows to be inserted"""
    objects: [medication_reminders_insert_input!]!

    """upsert condition"""
    on_conflict: medication_reminders_on_conflict
  ): medication_reminders_mutation_response

  """
  insert a single row into the table: "medication_reminders"
  """
  insert_medication_reminders_one(
    """the row to be inserted"""
    object: medication_reminders_insert_input!

    """upsert condition"""
    on_conflict: medication_reminders_on_conflict
  ): medication_reminders

  """
  insert data into the table: "oidc_model_instances"
  """
  insert_oidc_model_instances(
    """the rows to be inserted"""
    objects: [oidc_model_instances_insert_input!]!

    """upsert condition"""
    on_conflict: oidc_model_instances_on_conflict
  ): oidc_model_instances_mutation_response

  """
  insert a single row into the table: "oidc_model_instances"
  """
  insert_oidc_model_instances_one(
    """the row to be inserted"""
    object: oidc_model_instances_insert_input!

    """upsert condition"""
    on_conflict: oidc_model_instances_on_conflict
  ): oidc_model_instances

  """
  insert data into the table: "organization_invitation_role_relations"
  """
  insert_organization_invitation_role_relations(
    """the rows to be inserted"""
    objects: [organization_invitation_role_relations_insert_input!]!

    """upsert condition"""
    on_conflict: organization_invitation_role_relations_on_conflict
  ): organization_invitation_role_relations_mutation_response

  """
  insert a single row into the table: "organization_invitation_role_relations"
  """
  insert_organization_invitation_role_relations_one(
    """the row to be inserted"""
    object: organization_invitation_role_relations_insert_input!

    """upsert condition"""
    on_conflict: organization_invitation_role_relations_on_conflict
  ): organization_invitation_role_relations

  """
  insert data into the table: "organization_invitations"
  """
  insert_organization_invitations(
    """the rows to be inserted"""
    objects: [organization_invitations_insert_input!]!

    """upsert condition"""
    on_conflict: organization_invitations_on_conflict
  ): organization_invitations_mutation_response

  """
  insert a single row into the table: "organization_invitations"
  """
  insert_organization_invitations_one(
    """the row to be inserted"""
    object: organization_invitations_insert_input!

    """upsert condition"""
    on_conflict: organization_invitations_on_conflict
  ): organization_invitations

  """
  insert data into the table: "organization_role_scope_relations"
  """
  insert_organization_role_scope_relations(
    """the rows to be inserted"""
    objects: [organization_role_scope_relations_insert_input!]!

    """upsert condition"""
    on_conflict: organization_role_scope_relations_on_conflict
  ): organization_role_scope_relations_mutation_response

  """
  insert a single row into the table: "organization_role_scope_relations"
  """
  insert_organization_role_scope_relations_one(
    """the row to be inserted"""
    object: organization_role_scope_relations_insert_input!

    """upsert condition"""
    on_conflict: organization_role_scope_relations_on_conflict
  ): organization_role_scope_relations

  """
  insert data into the table: "organization_role_user_relations"
  """
  insert_organization_role_user_relations(
    """the rows to be inserted"""
    objects: [organization_role_user_relations_insert_input!]!

    """upsert condition"""
    on_conflict: organization_role_user_relations_on_conflict
  ): organization_role_user_relations_mutation_response

  """
  insert a single row into the table: "organization_role_user_relations"
  """
  insert_organization_role_user_relations_one(
    """the row to be inserted"""
    object: organization_role_user_relations_insert_input!

    """upsert condition"""
    on_conflict: organization_role_user_relations_on_conflict
  ): organization_role_user_relations

  """
  insert data into the table: "organization_roles"
  """
  insert_organization_roles(
    """the rows to be inserted"""
    objects: [organization_roles_insert_input!]!

    """upsert condition"""
    on_conflict: organization_roles_on_conflict
  ): organization_roles_mutation_response

  """
  insert a single row into the table: "organization_roles"
  """
  insert_organization_roles_one(
    """the row to be inserted"""
    object: organization_roles_insert_input!

    """upsert condition"""
    on_conflict: organization_roles_on_conflict
  ): organization_roles

  """
  insert data into the table: "organization_scopes"
  """
  insert_organization_scopes(
    """the rows to be inserted"""
    objects: [organization_scopes_insert_input!]!

    """upsert condition"""
    on_conflict: organization_scopes_on_conflict
  ): organization_scopes_mutation_response

  """
  insert a single row into the table: "organization_scopes"
  """
  insert_organization_scopes_one(
    """the row to be inserted"""
    object: organization_scopes_insert_input!

    """upsert condition"""
    on_conflict: organization_scopes_on_conflict
  ): organization_scopes

  """
  insert data into the table: "organization_user_relations"
  """
  insert_organization_user_relations(
    """the rows to be inserted"""
    objects: [organization_user_relations_insert_input!]!

    """upsert condition"""
    on_conflict: organization_user_relations_on_conflict
  ): organization_user_relations_mutation_response

  """
  insert a single row into the table: "organization_user_relations"
  """
  insert_organization_user_relations_one(
    """the row to be inserted"""
    object: organization_user_relations_insert_input!

    """upsert condition"""
    on_conflict: organization_user_relations_on_conflict
  ): organization_user_relations

  """
  insert data into the table: "organizations"
  """
  insert_organizations(
    """the rows to be inserted"""
    objects: [organizations_insert_input!]!

    """upsert condition"""
    on_conflict: organizations_on_conflict
  ): organizations_mutation_response

  """
  insert a single row into the table: "organizations"
  """
  insert_organizations_one(
    """the row to be inserted"""
    object: organizations_insert_input!

    """upsert condition"""
    on_conflict: organizations_on_conflict
  ): organizations

  """
  insert data into the table: "passcodes"
  """
  insert_passcodes(
    """the rows to be inserted"""
    objects: [passcodes_insert_input!]!

    """upsert condition"""
    on_conflict: passcodes_on_conflict
  ): passcodes_mutation_response

  """
  insert a single row into the table: "passcodes"
  """
  insert_passcodes_one(
    """the row to be inserted"""
    object: passcodes_insert_input!

    """upsert condition"""
    on_conflict: passcodes_on_conflict
  ): passcodes

  """
  insert data into the table: "resources"
  """
  insert_resources(
    """the rows to be inserted"""
    objects: [resources_insert_input!]!

    """upsert condition"""
    on_conflict: resources_on_conflict
  ): resources_mutation_response

  """
  insert a single row into the table: "resources"
  """
  insert_resources_one(
    """the row to be inserted"""
    object: resources_insert_input!

    """upsert condition"""
    on_conflict: resources_on_conflict
  ): resources

  """
  insert data into the table: "roles"
  """
  insert_roles(
    """the rows to be inserted"""
    objects: [roles_insert_input!]!

    """upsert condition"""
    on_conflict: roles_on_conflict
  ): roles_mutation_response

  """
  insert a single row into the table: "roles"
  """
  insert_roles_one(
    """the row to be inserted"""
    object: roles_insert_input!

    """upsert condition"""
    on_conflict: roles_on_conflict
  ): roles

  """
  insert data into the table: "roles_scopes"
  """
  insert_roles_scopes(
    """the rows to be inserted"""
    objects: [roles_scopes_insert_input!]!

    """upsert condition"""
    on_conflict: roles_scopes_on_conflict
  ): roles_scopes_mutation_response

  """
  insert a single row into the table: "roles_scopes"
  """
  insert_roles_scopes_one(
    """the row to be inserted"""
    object: roles_scopes_insert_input!

    """upsert condition"""
    on_conflict: roles_scopes_on_conflict
  ): roles_scopes

  """
  insert data into the table: "scopes"
  """
  insert_scopes(
    """the rows to be inserted"""
    objects: [scopes_insert_input!]!

    """upsert condition"""
    on_conflict: scopes_on_conflict
  ): scopes_mutation_response

  """
  insert a single row into the table: "scopes"
  """
  insert_scopes_one(
    """the row to be inserted"""
    object: scopes_insert_input!

    """upsert condition"""
    on_conflict: scopes_on_conflict
  ): scopes

  """
  insert data into the table: "sentinel_activities"
  """
  insert_sentinel_activities(
    """the rows to be inserted"""
    objects: [sentinel_activities_insert_input!]!

    """upsert condition"""
    on_conflict: sentinel_activities_on_conflict
  ): sentinel_activities_mutation_response

  """
  insert a single row into the table: "sentinel_activities"
  """
  insert_sentinel_activities_one(
    """the row to be inserted"""
    object: sentinel_activities_insert_input!

    """upsert condition"""
    on_conflict: sentinel_activities_on_conflict
  ): sentinel_activities

  """
  insert data into the table: "service_logs"
  """
  insert_service_logs(
    """the rows to be inserted"""
    objects: [service_logs_insert_input!]!

    """upsert condition"""
    on_conflict: service_logs_on_conflict
  ): service_logs_mutation_response

  """
  insert a single row into the table: "service_logs"
  """
  insert_service_logs_one(
    """the row to be inserted"""
    object: service_logs_insert_input!

    """upsert condition"""
    on_conflict: service_logs_on_conflict
  ): service_logs

  """
  insert data into the table: "sign_in_experiences"
  """
  insert_sign_in_experiences(
    """the rows to be inserted"""
    objects: [sign_in_experiences_insert_input!]!

    """upsert condition"""
    on_conflict: sign_in_experiences_on_conflict
  ): sign_in_experiences_mutation_response

  """
  insert a single row into the table: "sign_in_experiences"
  """
  insert_sign_in_experiences_one(
    """the row to be inserted"""
    object: sign_in_experiences_insert_input!

    """upsert condition"""
    on_conflict: sign_in_experiences_on_conflict
  ): sign_in_experiences

  """
  insert data into the table: "sms_codes"
  """
  insert_sms_codes(
    """the rows to be inserted"""
    objects: [sms_codes_insert_input!]!

    """upsert condition"""
    on_conflict: sms_codes_on_conflict
  ): sms_codes_mutation_response

  """
  insert a single row into the table: "sms_codes"
  """
  insert_sms_codes_one(
    """the row to be inserted"""
    object: sms_codes_insert_input!

    """upsert condition"""
    on_conflict: sms_codes_on_conflict
  ): sms_codes

  """
  insert data into the table: "sso_connectors"
  """
  insert_sso_connectors(
    """the rows to be inserted"""
    objects: [sso_connectors_insert_input!]!

    """upsert condition"""
    on_conflict: sso_connectors_on_conflict
  ): sso_connectors_mutation_response

  """
  insert a single row into the table: "sso_connectors"
  """
  insert_sso_connectors_one(
    """the row to be inserted"""
    object: sso_connectors_insert_input!

    """upsert condition"""
    on_conflict: sso_connectors_on_conflict
  ): sso_connectors

  """
  insert data into the table: "systems"
  """
  insert_systems(
    """the rows to be inserted"""
    objects: [systems_insert_input!]!

    """upsert condition"""
    on_conflict: systems_on_conflict
  ): systems_mutation_response

  """
  insert a single row into the table: "systems"
  """
  insert_systems_one(
    """the row to be inserted"""
    object: systems_insert_input!

    """upsert condition"""
    on_conflict: systems_on_conflict
  ): systems

  """
  insert data into the table: "tenants"
  """
  insert_tenants(
    """the rows to be inserted"""
    objects: [tenants_insert_input!]!

    """upsert condition"""
    on_conflict: tenants_on_conflict
  ): tenants_mutation_response

  """
  insert a single row into the table: "tenants"
  """
  insert_tenants_one(
    """the row to be inserted"""
    object: tenants_insert_input!

    """upsert condition"""
    on_conflict: tenants_on_conflict
  ): tenants

  """
  insert data into the table: "user_cholesterol_standards"
  """
  insert_user_cholesterol_standards(
    """the rows to be inserted"""
    objects: [user_cholesterol_standards_insert_input!]!

    """upsert condition"""
    on_conflict: user_cholesterol_standards_on_conflict
  ): user_cholesterol_standards_mutation_response

  """
  insert a single row into the table: "user_cholesterol_standards"
  """
  insert_user_cholesterol_standards_one(
    """the row to be inserted"""
    object: user_cholesterol_standards_insert_input!

    """upsert condition"""
    on_conflict: user_cholesterol_standards_on_conflict
  ): user_cholesterol_standards

  """
  insert data into the table: "user_glucose_standards"
  """
  insert_user_glucose_standards(
    """the rows to be inserted"""
    objects: [user_glucose_standards_insert_input!]!

    """upsert condition"""
    on_conflict: user_glucose_standards_on_conflict
  ): user_glucose_standards_mutation_response

  """
  insert a single row into the table: "user_glucose_standards"
  """
  insert_user_glucose_standards_one(
    """the row to be inserted"""
    object: user_glucose_standards_insert_input!

    """upsert condition"""
    on_conflict: user_glucose_standards_on_conflict
  ): user_glucose_standards

  """
  insert data into the table: "user_sso_identities"
  """
  insert_user_sso_identities(
    """the rows to be inserted"""
    objects: [user_sso_identities_insert_input!]!

    """upsert condition"""
    on_conflict: user_sso_identities_on_conflict
  ): user_sso_identities_mutation_response

  """
  insert a single row into the table: "user_sso_identities"
  """
  insert_user_sso_identities_one(
    """the row to be inserted"""
    object: user_sso_identities_insert_input!

    """upsert condition"""
    on_conflict: user_sso_identities_on_conflict
  ): user_sso_identities

  """
  insert data into the table: "users"
  """
  insert_users(
    """the rows to be inserted"""
    objects: [users_insert_input!]!

    """upsert condition"""
    on_conflict: users_on_conflict
  ): users_mutation_response

  """
  insert a single row into the table: "users"
  """
  insert_users_one(
    """the row to be inserted"""
    object: users_insert_input!

    """upsert condition"""
    on_conflict: users_on_conflict
  ): users

  """
  insert data into the table: "users_roles"
  """
  insert_users_roles(
    """the rows to be inserted"""
    objects: [users_roles_insert_input!]!

    """upsert condition"""
    on_conflict: users_roles_on_conflict
  ): users_roles_mutation_response

  """
  insert a single row into the table: "users_roles"
  """
  insert_users_roles_one(
    """the row to be inserted"""
    object: users_roles_insert_input!

    """upsert condition"""
    on_conflict: users_roles_on_conflict
  ): users_roles

  """
  insert data into the table: "verification_statuses"
  """
  insert_verification_statuses(
    """the rows to be inserted"""
    objects: [verification_statuses_insert_input!]!

    """upsert condition"""
    on_conflict: verification_statuses_on_conflict
  ): verification_statuses_mutation_response

  """
  insert a single row into the table: "verification_statuses"
  """
  insert_verification_statuses_one(
    """the row to be inserted"""
    object: verification_statuses_insert_input!

    """upsert condition"""
    on_conflict: verification_statuses_on_conflict
  ): verification_statuses

  """
  This API call changes parameters of an uploaded file.  Requires permission EDIT
  """
  modifyfile(allowedDownloads: Int, expiryTimestamp: Int, id: String!, originalPassword: Boolean, password: String): File

  """
  This API call changes the permissions for the given API key. Requires permission API_MOD
  """
  modifypermission(apiKeyToModify: String!, permission: Permission!, permissionModifier: PermissionModifier!): String!

  """上传文件"""
  s3Upload(file: Upload!): S3UploadOutput

  """
  update data of the table: "ads"
  """
  update_ads(
    """increments the numeric columns with given value of the filtered values"""
    _inc: ads_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: ads_set_input

    """filter the rows which have to be updated"""
    where: ads_bool_exp!
  ): ads_mutation_response

  """
  update single row of the table: "ads"
  """
  update_ads_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: ads_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: ads_set_input
    pk_columns: ads_pk_columns_input!
  ): ads

  """
  update multiples rows of table: "ads"
  """
  update_ads_many(
    """updates to execute, in order"""
    updates: [ads_updates!]!
  ): [ads_mutation_response]

  """
  update data of the table: "application_sign_in_experiences"
  """
  update_application_sign_in_experiences(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: application_sign_in_experiences_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: application_sign_in_experiences_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: application_sign_in_experiences_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: application_sign_in_experiences_delete_key_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: application_sign_in_experiences_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: application_sign_in_experiences_set_input

    """filter the rows which have to be updated"""
    where: application_sign_in_experiences_bool_exp!
  ): application_sign_in_experiences_mutation_response

  """
  update single row of the table: "application_sign_in_experiences"
  """
  update_application_sign_in_experiences_by_pk(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: application_sign_in_experiences_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: application_sign_in_experiences_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: application_sign_in_experiences_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: application_sign_in_experiences_delete_key_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: application_sign_in_experiences_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: application_sign_in_experiences_set_input
    pk_columns: application_sign_in_experiences_pk_columns_input!
  ): application_sign_in_experiences

  """
  update multiples rows of table: "application_sign_in_experiences"
  """
  update_application_sign_in_experiences_many(
    """updates to execute, in order"""
    updates: [application_sign_in_experiences_updates!]!
  ): [application_sign_in_experiences_mutation_response]

  """
  update data of the table: "application_user_consent_organization_scopes"
  """
  update_application_user_consent_organization_scopes(
    """sets the columns of the filtered rows to the given values"""
    _set: application_user_consent_organization_scopes_set_input

    """filter the rows which have to be updated"""
    where: application_user_consent_organization_scopes_bool_exp!
  ): application_user_consent_organization_scopes_mutation_response

  """
  update single row of the table: "application_user_consent_organization_scopes"
  """
  update_application_user_consent_organization_scopes_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: application_user_consent_organization_scopes_set_input
    pk_columns: application_user_consent_organization_scopes_pk_columns_input!
  ): application_user_consent_organization_scopes

  """
  update multiples rows of table: "application_user_consent_organization_scopes"
  """
  update_application_user_consent_organization_scopes_many(
    """updates to execute, in order"""
    updates: [application_user_consent_organization_scopes_updates!]!
  ): [application_user_consent_organization_scopes_mutation_response]

  """
  update data of the table: "application_user_consent_organizations"
  """
  update_application_user_consent_organizations(
    """sets the columns of the filtered rows to the given values"""
    _set: application_user_consent_organizations_set_input

    """filter the rows which have to be updated"""
    where: application_user_consent_organizations_bool_exp!
  ): application_user_consent_organizations_mutation_response

  """
  update single row of the table: "application_user_consent_organizations"
  """
  update_application_user_consent_organizations_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: application_user_consent_organizations_set_input
    pk_columns: application_user_consent_organizations_pk_columns_input!
  ): application_user_consent_organizations

  """
  update multiples rows of table: "application_user_consent_organizations"
  """
  update_application_user_consent_organizations_many(
    """updates to execute, in order"""
    updates: [application_user_consent_organizations_updates!]!
  ): [application_user_consent_organizations_mutation_response]

  """
  update data of the table: "application_user_consent_resource_scopes"
  """
  update_application_user_consent_resource_scopes(
    """sets the columns of the filtered rows to the given values"""
    _set: application_user_consent_resource_scopes_set_input

    """filter the rows which have to be updated"""
    where: application_user_consent_resource_scopes_bool_exp!
  ): application_user_consent_resource_scopes_mutation_response

  """
  update single row of the table: "application_user_consent_resource_scopes"
  """
  update_application_user_consent_resource_scopes_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: application_user_consent_resource_scopes_set_input
    pk_columns: application_user_consent_resource_scopes_pk_columns_input!
  ): application_user_consent_resource_scopes

  """
  update multiples rows of table: "application_user_consent_resource_scopes"
  """
  update_application_user_consent_resource_scopes_many(
    """updates to execute, in order"""
    updates: [application_user_consent_resource_scopes_updates!]!
  ): [application_user_consent_resource_scopes_mutation_response]

  """
  update data of the table: "application_user_consent_user_scopes"
  """
  update_application_user_consent_user_scopes(
    """sets the columns of the filtered rows to the given values"""
    _set: application_user_consent_user_scopes_set_input

    """filter the rows which have to be updated"""
    where: application_user_consent_user_scopes_bool_exp!
  ): application_user_consent_user_scopes_mutation_response

  """
  update single row of the table: "application_user_consent_user_scopes"
  """
  update_application_user_consent_user_scopes_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: application_user_consent_user_scopes_set_input
    pk_columns: application_user_consent_user_scopes_pk_columns_input!
  ): application_user_consent_user_scopes

  """
  update multiples rows of table: "application_user_consent_user_scopes"
  """
  update_application_user_consent_user_scopes_many(
    """updates to execute, in order"""
    updates: [application_user_consent_user_scopes_updates!]!
  ): [application_user_consent_user_scopes_mutation_response]

  """
  update data of the table: "applications"
  """
  update_applications(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: applications_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: applications_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: applications_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: applications_delete_key_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: applications_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: applications_set_input

    """filter the rows which have to be updated"""
    where: applications_bool_exp!
  ): applications_mutation_response

  """
  update single row of the table: "applications"
  """
  update_applications_by_pk(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: applications_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: applications_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: applications_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: applications_delete_key_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: applications_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: applications_set_input
    pk_columns: applications_pk_columns_input!
  ): applications

  """
  update multiples rows of table: "applications"
  """
  update_applications_many(
    """updates to execute, in order"""
    updates: [applications_updates!]!
  ): [applications_mutation_response]

  """
  update data of the table: "applications_roles"
  """
  update_applications_roles(
    """sets the columns of the filtered rows to the given values"""
    _set: applications_roles_set_input

    """filter the rows which have to be updated"""
    where: applications_roles_bool_exp!
  ): applications_roles_mutation_response

  """
  update single row of the table: "applications_roles"
  """
  update_applications_roles_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: applications_roles_set_input
    pk_columns: applications_roles_pk_columns_input!
  ): applications_roles

  """
  update multiples rows of table: "applications_roles"
  """
  update_applications_roles_many(
    """updates to execute, in order"""
    updates: [applications_roles_updates!]!
  ): [applications_roles_mutation_response]

  """
  update data of the table: "check_in_settings"
  """
  update_check_in_settings(
    """increments the numeric columns with given value of the filtered values"""
    _inc: check_in_settings_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: check_in_settings_set_input

    """filter the rows which have to be updated"""
    where: check_in_settings_bool_exp!
  ): check_in_settings_mutation_response

  """
  update single row of the table: "check_in_settings"
  """
  update_check_in_settings_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: check_in_settings_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: check_in_settings_set_input
    pk_columns: check_in_settings_pk_columns_input!
  ): check_in_settings

  """
  update multiples rows of table: "check_in_settings"
  """
  update_check_in_settings_many(
    """updates to execute, in order"""
    updates: [check_in_settings_updates!]!
  ): [check_in_settings_mutation_response]

  """
  update data of the table: "check_ins"
  """
  update_check_ins(
    """increments the numeric columns with given value of the filtered values"""
    _inc: check_ins_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: check_ins_set_input

    """filter the rows which have to be updated"""
    where: check_ins_bool_exp!
  ): check_ins_mutation_response

  """
  update single row of the table: "check_ins"
  """
  update_check_ins_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: check_ins_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: check_ins_set_input
    pk_columns: check_ins_pk_columns_input!
  ): check_ins

  """
  update multiples rows of table: "check_ins"
  """
  update_check_ins_many(
    """updates to execute, in order"""
    updates: [check_ins_updates!]!
  ): [check_ins_mutation_response]

  """
  update data of the table: "cholesterol_records"
  """
  update_cholesterol_records(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: cholesterol_records_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: cholesterol_records_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: cholesterol_records_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: cholesterol_records_delete_key_input

    """increments the numeric columns with given value of the filtered values"""
    _inc: cholesterol_records_inc_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: cholesterol_records_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: cholesterol_records_set_input

    """filter the rows which have to be updated"""
    where: cholesterol_records_bool_exp!
  ): cholesterol_records_mutation_response

  """
  update single row of the table: "cholesterol_records"
  """
  update_cholesterol_records_by_pk(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: cholesterol_records_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: cholesterol_records_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: cholesterol_records_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: cholesterol_records_delete_key_input

    """increments the numeric columns with given value of the filtered values"""
    _inc: cholesterol_records_inc_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: cholesterol_records_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: cholesterol_records_set_input
    pk_columns: cholesterol_records_pk_columns_input!
  ): cholesterol_records

  """
  update multiples rows of table: "cholesterol_records"
  """
  update_cholesterol_records_many(
    """updates to execute, in order"""
    updates: [cholesterol_records_updates!]!
  ): [cholesterol_records_mutation_response]

  """
  update data of the table: "cholesterol_standards"
  """
  update_cholesterol_standards(
    """increments the numeric columns with given value of the filtered values"""
    _inc: cholesterol_standards_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: cholesterol_standards_set_input

    """filter the rows which have to be updated"""
    where: cholesterol_standards_bool_exp!
  ): cholesterol_standards_mutation_response

  """
  update single row of the table: "cholesterol_standards"
  """
  update_cholesterol_standards_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: cholesterol_standards_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: cholesterol_standards_set_input
    pk_columns: cholesterol_standards_pk_columns_input!
  ): cholesterol_standards

  """
  update multiples rows of table: "cholesterol_standards"
  """
  update_cholesterol_standards_many(
    """updates to execute, in order"""
    updates: [cholesterol_standards_updates!]!
  ): [cholesterol_standards_mutation_response]

  """
  update data of the table: "connectors"
  """
  update_connectors(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: connectors_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: connectors_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: connectors_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: connectors_delete_key_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: connectors_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: connectors_set_input

    """filter the rows which have to be updated"""
    where: connectors_bool_exp!
  ): connectors_mutation_response

  """
  update single row of the table: "connectors"
  """
  update_connectors_by_pk(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: connectors_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: connectors_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: connectors_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: connectors_delete_key_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: connectors_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: connectors_set_input
    pk_columns: connectors_pk_columns_input!
  ): connectors

  """
  update multiples rows of table: "connectors"
  """
  update_connectors_many(
    """updates to execute, in order"""
    updates: [connectors_updates!]!
  ): [connectors_mutation_response]

  """
  update data of the table: "custom_phrases"
  """
  update_custom_phrases(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: custom_phrases_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: custom_phrases_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: custom_phrases_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: custom_phrases_delete_key_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: custom_phrases_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: custom_phrases_set_input

    """filter the rows which have to be updated"""
    where: custom_phrases_bool_exp!
  ): custom_phrases_mutation_response

  """
  update single row of the table: "custom_phrases"
  """
  update_custom_phrases_by_pk(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: custom_phrases_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: custom_phrases_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: custom_phrases_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: custom_phrases_delete_key_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: custom_phrases_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: custom_phrases_set_input
    pk_columns: custom_phrases_pk_columns_input!
  ): custom_phrases

  """
  update multiples rows of table: "custom_phrases"
  """
  update_custom_phrases_many(
    """updates to execute, in order"""
    updates: [custom_phrases_updates!]!
  ): [custom_phrases_mutation_response]

  """
  update data of the table: "daily_active_users"
  """
  update_daily_active_users(
    """sets the columns of the filtered rows to the given values"""
    _set: daily_active_users_set_input

    """filter the rows which have to be updated"""
    where: daily_active_users_bool_exp!
  ): daily_active_users_mutation_response

  """
  update single row of the table: "daily_active_users"
  """
  update_daily_active_users_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: daily_active_users_set_input
    pk_columns: daily_active_users_pk_columns_input!
  ): daily_active_users

  """
  update multiples rows of table: "daily_active_users"
  """
  update_daily_active_users_many(
    """updates to execute, in order"""
    updates: [daily_active_users_updates!]!
  ): [daily_active_users_mutation_response]

  """
  update data of the table: "daily_token_usage"
  """
  update_daily_token_usage(
    """increments the numeric columns with given value of the filtered values"""
    _inc: daily_token_usage_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: daily_token_usage_set_input

    """filter the rows which have to be updated"""
    where: daily_token_usage_bool_exp!
  ): daily_token_usage_mutation_response

  """
  update single row of the table: "daily_token_usage"
  """
  update_daily_token_usage_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: daily_token_usage_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: daily_token_usage_set_input
    pk_columns: daily_token_usage_pk_columns_input!
  ): daily_token_usage

  """
  update multiples rows of table: "daily_token_usage"
  """
  update_daily_token_usage_many(
    """updates to execute, in order"""
    updates: [daily_token_usage_updates!]!
  ): [daily_token_usage_mutation_response]

  """
  update data of the table: "domains"
  """
  update_domains(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: domains_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: domains_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: domains_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: domains_delete_key_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: domains_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: domains_set_input

    """filter the rows which have to be updated"""
    where: domains_bool_exp!
  ): domains_mutation_response

  """
  update single row of the table: "domains"
  """
  update_domains_by_pk(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: domains_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: domains_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: domains_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: domains_delete_key_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: domains_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: domains_set_input
    pk_columns: domains_pk_columns_input!
  ): domains

  """
  update multiples rows of table: "domains"
  """
  update_domains_many(
    """updates to execute, in order"""
    updates: [domains_updates!]!
  ): [domains_mutation_response]

  """
  update data of the table: "glucose_records"
  """
  update_glucose_records(
    """increments the numeric columns with given value of the filtered values"""
    _inc: glucose_records_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: glucose_records_set_input

    """filter the rows which have to be updated"""
    where: glucose_records_bool_exp!
  ): glucose_records_mutation_response

  """
  update single row of the table: "glucose_records"
  """
  update_glucose_records_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: glucose_records_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: glucose_records_set_input
    pk_columns: glucose_records_pk_columns_input!
  ): glucose_records

  """
  update multiples rows of table: "glucose_records"
  """
  update_glucose_records_many(
    """updates to execute, in order"""
    updates: [glucose_records_updates!]!
  ): [glucose_records_mutation_response]

  """
  update data of the table: "glucose_standards"
  """
  update_glucose_standards(
    """increments the numeric columns with given value of the filtered values"""
    _inc: glucose_standards_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: glucose_standards_set_input

    """filter the rows which have to be updated"""
    where: glucose_standards_bool_exp!
  ): glucose_standards_mutation_response

  """
  update single row of the table: "glucose_standards"
  """
  update_glucose_standards_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: glucose_standards_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: glucose_standards_set_input
    pk_columns: glucose_standards_pk_columns_input!
  ): glucose_standards

  """
  update multiples rows of table: "glucose_standards"
  """
  update_glucose_standards_many(
    """updates to execute, in order"""
    updates: [glucose_standards_updates!]!
  ): [glucose_standards_mutation_response]

  """
  update data of the table: "hooks"
  """
  update_hooks(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: hooks_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: hooks_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: hooks_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: hooks_delete_key_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: hooks_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: hooks_set_input

    """filter the rows which have to be updated"""
    where: hooks_bool_exp!
  ): hooks_mutation_response

  """
  update single row of the table: "hooks"
  """
  update_hooks_by_pk(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: hooks_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: hooks_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: hooks_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: hooks_delete_key_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: hooks_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: hooks_set_input
    pk_columns: hooks_pk_columns_input!
  ): hooks

  """
  update multiples rows of table: "hooks"
  """
  update_hooks_many(
    """updates to execute, in order"""
    updates: [hooks_updates!]!
  ): [hooks_mutation_response]

  """
  update data of the table: "lab_report_records"
  """
  update_lab_report_records(
    """increments the numeric columns with given value of the filtered values"""
    _inc: lab_report_records_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: lab_report_records_set_input

    """filter the rows which have to be updated"""
    where: lab_report_records_bool_exp!
  ): lab_report_records_mutation_response

  """
  update single row of the table: "lab_report_records"
  """
  update_lab_report_records_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: lab_report_records_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: lab_report_records_set_input
    pk_columns: lab_report_records_pk_columns_input!
  ): lab_report_records

  """
  update multiples rows of table: "lab_report_records"
  """
  update_lab_report_records_many(
    """updates to execute, in order"""
    updates: [lab_report_records_updates!]!
  ): [lab_report_records_mutation_response]

  """
  update data of the table: "logs"
  """
  update_logs(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: logs_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: logs_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: logs_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: logs_delete_key_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: logs_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: logs_set_input

    """filter the rows which have to be updated"""
    where: logs_bool_exp!
  ): logs_mutation_response

  """
  update single row of the table: "logs"
  """
  update_logs_by_pk(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: logs_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: logs_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: logs_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: logs_delete_key_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: logs_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: logs_set_input
    pk_columns: logs_pk_columns_input!
  ): logs

  """
  update multiples rows of table: "logs"
  """
  update_logs_many(
    """updates to execute, in order"""
    updates: [logs_updates!]!
  ): [logs_mutation_response]

  """
  update data of the table: "logto_configs"
  """
  update_logto_configs(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: logto_configs_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: logto_configs_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: logto_configs_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: logto_configs_delete_key_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: logto_configs_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: logto_configs_set_input

    """filter the rows which have to be updated"""
    where: logto_configs_bool_exp!
  ): logto_configs_mutation_response

  """
  update single row of the table: "logto_configs"
  """
  update_logto_configs_by_pk(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: logto_configs_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: logto_configs_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: logto_configs_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: logto_configs_delete_key_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: logto_configs_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: logto_configs_set_input
    pk_columns: logto_configs_pk_columns_input!
  ): logto_configs

  """
  update multiples rows of table: "logto_configs"
  """
  update_logto_configs_many(
    """updates to execute, in order"""
    updates: [logto_configs_updates!]!
  ): [logto_configs_mutation_response]

  """
  update data of the table: "medical_examination_records"
  """
  update_medical_examination_records(
    """sets the columns of the filtered rows to the given values"""
    _set: medical_examination_records_set_input

    """filter the rows which have to be updated"""
    where: medical_examination_records_bool_exp!
  ): medical_examination_records_mutation_response

  """
  update single row of the table: "medical_examination_records"
  """
  update_medical_examination_records_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: medical_examination_records_set_input
    pk_columns: medical_examination_records_pk_columns_input!
  ): medical_examination_records

  """
  update multiples rows of table: "medical_examination_records"
  """
  update_medical_examination_records_many(
    """updates to execute, in order"""
    updates: [medical_examination_records_updates!]!
  ): [medical_examination_records_mutation_response]

  """
  update data of the table: "medication_reminders"
  """
  update_medication_reminders(
    """increments the numeric columns with given value of the filtered values"""
    _inc: medication_reminders_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: medication_reminders_set_input

    """filter the rows which have to be updated"""
    where: medication_reminders_bool_exp!
  ): medication_reminders_mutation_response

  """
  update single row of the table: "medication_reminders"
  """
  update_medication_reminders_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: medication_reminders_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: medication_reminders_set_input
    pk_columns: medication_reminders_pk_columns_input!
  ): medication_reminders

  """
  update multiples rows of table: "medication_reminders"
  """
  update_medication_reminders_many(
    """updates to execute, in order"""
    updates: [medication_reminders_updates!]!
  ): [medication_reminders_mutation_response]

  """
  update data of the table: "oidc_model_instances"
  """
  update_oidc_model_instances(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: oidc_model_instances_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: oidc_model_instances_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: oidc_model_instances_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: oidc_model_instances_delete_key_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: oidc_model_instances_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: oidc_model_instances_set_input

    """filter the rows which have to be updated"""
    where: oidc_model_instances_bool_exp!
  ): oidc_model_instances_mutation_response

  """
  update single row of the table: "oidc_model_instances"
  """
  update_oidc_model_instances_by_pk(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: oidc_model_instances_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: oidc_model_instances_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: oidc_model_instances_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: oidc_model_instances_delete_key_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: oidc_model_instances_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: oidc_model_instances_set_input
    pk_columns: oidc_model_instances_pk_columns_input!
  ): oidc_model_instances

  """
  update multiples rows of table: "oidc_model_instances"
  """
  update_oidc_model_instances_many(
    """updates to execute, in order"""
    updates: [oidc_model_instances_updates!]!
  ): [oidc_model_instances_mutation_response]

  """
  update data of the table: "organization_invitation_role_relations"
  """
  update_organization_invitation_role_relations(
    """sets the columns of the filtered rows to the given values"""
    _set: organization_invitation_role_relations_set_input

    """filter the rows which have to be updated"""
    where: organization_invitation_role_relations_bool_exp!
  ): organization_invitation_role_relations_mutation_response

  """
  update single row of the table: "organization_invitation_role_relations"
  """
  update_organization_invitation_role_relations_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: organization_invitation_role_relations_set_input
    pk_columns: organization_invitation_role_relations_pk_columns_input!
  ): organization_invitation_role_relations

  """
  update multiples rows of table: "organization_invitation_role_relations"
  """
  update_organization_invitation_role_relations_many(
    """updates to execute, in order"""
    updates: [organization_invitation_role_relations_updates!]!
  ): [organization_invitation_role_relations_mutation_response]

  """
  update data of the table: "organization_invitations"
  """
  update_organization_invitations(
    """sets the columns of the filtered rows to the given values"""
    _set: organization_invitations_set_input

    """filter the rows which have to be updated"""
    where: organization_invitations_bool_exp!
  ): organization_invitations_mutation_response

  """
  update single row of the table: "organization_invitations"
  """
  update_organization_invitations_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: organization_invitations_set_input
    pk_columns: organization_invitations_pk_columns_input!
  ): organization_invitations

  """
  update multiples rows of table: "organization_invitations"
  """
  update_organization_invitations_many(
    """updates to execute, in order"""
    updates: [organization_invitations_updates!]!
  ): [organization_invitations_mutation_response]

  """
  update data of the table: "organization_role_scope_relations"
  """
  update_organization_role_scope_relations(
    """sets the columns of the filtered rows to the given values"""
    _set: organization_role_scope_relations_set_input

    """filter the rows which have to be updated"""
    where: organization_role_scope_relations_bool_exp!
  ): organization_role_scope_relations_mutation_response

  """
  update single row of the table: "organization_role_scope_relations"
  """
  update_organization_role_scope_relations_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: organization_role_scope_relations_set_input
    pk_columns: organization_role_scope_relations_pk_columns_input!
  ): organization_role_scope_relations

  """
  update multiples rows of table: "organization_role_scope_relations"
  """
  update_organization_role_scope_relations_many(
    """updates to execute, in order"""
    updates: [organization_role_scope_relations_updates!]!
  ): [organization_role_scope_relations_mutation_response]

  """
  update data of the table: "organization_role_user_relations"
  """
  update_organization_role_user_relations(
    """sets the columns of the filtered rows to the given values"""
    _set: organization_role_user_relations_set_input

    """filter the rows which have to be updated"""
    where: organization_role_user_relations_bool_exp!
  ): organization_role_user_relations_mutation_response

  """
  update single row of the table: "organization_role_user_relations"
  """
  update_organization_role_user_relations_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: organization_role_user_relations_set_input
    pk_columns: organization_role_user_relations_pk_columns_input!
  ): organization_role_user_relations

  """
  update multiples rows of table: "organization_role_user_relations"
  """
  update_organization_role_user_relations_many(
    """updates to execute, in order"""
    updates: [organization_role_user_relations_updates!]!
  ): [organization_role_user_relations_mutation_response]

  """
  update data of the table: "organization_roles"
  """
  update_organization_roles(
    """sets the columns of the filtered rows to the given values"""
    _set: organization_roles_set_input

    """filter the rows which have to be updated"""
    where: organization_roles_bool_exp!
  ): organization_roles_mutation_response

  """
  update single row of the table: "organization_roles"
  """
  update_organization_roles_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: organization_roles_set_input
    pk_columns: organization_roles_pk_columns_input!
  ): organization_roles

  """
  update multiples rows of table: "organization_roles"
  """
  update_organization_roles_many(
    """updates to execute, in order"""
    updates: [organization_roles_updates!]!
  ): [organization_roles_mutation_response]

  """
  update data of the table: "organization_scopes"
  """
  update_organization_scopes(
    """sets the columns of the filtered rows to the given values"""
    _set: organization_scopes_set_input

    """filter the rows which have to be updated"""
    where: organization_scopes_bool_exp!
  ): organization_scopes_mutation_response

  """
  update single row of the table: "organization_scopes"
  """
  update_organization_scopes_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: organization_scopes_set_input
    pk_columns: organization_scopes_pk_columns_input!
  ): organization_scopes

  """
  update multiples rows of table: "organization_scopes"
  """
  update_organization_scopes_many(
    """updates to execute, in order"""
    updates: [organization_scopes_updates!]!
  ): [organization_scopes_mutation_response]

  """
  update data of the table: "organization_user_relations"
  """
  update_organization_user_relations(
    """sets the columns of the filtered rows to the given values"""
    _set: organization_user_relations_set_input

    """filter the rows which have to be updated"""
    where: organization_user_relations_bool_exp!
  ): organization_user_relations_mutation_response

  """
  update single row of the table: "organization_user_relations"
  """
  update_organization_user_relations_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: organization_user_relations_set_input
    pk_columns: organization_user_relations_pk_columns_input!
  ): organization_user_relations

  """
  update multiples rows of table: "organization_user_relations"
  """
  update_organization_user_relations_many(
    """updates to execute, in order"""
    updates: [organization_user_relations_updates!]!
  ): [organization_user_relations_mutation_response]

  """
  update data of the table: "organizations"
  """
  update_organizations(
    """sets the columns of the filtered rows to the given values"""
    _set: organizations_set_input

    """filter the rows which have to be updated"""
    where: organizations_bool_exp!
  ): organizations_mutation_response

  """
  update single row of the table: "organizations"
  """
  update_organizations_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: organizations_set_input
    pk_columns: organizations_pk_columns_input!
  ): organizations

  """
  update multiples rows of table: "organizations"
  """
  update_organizations_many(
    """updates to execute, in order"""
    updates: [organizations_updates!]!
  ): [organizations_mutation_response]

  """
  update data of the table: "passcodes"
  """
  update_passcodes(
    """increments the numeric columns with given value of the filtered values"""
    _inc: passcodes_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: passcodes_set_input

    """filter the rows which have to be updated"""
    where: passcodes_bool_exp!
  ): passcodes_mutation_response

  """
  update single row of the table: "passcodes"
  """
  update_passcodes_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: passcodes_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: passcodes_set_input
    pk_columns: passcodes_pk_columns_input!
  ): passcodes

  """
  update multiples rows of table: "passcodes"
  """
  update_passcodes_many(
    """updates to execute, in order"""
    updates: [passcodes_updates!]!
  ): [passcodes_mutation_response]

  """
  update data of the table: "resources"
  """
  update_resources(
    """increments the numeric columns with given value of the filtered values"""
    _inc: resources_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: resources_set_input

    """filter the rows which have to be updated"""
    where: resources_bool_exp!
  ): resources_mutation_response

  """
  update single row of the table: "resources"
  """
  update_resources_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: resources_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: resources_set_input
    pk_columns: resources_pk_columns_input!
  ): resources

  """
  update multiples rows of table: "resources"
  """
  update_resources_many(
    """updates to execute, in order"""
    updates: [resources_updates!]!
  ): [resources_mutation_response]

  """
  update data of the table: "roles"
  """
  update_roles(
    """sets the columns of the filtered rows to the given values"""
    _set: roles_set_input

    """filter the rows which have to be updated"""
    where: roles_bool_exp!
  ): roles_mutation_response

  """
  update single row of the table: "roles"
  """
  update_roles_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: roles_set_input
    pk_columns: roles_pk_columns_input!
  ): roles

  """
  update multiples rows of table: "roles"
  """
  update_roles_many(
    """updates to execute, in order"""
    updates: [roles_updates!]!
  ): [roles_mutation_response]

  """
  update data of the table: "roles_scopes"
  """
  update_roles_scopes(
    """sets the columns of the filtered rows to the given values"""
    _set: roles_scopes_set_input

    """filter the rows which have to be updated"""
    where: roles_scopes_bool_exp!
  ): roles_scopes_mutation_response

  """
  update single row of the table: "roles_scopes"
  """
  update_roles_scopes_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: roles_scopes_set_input
    pk_columns: roles_scopes_pk_columns_input!
  ): roles_scopes

  """
  update multiples rows of table: "roles_scopes"
  """
  update_roles_scopes_many(
    """updates to execute, in order"""
    updates: [roles_scopes_updates!]!
  ): [roles_scopes_mutation_response]

  """
  update data of the table: "scopes"
  """
  update_scopes(
    """sets the columns of the filtered rows to the given values"""
    _set: scopes_set_input

    """filter the rows which have to be updated"""
    where: scopes_bool_exp!
  ): scopes_mutation_response

  """
  update single row of the table: "scopes"
  """
  update_scopes_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: scopes_set_input
    pk_columns: scopes_pk_columns_input!
  ): scopes

  """
  update multiples rows of table: "scopes"
  """
  update_scopes_many(
    """updates to execute, in order"""
    updates: [scopes_updates!]!
  ): [scopes_mutation_response]

  """
  update data of the table: "sentinel_activities"
  """
  update_sentinel_activities(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: sentinel_activities_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: sentinel_activities_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: sentinel_activities_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: sentinel_activities_delete_key_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: sentinel_activities_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: sentinel_activities_set_input

    """filter the rows which have to be updated"""
    where: sentinel_activities_bool_exp!
  ): sentinel_activities_mutation_response

  """
  update single row of the table: "sentinel_activities"
  """
  update_sentinel_activities_by_pk(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: sentinel_activities_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: sentinel_activities_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: sentinel_activities_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: sentinel_activities_delete_key_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: sentinel_activities_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: sentinel_activities_set_input
    pk_columns: sentinel_activities_pk_columns_input!
  ): sentinel_activities

  """
  update multiples rows of table: "sentinel_activities"
  """
  update_sentinel_activities_many(
    """updates to execute, in order"""
    updates: [sentinel_activities_updates!]!
  ): [sentinel_activities_mutation_response]

  """
  update data of the table: "service_logs"
  """
  update_service_logs(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: service_logs_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: service_logs_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: service_logs_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: service_logs_delete_key_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: service_logs_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: service_logs_set_input

    """filter the rows which have to be updated"""
    where: service_logs_bool_exp!
  ): service_logs_mutation_response

  """
  update single row of the table: "service_logs"
  """
  update_service_logs_by_pk(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: service_logs_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: service_logs_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: service_logs_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: service_logs_delete_key_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: service_logs_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: service_logs_set_input
    pk_columns: service_logs_pk_columns_input!
  ): service_logs

  """
  update multiples rows of table: "service_logs"
  """
  update_service_logs_many(
    """updates to execute, in order"""
    updates: [service_logs_updates!]!
  ): [service_logs_mutation_response]

  """
  update data of the table: "sign_in_experiences"
  """
  update_sign_in_experiences(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: sign_in_experiences_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: sign_in_experiences_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: sign_in_experiences_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: sign_in_experiences_delete_key_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: sign_in_experiences_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: sign_in_experiences_set_input

    """filter the rows which have to be updated"""
    where: sign_in_experiences_bool_exp!
  ): sign_in_experiences_mutation_response

  """
  update single row of the table: "sign_in_experiences"
  """
  update_sign_in_experiences_by_pk(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: sign_in_experiences_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: sign_in_experiences_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: sign_in_experiences_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: sign_in_experiences_delete_key_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: sign_in_experiences_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: sign_in_experiences_set_input
    pk_columns: sign_in_experiences_pk_columns_input!
  ): sign_in_experiences

  """
  update multiples rows of table: "sign_in_experiences"
  """
  update_sign_in_experiences_many(
    """updates to execute, in order"""
    updates: [sign_in_experiences_updates!]!
  ): [sign_in_experiences_mutation_response]

  """
  update data of the table: "sms_codes"
  """
  update_sms_codes(
    """sets the columns of the filtered rows to the given values"""
    _set: sms_codes_set_input

    """filter the rows which have to be updated"""
    where: sms_codes_bool_exp!
  ): sms_codes_mutation_response

  """
  update single row of the table: "sms_codes"
  """
  update_sms_codes_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: sms_codes_set_input
    pk_columns: sms_codes_pk_columns_input!
  ): sms_codes

  """
  update multiples rows of table: "sms_codes"
  """
  update_sms_codes_many(
    """updates to execute, in order"""
    updates: [sms_codes_updates!]!
  ): [sms_codes_mutation_response]

  """
  update data of the table: "sso_connectors"
  """
  update_sso_connectors(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: sso_connectors_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: sso_connectors_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: sso_connectors_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: sso_connectors_delete_key_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: sso_connectors_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: sso_connectors_set_input

    """filter the rows which have to be updated"""
    where: sso_connectors_bool_exp!
  ): sso_connectors_mutation_response

  """
  update single row of the table: "sso_connectors"
  """
  update_sso_connectors_by_pk(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: sso_connectors_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: sso_connectors_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: sso_connectors_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: sso_connectors_delete_key_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: sso_connectors_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: sso_connectors_set_input
    pk_columns: sso_connectors_pk_columns_input!
  ): sso_connectors

  """
  update multiples rows of table: "sso_connectors"
  """
  update_sso_connectors_many(
    """updates to execute, in order"""
    updates: [sso_connectors_updates!]!
  ): [sso_connectors_mutation_response]

  """
  update data of the table: "systems"
  """
  update_systems(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: systems_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: systems_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: systems_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: systems_delete_key_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: systems_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: systems_set_input

    """filter the rows which have to be updated"""
    where: systems_bool_exp!
  ): systems_mutation_response

  """
  update single row of the table: "systems"
  """
  update_systems_by_pk(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: systems_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: systems_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: systems_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: systems_delete_key_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: systems_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: systems_set_input
    pk_columns: systems_pk_columns_input!
  ): systems

  """
  update multiples rows of table: "systems"
  """
  update_systems_many(
    """updates to execute, in order"""
    updates: [systems_updates!]!
  ): [systems_mutation_response]

  """
  update data of the table: "tenants"
  """
  update_tenants(
    """sets the columns of the filtered rows to the given values"""
    _set: tenants_set_input

    """filter the rows which have to be updated"""
    where: tenants_bool_exp!
  ): tenants_mutation_response

  """
  update single row of the table: "tenants"
  """
  update_tenants_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: tenants_set_input
    pk_columns: tenants_pk_columns_input!
  ): tenants

  """
  update multiples rows of table: "tenants"
  """
  update_tenants_many(
    """updates to execute, in order"""
    updates: [tenants_updates!]!
  ): [tenants_mutation_response]

  """
  update data of the table: "user_cholesterol_standards"
  """
  update_user_cholesterol_standards(
    """increments the numeric columns with given value of the filtered values"""
    _inc: user_cholesterol_standards_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: user_cholesterol_standards_set_input

    """filter the rows which have to be updated"""
    where: user_cholesterol_standards_bool_exp!
  ): user_cholesterol_standards_mutation_response

  """
  update single row of the table: "user_cholesterol_standards"
  """
  update_user_cholesterol_standards_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: user_cholesterol_standards_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: user_cholesterol_standards_set_input
    pk_columns: user_cholesterol_standards_pk_columns_input!
  ): user_cholesterol_standards

  """
  update multiples rows of table: "user_cholesterol_standards"
  """
  update_user_cholesterol_standards_many(
    """updates to execute, in order"""
    updates: [user_cholesterol_standards_updates!]!
  ): [user_cholesterol_standards_mutation_response]

  """
  update data of the table: "user_glucose_standards"
  """
  update_user_glucose_standards(
    """increments the numeric columns with given value of the filtered values"""
    _inc: user_glucose_standards_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: user_glucose_standards_set_input

    """filter the rows which have to be updated"""
    where: user_glucose_standards_bool_exp!
  ): user_glucose_standards_mutation_response

  """
  update single row of the table: "user_glucose_standards"
  """
  update_user_glucose_standards_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: user_glucose_standards_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: user_glucose_standards_set_input
    pk_columns: user_glucose_standards_pk_columns_input!
  ): user_glucose_standards

  """
  update multiples rows of table: "user_glucose_standards"
  """
  update_user_glucose_standards_many(
    """updates to execute, in order"""
    updates: [user_glucose_standards_updates!]!
  ): [user_glucose_standards_mutation_response]

  """
  update data of the table: "user_sso_identities"
  """
  update_user_sso_identities(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: user_sso_identities_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: user_sso_identities_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: user_sso_identities_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: user_sso_identities_delete_key_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: user_sso_identities_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: user_sso_identities_set_input

    """filter the rows which have to be updated"""
    where: user_sso_identities_bool_exp!
  ): user_sso_identities_mutation_response

  """
  update single row of the table: "user_sso_identities"
  """
  update_user_sso_identities_by_pk(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: user_sso_identities_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: user_sso_identities_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: user_sso_identities_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: user_sso_identities_delete_key_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: user_sso_identities_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: user_sso_identities_set_input
    pk_columns: user_sso_identities_pk_columns_input!
  ): user_sso_identities

  """
  update multiples rows of table: "user_sso_identities"
  """
  update_user_sso_identities_many(
    """updates to execute, in order"""
    updates: [user_sso_identities_updates!]!
  ): [user_sso_identities_mutation_response]

  """
  update data of the table: "users"
  """
  update_users(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: users_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: users_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: users_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: users_delete_key_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: users_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: users_set_input

    """filter the rows which have to be updated"""
    where: users_bool_exp!
  ): users_mutation_response

  """
  update single row of the table: "users"
  """
  update_users_by_pk(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: users_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: users_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: users_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: users_delete_key_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: users_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: users_set_input
    pk_columns: users_pk_columns_input!
  ): users

  """
  update multiples rows of table: "users"
  """
  update_users_many(
    """updates to execute, in order"""
    updates: [users_updates!]!
  ): [users_mutation_response]

  """
  update data of the table: "users_roles"
  """
  update_users_roles(
    """sets the columns of the filtered rows to the given values"""
    _set: users_roles_set_input

    """filter the rows which have to be updated"""
    where: users_roles_bool_exp!
  ): users_roles_mutation_response

  """
  update single row of the table: "users_roles"
  """
  update_users_roles_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: users_roles_set_input
    pk_columns: users_roles_pk_columns_input!
  ): users_roles

  """
  update multiples rows of table: "users_roles"
  """
  update_users_roles_many(
    """updates to execute, in order"""
    updates: [users_roles_updates!]!
  ): [users_roles_mutation_response]

  """
  update data of the table: "verification_statuses"
  """
  update_verification_statuses(
    """sets the columns of the filtered rows to the given values"""
    _set: verification_statuses_set_input

    """filter the rows which have to be updated"""
    where: verification_statuses_bool_exp!
  ): verification_statuses_mutation_response

  """
  update single row of the table: "verification_statuses"
  """
  update_verification_statuses_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: verification_statuses_set_input
    pk_columns: verification_statuses_pk_columns_input!
  ): verification_statuses

  """
  update multiples rows of table: "verification_statuses"
  """
  update_verification_statuses_many(
    """updates to execute, in order"""
    updates: [verification_statuses_updates!]!
  ): [verification_statuses_mutation_response]
}

scalar numeric

"""
Boolean expression to compare columns of type "numeric". All fields are combined with logical 'AND'.
"""
input numeric_comparison_exp {
  _eq: numeric
  _gt: numeric
  _gte: numeric
  _in: [numeric!]
  _is_null: Boolean
  _lt: numeric
  _lte: numeric
  _neq: numeric
  _nin: [numeric!]
}

scalar oid

"""
Boolean expression to compare columns of type "oid". All fields are combined with logical 'AND'.
"""
input oid_comparison_exp {
  _eq: oid
  _gt: oid
  _gte: oid
  _in: [oid!]
  _is_null: Boolean
  _lt: oid
  _lte: oid
  _neq: oid
  _nin: [oid!]
}

"""
columns and relationships of "oidc_model_instances"
"""
type oidc_model_instances {
  consumed_at: timestamptz
  expires_at: timestamptz!
  id: String!
  model_name: String!
  payload(
    """JSON select path"""
    path: String
  ): jsonb!
  tenant_id: String!
}

"""
aggregated selection of "oidc_model_instances"
"""
type oidc_model_instances_aggregate {
  aggregate: oidc_model_instances_aggregate_fields
  nodes: [oidc_model_instances!]!
}

"""
aggregate fields of "oidc_model_instances"
"""
type oidc_model_instances_aggregate_fields {
  count(columns: [oidc_model_instances_select_column!], distinct: Boolean): Int!
  max: oidc_model_instances_max_fields
  min: oidc_model_instances_min_fields
}

"""append existing jsonb value of filtered columns with new jsonb value"""
input oidc_model_instances_append_input {
  payload: jsonb
}

"""
Boolean expression to filter rows from the table "oidc_model_instances". All fields are combined with a logical 'AND'.
"""
input oidc_model_instances_bool_exp {
  _and: [oidc_model_instances_bool_exp!]
  _not: oidc_model_instances_bool_exp
  _or: [oidc_model_instances_bool_exp!]
  consumed_at: timestamptz_comparison_exp
  expires_at: timestamptz_comparison_exp
  id: String_comparison_exp
  model_name: String_comparison_exp
  payload: jsonb_comparison_exp
  tenant_id: String_comparison_exp
}

"""
unique or primary key constraints on table "oidc_model_instances"
"""
enum oidc_model_instances_constraint {
  """
  unique or primary key constraint on columns "id", "tenant_id", "model_name"
  """
  oidc_model_instances__model_name_id

  """
  unique or primary key constraint on columns "id"
  """
  oidc_model_instances_pkey
}

"""
delete the field or element with specified path (for JSON arrays, negative integers count from the end)
"""
input oidc_model_instances_delete_at_path_input {
  payload: [String!]
}

"""
delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
"""
input oidc_model_instances_delete_elem_input {
  payload: Int
}

"""
delete key/value pair or string element. key/value pairs are matched based on their key value
"""
input oidc_model_instances_delete_key_input {
  payload: String
}

"""
input type for inserting data into table "oidc_model_instances"
"""
input oidc_model_instances_insert_input {
  consumed_at: timestamptz
  expires_at: timestamptz
  id: String
  model_name: String
  payload: jsonb
  tenant_id: String
}

"""aggregate max on columns"""
type oidc_model_instances_max_fields {
  consumed_at: timestamptz
  expires_at: timestamptz
  id: String
  model_name: String
  tenant_id: String
}

"""aggregate min on columns"""
type oidc_model_instances_min_fields {
  consumed_at: timestamptz
  expires_at: timestamptz
  id: String
  model_name: String
  tenant_id: String
}

"""
response of any mutation on the table "oidc_model_instances"
"""
type oidc_model_instances_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [oidc_model_instances!]!
}

"""
on_conflict condition type for table "oidc_model_instances"
"""
input oidc_model_instances_on_conflict {
  constraint: oidc_model_instances_constraint!
  update_columns: [oidc_model_instances_update_column!]! = []
  where: oidc_model_instances_bool_exp
}

"""Ordering options when selecting data from "oidc_model_instances"."""
input oidc_model_instances_order_by {
  consumed_at: order_by
  expires_at: order_by
  id: order_by
  model_name: order_by
  payload: order_by
  tenant_id: order_by
}

"""primary key columns input for table: oidc_model_instances"""
input oidc_model_instances_pk_columns_input {
  id: String!
}

"""prepend existing jsonb value of filtered columns with new jsonb value"""
input oidc_model_instances_prepend_input {
  payload: jsonb
}

"""
select columns of table "oidc_model_instances"
"""
enum oidc_model_instances_select_column {
  """column name"""
  consumed_at

  """column name"""
  expires_at

  """column name"""
  id

  """column name"""
  model_name

  """column name"""
  payload

  """column name"""
  tenant_id
}

"""
input type for updating data in table "oidc_model_instances"
"""
input oidc_model_instances_set_input {
  consumed_at: timestamptz
  expires_at: timestamptz
  id: String
  model_name: String
  payload: jsonb
  tenant_id: String
}

"""
Streaming cursor of the table "oidc_model_instances"
"""
input oidc_model_instances_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: oidc_model_instances_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input oidc_model_instances_stream_cursor_value_input {
  consumed_at: timestamptz
  expires_at: timestamptz
  id: String
  model_name: String
  payload: jsonb
  tenant_id: String
}

"""
update columns of table "oidc_model_instances"
"""
enum oidc_model_instances_update_column {
  """column name"""
  consumed_at

  """column name"""
  expires_at

  """column name"""
  id

  """column name"""
  model_name

  """column name"""
  payload

  """column name"""
  tenant_id
}

input oidc_model_instances_updates {
  """append existing jsonb value of filtered columns with new jsonb value"""
  _append: oidc_model_instances_append_input

  """
  delete the field or element with specified path (for JSON arrays, negative integers count from the end)
  """
  _delete_at_path: oidc_model_instances_delete_at_path_input

  """
  delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
  """
  _delete_elem: oidc_model_instances_delete_elem_input

  """
  delete key/value pair or string element. key/value pairs are matched based on their key value
  """
  _delete_key: oidc_model_instances_delete_key_input

  """prepend existing jsonb value of filtered columns with new jsonb value"""
  _prepend: oidc_model_instances_prepend_input

  """sets the columns of the filtered rows to the given values"""
  _set: oidc_model_instances_set_input

  """filter the rows which have to be updated"""
  where: oidc_model_instances_bool_exp!
}

"""column ordering options"""
enum order_by {
  """in ascending order, nulls last"""
  asc

  """in ascending order, nulls first"""
  asc_nulls_first

  """in ascending order, nulls last"""
  asc_nulls_last

  """in descending order, nulls first"""
  desc

  """in descending order, nulls first"""
  desc_nulls_first

  """in descending order, nulls last"""
  desc_nulls_last
}

"""
columns and relationships of "organization_invitation_role_relations"
"""
type organization_invitation_role_relations {
  organization_invitation_id: String!
  organization_role_id: String!
  tenant_id: String!
}

"""
aggregated selection of "organization_invitation_role_relations"
"""
type organization_invitation_role_relations_aggregate {
  aggregate: organization_invitation_role_relations_aggregate_fields
  nodes: [organization_invitation_role_relations!]!
}

"""
aggregate fields of "organization_invitation_role_relations"
"""
type organization_invitation_role_relations_aggregate_fields {
  count(columns: [organization_invitation_role_relations_select_column!], distinct: Boolean): Int!
  max: organization_invitation_role_relations_max_fields
  min: organization_invitation_role_relations_min_fields
}

"""
Boolean expression to filter rows from the table "organization_invitation_role_relations". All fields are combined with a logical 'AND'.
"""
input organization_invitation_role_relations_bool_exp {
  _and: [organization_invitation_role_relations_bool_exp!]
  _not: organization_invitation_role_relations_bool_exp
  _or: [organization_invitation_role_relations_bool_exp!]
  organization_invitation_id: String_comparison_exp
  organization_role_id: String_comparison_exp
  tenant_id: String_comparison_exp
}

"""
unique or primary key constraints on table "organization_invitation_role_relations"
"""
enum organization_invitation_role_relations_constraint {
  """
  unique or primary key constraint on columns "organization_role_id", "organization_invitation_id", "tenant_id"
  """
  organization_invitation_role_relations_pkey
}

"""
input type for inserting data into table "organization_invitation_role_relations"
"""
input organization_invitation_role_relations_insert_input {
  organization_invitation_id: String
  organization_role_id: String
  tenant_id: String
}

"""aggregate max on columns"""
type organization_invitation_role_relations_max_fields {
  organization_invitation_id: String
  organization_role_id: String
  tenant_id: String
}

"""aggregate min on columns"""
type organization_invitation_role_relations_min_fields {
  organization_invitation_id: String
  organization_role_id: String
  tenant_id: String
}

"""
response of any mutation on the table "organization_invitation_role_relations"
"""
type organization_invitation_role_relations_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [organization_invitation_role_relations!]!
}

"""
on_conflict condition type for table "organization_invitation_role_relations"
"""
input organization_invitation_role_relations_on_conflict {
  constraint: organization_invitation_role_relations_constraint!
  update_columns: [organization_invitation_role_relations_update_column!]! = []
  where: organization_invitation_role_relations_bool_exp
}

"""
Ordering options when selecting data from "organization_invitation_role_relations".
"""
input organization_invitation_role_relations_order_by {
  organization_invitation_id: order_by
  organization_role_id: order_by
  tenant_id: order_by
}

"""
primary key columns input for table: organization_invitation_role_relations
"""
input organization_invitation_role_relations_pk_columns_input {
  organization_invitation_id: String!
  organization_role_id: String!
  tenant_id: String!
}

"""
select columns of table "organization_invitation_role_relations"
"""
enum organization_invitation_role_relations_select_column {
  """column name"""
  organization_invitation_id

  """column name"""
  organization_role_id

  """column name"""
  tenant_id
}

"""
input type for updating data in table "organization_invitation_role_relations"
"""
input organization_invitation_role_relations_set_input {
  organization_invitation_id: String
  organization_role_id: String
  tenant_id: String
}

"""
Streaming cursor of the table "organization_invitation_role_relations"
"""
input organization_invitation_role_relations_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: organization_invitation_role_relations_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input organization_invitation_role_relations_stream_cursor_value_input {
  organization_invitation_id: String
  organization_role_id: String
  tenant_id: String
}

"""
update columns of table "organization_invitation_role_relations"
"""
enum organization_invitation_role_relations_update_column {
  """column name"""
  organization_invitation_id

  """column name"""
  organization_role_id

  """column name"""
  tenant_id
}

input organization_invitation_role_relations_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: organization_invitation_role_relations_set_input

  """filter the rows which have to be updated"""
  where: organization_invitation_role_relations_bool_exp!
}

scalar organization_invitation_status

"""
Boolean expression to compare columns of type "organization_invitation_status". All fields are combined with logical 'AND'.
"""
input organization_invitation_status_comparison_exp {
  _eq: organization_invitation_status
  _gt: organization_invitation_status
  _gte: organization_invitation_status
  _in: [organization_invitation_status!]
  _is_null: Boolean
  _lt: organization_invitation_status
  _lte: organization_invitation_status
  _neq: organization_invitation_status
  _nin: [organization_invitation_status!]
}

"""
columns and relationships of "organization_invitations"
"""
type organization_invitations {
  accepted_user_id: String
  created_at: timestamptz!
  expires_at: timestamptz!
  id: String!
  invitee: String!
  inviter_id: String
  organization_id: String!
  status: organization_invitation_status!
  tenant_id: String!
  updated_at: timestamptz!
}

"""
aggregated selection of "organization_invitations"
"""
type organization_invitations_aggregate {
  aggregate: organization_invitations_aggregate_fields
  nodes: [organization_invitations!]!
}

"""
aggregate fields of "organization_invitations"
"""
type organization_invitations_aggregate_fields {
  count(columns: [organization_invitations_select_column!], distinct: Boolean): Int!
  max: organization_invitations_max_fields
  min: organization_invitations_min_fields
}

"""
Boolean expression to filter rows from the table "organization_invitations". All fields are combined with a logical 'AND'.
"""
input organization_invitations_bool_exp {
  _and: [organization_invitations_bool_exp!]
  _not: organization_invitations_bool_exp
  _or: [organization_invitations_bool_exp!]
  accepted_user_id: String_comparison_exp
  created_at: timestamptz_comparison_exp
  expires_at: timestamptz_comparison_exp
  id: String_comparison_exp
  invitee: String_comparison_exp
  inviter_id: String_comparison_exp
  organization_id: String_comparison_exp
  status: organization_invitation_status_comparison_exp
  tenant_id: String_comparison_exp
  updated_at: timestamptz_comparison_exp
}

"""
unique or primary key constraints on table "organization_invitations"
"""
enum organization_invitations_constraint {
  """
  unique or primary key constraint on columns "invitee", "tenant_id", "organization_id"
  """
  organization_invitations__invitee_organization_id

  """
  unique or primary key constraint on columns "id"
  """
  organization_invitations_pkey
}

"""
input type for inserting data into table "organization_invitations"
"""
input organization_invitations_insert_input {
  accepted_user_id: String
  created_at: timestamptz
  expires_at: timestamptz
  id: String
  invitee: String
  inviter_id: String
  organization_id: String
  status: organization_invitation_status
  tenant_id: String
  updated_at: timestamptz
}

"""aggregate max on columns"""
type organization_invitations_max_fields {
  accepted_user_id: String
  created_at: timestamptz
  expires_at: timestamptz
  id: String
  invitee: String
  inviter_id: String
  organization_id: String
  status: organization_invitation_status
  tenant_id: String
  updated_at: timestamptz
}

"""aggregate min on columns"""
type organization_invitations_min_fields {
  accepted_user_id: String
  created_at: timestamptz
  expires_at: timestamptz
  id: String
  invitee: String
  inviter_id: String
  organization_id: String
  status: organization_invitation_status
  tenant_id: String
  updated_at: timestamptz
}

"""
response of any mutation on the table "organization_invitations"
"""
type organization_invitations_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [organization_invitations!]!
}

"""
on_conflict condition type for table "organization_invitations"
"""
input organization_invitations_on_conflict {
  constraint: organization_invitations_constraint!
  update_columns: [organization_invitations_update_column!]! = []
  where: organization_invitations_bool_exp
}

"""Ordering options when selecting data from "organization_invitations"."""
input organization_invitations_order_by {
  accepted_user_id: order_by
  created_at: order_by
  expires_at: order_by
  id: order_by
  invitee: order_by
  inviter_id: order_by
  organization_id: order_by
  status: order_by
  tenant_id: order_by
  updated_at: order_by
}

"""primary key columns input for table: organization_invitations"""
input organization_invitations_pk_columns_input {
  id: String!
}

"""
select columns of table "organization_invitations"
"""
enum organization_invitations_select_column {
  """column name"""
  accepted_user_id

  """column name"""
  created_at

  """column name"""
  expires_at

  """column name"""
  id

  """column name"""
  invitee

  """column name"""
  inviter_id

  """column name"""
  organization_id

  """column name"""
  status

  """column name"""
  tenant_id

  """column name"""
  updated_at
}

"""
input type for updating data in table "organization_invitations"
"""
input organization_invitations_set_input {
  accepted_user_id: String
  created_at: timestamptz
  expires_at: timestamptz
  id: String
  invitee: String
  inviter_id: String
  organization_id: String
  status: organization_invitation_status
  tenant_id: String
  updated_at: timestamptz
}

"""
Streaming cursor of the table "organization_invitations"
"""
input organization_invitations_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: organization_invitations_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input organization_invitations_stream_cursor_value_input {
  accepted_user_id: String
  created_at: timestamptz
  expires_at: timestamptz
  id: String
  invitee: String
  inviter_id: String
  organization_id: String
  status: organization_invitation_status
  tenant_id: String
  updated_at: timestamptz
}

"""
update columns of table "organization_invitations"
"""
enum organization_invitations_update_column {
  """column name"""
  accepted_user_id

  """column name"""
  created_at

  """column name"""
  expires_at

  """column name"""
  id

  """column name"""
  invitee

  """column name"""
  inviter_id

  """column name"""
  organization_id

  """column name"""
  status

  """column name"""
  tenant_id

  """column name"""
  updated_at
}

input organization_invitations_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: organization_invitations_set_input

  """filter the rows which have to be updated"""
  where: organization_invitations_bool_exp!
}

"""
columns and relationships of "organization_role_scope_relations"
"""
type organization_role_scope_relations {
  organization_role_id: String!
  organization_scope_id: String!
  tenant_id: String!
}

"""
aggregated selection of "organization_role_scope_relations"
"""
type organization_role_scope_relations_aggregate {
  aggregate: organization_role_scope_relations_aggregate_fields
  nodes: [organization_role_scope_relations!]!
}

"""
aggregate fields of "organization_role_scope_relations"
"""
type organization_role_scope_relations_aggregate_fields {
  count(columns: [organization_role_scope_relations_select_column!], distinct: Boolean): Int!
  max: organization_role_scope_relations_max_fields
  min: organization_role_scope_relations_min_fields
}

"""
Boolean expression to filter rows from the table "organization_role_scope_relations". All fields are combined with a logical 'AND'.
"""
input organization_role_scope_relations_bool_exp {
  _and: [organization_role_scope_relations_bool_exp!]
  _not: organization_role_scope_relations_bool_exp
  _or: [organization_role_scope_relations_bool_exp!]
  organization_role_id: String_comparison_exp
  organization_scope_id: String_comparison_exp
  tenant_id: String_comparison_exp
}

"""
unique or primary key constraints on table "organization_role_scope_relations"
"""
enum organization_role_scope_relations_constraint {
  """
  unique or primary key constraint on columns "organization_scope_id", "organization_role_id", "tenant_id"
  """
  organization_role_scope_relations_pkey
}

"""
input type for inserting data into table "organization_role_scope_relations"
"""
input organization_role_scope_relations_insert_input {
  organization_role_id: String
  organization_scope_id: String
  tenant_id: String
}

"""aggregate max on columns"""
type organization_role_scope_relations_max_fields {
  organization_role_id: String
  organization_scope_id: String
  tenant_id: String
}

"""aggregate min on columns"""
type organization_role_scope_relations_min_fields {
  organization_role_id: String
  organization_scope_id: String
  tenant_id: String
}

"""
response of any mutation on the table "organization_role_scope_relations"
"""
type organization_role_scope_relations_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [organization_role_scope_relations!]!
}

"""
on_conflict condition type for table "organization_role_scope_relations"
"""
input organization_role_scope_relations_on_conflict {
  constraint: organization_role_scope_relations_constraint!
  update_columns: [organization_role_scope_relations_update_column!]! = []
  where: organization_role_scope_relations_bool_exp
}

"""
Ordering options when selecting data from "organization_role_scope_relations".
"""
input organization_role_scope_relations_order_by {
  organization_role_id: order_by
  organization_scope_id: order_by
  tenant_id: order_by
}

"""primary key columns input for table: organization_role_scope_relations"""
input organization_role_scope_relations_pk_columns_input {
  organization_role_id: String!
  organization_scope_id: String!
  tenant_id: String!
}

"""
select columns of table "organization_role_scope_relations"
"""
enum organization_role_scope_relations_select_column {
  """column name"""
  organization_role_id

  """column name"""
  organization_scope_id

  """column name"""
  tenant_id
}

"""
input type for updating data in table "organization_role_scope_relations"
"""
input organization_role_scope_relations_set_input {
  organization_role_id: String
  organization_scope_id: String
  tenant_id: String
}

"""
Streaming cursor of the table "organization_role_scope_relations"
"""
input organization_role_scope_relations_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: organization_role_scope_relations_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input organization_role_scope_relations_stream_cursor_value_input {
  organization_role_id: String
  organization_scope_id: String
  tenant_id: String
}

"""
update columns of table "organization_role_scope_relations"
"""
enum organization_role_scope_relations_update_column {
  """column name"""
  organization_role_id

  """column name"""
  organization_scope_id

  """column name"""
  tenant_id
}

input organization_role_scope_relations_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: organization_role_scope_relations_set_input

  """filter the rows which have to be updated"""
  where: organization_role_scope_relations_bool_exp!
}

"""
columns and relationships of "organization_role_user_relations"
"""
type organization_role_user_relations {
  organization_id: String!
  organization_role_id: String!
  tenant_id: String!
  user_id: String!
}

"""
aggregated selection of "organization_role_user_relations"
"""
type organization_role_user_relations_aggregate {
  aggregate: organization_role_user_relations_aggregate_fields
  nodes: [organization_role_user_relations!]!
}

"""
aggregate fields of "organization_role_user_relations"
"""
type organization_role_user_relations_aggregate_fields {
  count(columns: [organization_role_user_relations_select_column!], distinct: Boolean): Int!
  max: organization_role_user_relations_max_fields
  min: organization_role_user_relations_min_fields
}

"""
Boolean expression to filter rows from the table "organization_role_user_relations". All fields are combined with a logical 'AND'.
"""
input organization_role_user_relations_bool_exp {
  _and: [organization_role_user_relations_bool_exp!]
  _not: organization_role_user_relations_bool_exp
  _or: [organization_role_user_relations_bool_exp!]
  organization_id: String_comparison_exp
  organization_role_id: String_comparison_exp
  tenant_id: String_comparison_exp
  user_id: String_comparison_exp
}

"""
unique or primary key constraints on table "organization_role_user_relations"
"""
enum organization_role_user_relations_constraint {
  """
  unique or primary key constraint on columns "user_id", "organization_role_id", "tenant_id", "organization_id"
  """
  organization_role_user_relations_pkey
}

"""
input type for inserting data into table "organization_role_user_relations"
"""
input organization_role_user_relations_insert_input {
  organization_id: String
  organization_role_id: String
  tenant_id: String
  user_id: String
}

"""aggregate max on columns"""
type organization_role_user_relations_max_fields {
  organization_id: String
  organization_role_id: String
  tenant_id: String
  user_id: String
}

"""aggregate min on columns"""
type organization_role_user_relations_min_fields {
  organization_id: String
  organization_role_id: String
  tenant_id: String
  user_id: String
}

"""
response of any mutation on the table "organization_role_user_relations"
"""
type organization_role_user_relations_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [organization_role_user_relations!]!
}

"""
on_conflict condition type for table "organization_role_user_relations"
"""
input organization_role_user_relations_on_conflict {
  constraint: organization_role_user_relations_constraint!
  update_columns: [organization_role_user_relations_update_column!]! = []
  where: organization_role_user_relations_bool_exp
}

"""
Ordering options when selecting data from "organization_role_user_relations".
"""
input organization_role_user_relations_order_by {
  organization_id: order_by
  organization_role_id: order_by
  tenant_id: order_by
  user_id: order_by
}

"""primary key columns input for table: organization_role_user_relations"""
input organization_role_user_relations_pk_columns_input {
  organization_id: String!
  organization_role_id: String!
  tenant_id: String!
  user_id: String!
}

"""
select columns of table "organization_role_user_relations"
"""
enum organization_role_user_relations_select_column {
  """column name"""
  organization_id

  """column name"""
  organization_role_id

  """column name"""
  tenant_id

  """column name"""
  user_id
}

"""
input type for updating data in table "organization_role_user_relations"
"""
input organization_role_user_relations_set_input {
  organization_id: String
  organization_role_id: String
  tenant_id: String
  user_id: String
}

"""
Streaming cursor of the table "organization_role_user_relations"
"""
input organization_role_user_relations_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: organization_role_user_relations_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input organization_role_user_relations_stream_cursor_value_input {
  organization_id: String
  organization_role_id: String
  tenant_id: String
  user_id: String
}

"""
update columns of table "organization_role_user_relations"
"""
enum organization_role_user_relations_update_column {
  """column name"""
  organization_id

  """column name"""
  organization_role_id

  """column name"""
  tenant_id

  """column name"""
  user_id
}

input organization_role_user_relations_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: organization_role_user_relations_set_input

  """filter the rows which have to be updated"""
  where: organization_role_user_relations_bool_exp!
}

"""
columns and relationships of "organization_roles"
"""
type organization_roles {
  description: String
  id: String!
  name: String!
  tenant_id: String!
}

"""
aggregated selection of "organization_roles"
"""
type organization_roles_aggregate {
  aggregate: organization_roles_aggregate_fields
  nodes: [organization_roles!]!
}

"""
aggregate fields of "organization_roles"
"""
type organization_roles_aggregate_fields {
  count(columns: [organization_roles_select_column!], distinct: Boolean): Int!
  max: organization_roles_max_fields
  min: organization_roles_min_fields
}

"""
Boolean expression to filter rows from the table "organization_roles". All fields are combined with a logical 'AND'.
"""
input organization_roles_bool_exp {
  _and: [organization_roles_bool_exp!]
  _not: organization_roles_bool_exp
  _or: [organization_roles_bool_exp!]
  description: String_comparison_exp
  id: String_comparison_exp
  name: String_comparison_exp
  tenant_id: String_comparison_exp
}

"""
unique or primary key constraints on table "organization_roles"
"""
enum organization_roles_constraint {
  """
  unique or primary key constraint on columns "tenant_id", "name"
  """
  organization_roles__name

  """
  unique or primary key constraint on columns "id"
  """
  organization_roles_pkey
}

"""
input type for inserting data into table "organization_roles"
"""
input organization_roles_insert_input {
  description: String
  id: String
  name: String
  tenant_id: String
}

"""aggregate max on columns"""
type organization_roles_max_fields {
  description: String
  id: String
  name: String
  tenant_id: String
}

"""aggregate min on columns"""
type organization_roles_min_fields {
  description: String
  id: String
  name: String
  tenant_id: String
}

"""
response of any mutation on the table "organization_roles"
"""
type organization_roles_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [organization_roles!]!
}

"""
on_conflict condition type for table "organization_roles"
"""
input organization_roles_on_conflict {
  constraint: organization_roles_constraint!
  update_columns: [organization_roles_update_column!]! = []
  where: organization_roles_bool_exp
}

"""Ordering options when selecting data from "organization_roles"."""
input organization_roles_order_by {
  description: order_by
  id: order_by
  name: order_by
  tenant_id: order_by
}

"""primary key columns input for table: organization_roles"""
input organization_roles_pk_columns_input {
  id: String!
}

"""
select columns of table "organization_roles"
"""
enum organization_roles_select_column {
  """column name"""
  description

  """column name"""
  id

  """column name"""
  name

  """column name"""
  tenant_id
}

"""
input type for updating data in table "organization_roles"
"""
input organization_roles_set_input {
  description: String
  id: String
  name: String
  tenant_id: String
}

"""
Streaming cursor of the table "organization_roles"
"""
input organization_roles_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: organization_roles_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input organization_roles_stream_cursor_value_input {
  description: String
  id: String
  name: String
  tenant_id: String
}

"""
update columns of table "organization_roles"
"""
enum organization_roles_update_column {
  """column name"""
  description

  """column name"""
  id

  """column name"""
  name

  """column name"""
  tenant_id
}

input organization_roles_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: organization_roles_set_input

  """filter the rows which have to be updated"""
  where: organization_roles_bool_exp!
}

"""
columns and relationships of "organization_scopes"
"""
type organization_scopes {
  description: String
  id: String!
  name: String!
  tenant_id: String!
}

"""
aggregated selection of "organization_scopes"
"""
type organization_scopes_aggregate {
  aggregate: organization_scopes_aggregate_fields
  nodes: [organization_scopes!]!
}

"""
aggregate fields of "organization_scopes"
"""
type organization_scopes_aggregate_fields {
  count(columns: [organization_scopes_select_column!], distinct: Boolean): Int!
  max: organization_scopes_max_fields
  min: organization_scopes_min_fields
}

"""
Boolean expression to filter rows from the table "organization_scopes". All fields are combined with a logical 'AND'.
"""
input organization_scopes_bool_exp {
  _and: [organization_scopes_bool_exp!]
  _not: organization_scopes_bool_exp
  _or: [organization_scopes_bool_exp!]
  description: String_comparison_exp
  id: String_comparison_exp
  name: String_comparison_exp
  tenant_id: String_comparison_exp
}

"""
unique or primary key constraints on table "organization_scopes"
"""
enum organization_scopes_constraint {
  """
  unique or primary key constraint on columns "tenant_id", "name"
  """
  organization_scopes__name

  """
  unique or primary key constraint on columns "id"
  """
  organization_scopes_pkey
}

"""
input type for inserting data into table "organization_scopes"
"""
input organization_scopes_insert_input {
  description: String
  id: String
  name: String
  tenant_id: String
}

"""aggregate max on columns"""
type organization_scopes_max_fields {
  description: String
  id: String
  name: String
  tenant_id: String
}

"""aggregate min on columns"""
type organization_scopes_min_fields {
  description: String
  id: String
  name: String
  tenant_id: String
}

"""
response of any mutation on the table "organization_scopes"
"""
type organization_scopes_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [organization_scopes!]!
}

"""
on_conflict condition type for table "organization_scopes"
"""
input organization_scopes_on_conflict {
  constraint: organization_scopes_constraint!
  update_columns: [organization_scopes_update_column!]! = []
  where: organization_scopes_bool_exp
}

"""Ordering options when selecting data from "organization_scopes"."""
input organization_scopes_order_by {
  description: order_by
  id: order_by
  name: order_by
  tenant_id: order_by
}

"""primary key columns input for table: organization_scopes"""
input organization_scopes_pk_columns_input {
  id: String!
}

"""
select columns of table "organization_scopes"
"""
enum organization_scopes_select_column {
  """column name"""
  description

  """column name"""
  id

  """column name"""
  name

  """column name"""
  tenant_id
}

"""
input type for updating data in table "organization_scopes"
"""
input organization_scopes_set_input {
  description: String
  id: String
  name: String
  tenant_id: String
}

"""
Streaming cursor of the table "organization_scopes"
"""
input organization_scopes_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: organization_scopes_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input organization_scopes_stream_cursor_value_input {
  description: String
  id: String
  name: String
  tenant_id: String
}

"""
update columns of table "organization_scopes"
"""
enum organization_scopes_update_column {
  """column name"""
  description

  """column name"""
  id

  """column name"""
  name

  """column name"""
  tenant_id
}

input organization_scopes_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: organization_scopes_set_input

  """filter the rows which have to be updated"""
  where: organization_scopes_bool_exp!
}

"""
columns and relationships of "organization_user_relations"
"""
type organization_user_relations {
  organization_id: String!
  tenant_id: String!
  user_id: String!
}

"""
aggregated selection of "organization_user_relations"
"""
type organization_user_relations_aggregate {
  aggregate: organization_user_relations_aggregate_fields
  nodes: [organization_user_relations!]!
}

"""
aggregate fields of "organization_user_relations"
"""
type organization_user_relations_aggregate_fields {
  count(columns: [organization_user_relations_select_column!], distinct: Boolean): Int!
  max: organization_user_relations_max_fields
  min: organization_user_relations_min_fields
}

"""
Boolean expression to filter rows from the table "organization_user_relations". All fields are combined with a logical 'AND'.
"""
input organization_user_relations_bool_exp {
  _and: [organization_user_relations_bool_exp!]
  _not: organization_user_relations_bool_exp
  _or: [organization_user_relations_bool_exp!]
  organization_id: String_comparison_exp
  tenant_id: String_comparison_exp
  user_id: String_comparison_exp
}

"""
unique or primary key constraints on table "organization_user_relations"
"""
enum organization_user_relations_constraint {
  """
  unique or primary key constraint on columns "user_id", "tenant_id", "organization_id"
  """
  organization_user_relations_pkey
}

"""
input type for inserting data into table "organization_user_relations"
"""
input organization_user_relations_insert_input {
  organization_id: String
  tenant_id: String
  user_id: String
}

"""aggregate max on columns"""
type organization_user_relations_max_fields {
  organization_id: String
  tenant_id: String
  user_id: String
}

"""aggregate min on columns"""
type organization_user_relations_min_fields {
  organization_id: String
  tenant_id: String
  user_id: String
}

"""
response of any mutation on the table "organization_user_relations"
"""
type organization_user_relations_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [organization_user_relations!]!
}

"""
on_conflict condition type for table "organization_user_relations"
"""
input organization_user_relations_on_conflict {
  constraint: organization_user_relations_constraint!
  update_columns: [organization_user_relations_update_column!]! = []
  where: organization_user_relations_bool_exp
}

"""
Ordering options when selecting data from "organization_user_relations".
"""
input organization_user_relations_order_by {
  organization_id: order_by
  tenant_id: order_by
  user_id: order_by
}

"""primary key columns input for table: organization_user_relations"""
input organization_user_relations_pk_columns_input {
  organization_id: String!
  tenant_id: String!
  user_id: String!
}

"""
select columns of table "organization_user_relations"
"""
enum organization_user_relations_select_column {
  """column name"""
  organization_id

  """column name"""
  tenant_id

  """column name"""
  user_id
}

"""
input type for updating data in table "organization_user_relations"
"""
input organization_user_relations_set_input {
  organization_id: String
  tenant_id: String
  user_id: String
}

"""
Streaming cursor of the table "organization_user_relations"
"""
input organization_user_relations_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: organization_user_relations_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input organization_user_relations_stream_cursor_value_input {
  organization_id: String
  tenant_id: String
  user_id: String
}

"""
update columns of table "organization_user_relations"
"""
enum organization_user_relations_update_column {
  """column name"""
  organization_id

  """column name"""
  tenant_id

  """column name"""
  user_id
}

input organization_user_relations_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: organization_user_relations_set_input

  """filter the rows which have to be updated"""
  where: organization_user_relations_bool_exp!
}

"""
columns and relationships of "organizations"
"""
type organizations {
  created_at: timestamptz!
  description: String
  id: String!
  name: String!
  tenant_id: String!
}

"""
aggregated selection of "organizations"
"""
type organizations_aggregate {
  aggregate: organizations_aggregate_fields
  nodes: [organizations!]!
}

"""
aggregate fields of "organizations"
"""
type organizations_aggregate_fields {
  count(columns: [organizations_select_column!], distinct: Boolean): Int!
  max: organizations_max_fields
  min: organizations_min_fields
}

"""
Boolean expression to filter rows from the table "organizations". All fields are combined with a logical 'AND'.
"""
input organizations_bool_exp {
  _and: [organizations_bool_exp!]
  _not: organizations_bool_exp
  _or: [organizations_bool_exp!]
  created_at: timestamptz_comparison_exp
  description: String_comparison_exp
  id: String_comparison_exp
  name: String_comparison_exp
  tenant_id: String_comparison_exp
}

"""
unique or primary key constraints on table "organizations"
"""
enum organizations_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  organizations_pkey
}

"""
input type for inserting data into table "organizations"
"""
input organizations_insert_input {
  created_at: timestamptz
  description: String
  id: String
  name: String
  tenant_id: String
}

"""aggregate max on columns"""
type organizations_max_fields {
  created_at: timestamptz
  description: String
  id: String
  name: String
  tenant_id: String
}

"""aggregate min on columns"""
type organizations_min_fields {
  created_at: timestamptz
  description: String
  id: String
  name: String
  tenant_id: String
}

"""
response of any mutation on the table "organizations"
"""
type organizations_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [organizations!]!
}

"""
on_conflict condition type for table "organizations"
"""
input organizations_on_conflict {
  constraint: organizations_constraint!
  update_columns: [organizations_update_column!]! = []
  where: organizations_bool_exp
}

"""Ordering options when selecting data from "organizations"."""
input organizations_order_by {
  created_at: order_by
  description: order_by
  id: order_by
  name: order_by
  tenant_id: order_by
}

"""primary key columns input for table: organizations"""
input organizations_pk_columns_input {
  id: String!
}

"""
select columns of table "organizations"
"""
enum organizations_select_column {
  """column name"""
  created_at

  """column name"""
  description

  """column name"""
  id

  """column name"""
  name

  """column name"""
  tenant_id
}

"""
input type for updating data in table "organizations"
"""
input organizations_set_input {
  created_at: timestamptz
  description: String
  id: String
  name: String
  tenant_id: String
}

"""
Streaming cursor of the table "organizations"
"""
input organizations_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: organizations_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input organizations_stream_cursor_value_input {
  created_at: timestamptz
  description: String
  id: String
  name: String
  tenant_id: String
}

"""
update columns of table "organizations"
"""
enum organizations_update_column {
  """column name"""
  created_at

  """column name"""
  description

  """column name"""
  id

  """column name"""
  name

  """column name"""
  tenant_id
}

input organizations_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: organizations_set_input

  """filter the rows which have to be updated"""
  where: organizations_bool_exp!
}

"""
columns and relationships of "passcodes"
"""
type passcodes {
  code: String!
  consumed: Boolean!
  created_at: timestamptz!
  email: String
  id: String!
  interaction_jti: String
  phone: String
  tenant_id: String!
  try_count: smallint!
  type: String!
}

"""
aggregated selection of "passcodes"
"""
type passcodes_aggregate {
  aggregate: passcodes_aggregate_fields
  nodes: [passcodes!]!
}

"""
aggregate fields of "passcodes"
"""
type passcodes_aggregate_fields {
  avg: passcodes_avg_fields
  count(columns: [passcodes_select_column!], distinct: Boolean): Int!
  max: passcodes_max_fields
  min: passcodes_min_fields
  stddev: passcodes_stddev_fields
  stddev_pop: passcodes_stddev_pop_fields
  stddev_samp: passcodes_stddev_samp_fields
  sum: passcodes_sum_fields
  var_pop: passcodes_var_pop_fields
  var_samp: passcodes_var_samp_fields
  variance: passcodes_variance_fields
}

"""aggregate avg on columns"""
type passcodes_avg_fields {
  try_count: Float
}

"""
Boolean expression to filter rows from the table "passcodes". All fields are combined with a logical 'AND'.
"""
input passcodes_bool_exp {
  _and: [passcodes_bool_exp!]
  _not: passcodes_bool_exp
  _or: [passcodes_bool_exp!]
  code: String_comparison_exp
  consumed: Boolean_comparison_exp
  created_at: timestamptz_comparison_exp
  email: String_comparison_exp
  id: String_comparison_exp
  interaction_jti: String_comparison_exp
  phone: String_comparison_exp
  tenant_id: String_comparison_exp
  try_count: smallint_comparison_exp
  type: String_comparison_exp
}

"""
unique or primary key constraints on table "passcodes"
"""
enum passcodes_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  passcodes_pkey
}

"""
input type for incrementing numeric columns in table "passcodes"
"""
input passcodes_inc_input {
  try_count: smallint
}

"""
input type for inserting data into table "passcodes"
"""
input passcodes_insert_input {
  code: String
  consumed: Boolean
  created_at: timestamptz
  email: String
  id: String
  interaction_jti: String
  phone: String
  tenant_id: String
  try_count: smallint
  type: String
}

"""aggregate max on columns"""
type passcodes_max_fields {
  code: String
  created_at: timestamptz
  email: String
  id: String
  interaction_jti: String
  phone: String
  tenant_id: String
  try_count: smallint
  type: String
}

"""aggregate min on columns"""
type passcodes_min_fields {
  code: String
  created_at: timestamptz
  email: String
  id: String
  interaction_jti: String
  phone: String
  tenant_id: String
  try_count: smallint
  type: String
}

"""
response of any mutation on the table "passcodes"
"""
type passcodes_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [passcodes!]!
}

"""
on_conflict condition type for table "passcodes"
"""
input passcodes_on_conflict {
  constraint: passcodes_constraint!
  update_columns: [passcodes_update_column!]! = []
  where: passcodes_bool_exp
}

"""Ordering options when selecting data from "passcodes"."""
input passcodes_order_by {
  code: order_by
  consumed: order_by
  created_at: order_by
  email: order_by
  id: order_by
  interaction_jti: order_by
  phone: order_by
  tenant_id: order_by
  try_count: order_by
  type: order_by
}

"""primary key columns input for table: passcodes"""
input passcodes_pk_columns_input {
  id: String!
}

"""
select columns of table "passcodes"
"""
enum passcodes_select_column {
  """column name"""
  code

  """column name"""
  consumed

  """column name"""
  created_at

  """column name"""
  email

  """column name"""
  id

  """column name"""
  interaction_jti

  """column name"""
  phone

  """column name"""
  tenant_id

  """column name"""
  try_count

  """column name"""
  type
}

"""
input type for updating data in table "passcodes"
"""
input passcodes_set_input {
  code: String
  consumed: Boolean
  created_at: timestamptz
  email: String
  id: String
  interaction_jti: String
  phone: String
  tenant_id: String
  try_count: smallint
  type: String
}

"""aggregate stddev on columns"""
type passcodes_stddev_fields {
  try_count: Float
}

"""aggregate stddev_pop on columns"""
type passcodes_stddev_pop_fields {
  try_count: Float
}

"""aggregate stddev_samp on columns"""
type passcodes_stddev_samp_fields {
  try_count: Float
}

"""
Streaming cursor of the table "passcodes"
"""
input passcodes_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: passcodes_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input passcodes_stream_cursor_value_input {
  code: String
  consumed: Boolean
  created_at: timestamptz
  email: String
  id: String
  interaction_jti: String
  phone: String
  tenant_id: String
  try_count: smallint
  type: String
}

"""aggregate sum on columns"""
type passcodes_sum_fields {
  try_count: smallint
}

"""
update columns of table "passcodes"
"""
enum passcodes_update_column {
  """column name"""
  code

  """column name"""
  consumed

  """column name"""
  created_at

  """column name"""
  email

  """column name"""
  id

  """column name"""
  interaction_jti

  """column name"""
  phone

  """column name"""
  tenant_id

  """column name"""
  try_count

  """column name"""
  type
}

input passcodes_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: passcodes_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: passcodes_set_input

  """filter the rows which have to be updated"""
  where: passcodes_bool_exp!
}

"""aggregate var_pop on columns"""
type passcodes_var_pop_fields {
  try_count: Float
}

"""aggregate var_samp on columns"""
type passcodes_var_samp_fields {
  try_count: Float
}

"""aggregate variance on columns"""
type passcodes_variance_fields {
  try_count: Float
}

"""
columns and relationships of "pg_buffercache"
"""
type pg_buffercache {
  bufferid: Int
  isdirty: Boolean
  pinning_backends: Int
  relblocknumber: bigint
  reldatabase: oid
  relfilenode: oid
  relforknumber: smallint
  reltablespace: oid
  usagecount: smallint
}

"""
aggregated selection of "pg_buffercache"
"""
type pg_buffercache_aggregate {
  aggregate: pg_buffercache_aggregate_fields
  nodes: [pg_buffercache!]!
}

"""
aggregate fields of "pg_buffercache"
"""
type pg_buffercache_aggregate_fields {
  avg: pg_buffercache_avg_fields
  count(columns: [pg_buffercache_select_column!], distinct: Boolean): Int!
  max: pg_buffercache_max_fields
  min: pg_buffercache_min_fields
  stddev: pg_buffercache_stddev_fields
  stddev_pop: pg_buffercache_stddev_pop_fields
  stddev_samp: pg_buffercache_stddev_samp_fields
  sum: pg_buffercache_sum_fields
  var_pop: pg_buffercache_var_pop_fields
  var_samp: pg_buffercache_var_samp_fields
  variance: pg_buffercache_variance_fields
}

"""aggregate avg on columns"""
type pg_buffercache_avg_fields {
  bufferid: Float
  pinning_backends: Float
  relblocknumber: Float
  relforknumber: Float
  usagecount: Float
}

"""
Boolean expression to filter rows from the table "pg_buffercache". All fields are combined with a logical 'AND'.
"""
input pg_buffercache_bool_exp {
  _and: [pg_buffercache_bool_exp!]
  _not: pg_buffercache_bool_exp
  _or: [pg_buffercache_bool_exp!]
  bufferid: Int_comparison_exp
  isdirty: Boolean_comparison_exp
  pinning_backends: Int_comparison_exp
  relblocknumber: bigint_comparison_exp
  reldatabase: oid_comparison_exp
  relfilenode: oid_comparison_exp
  relforknumber: smallint_comparison_exp
  reltablespace: oid_comparison_exp
  usagecount: smallint_comparison_exp
}

"""aggregate max on columns"""
type pg_buffercache_max_fields {
  bufferid: Int
  pinning_backends: Int
  relblocknumber: bigint
  relforknumber: smallint
  usagecount: smallint
}

"""aggregate min on columns"""
type pg_buffercache_min_fields {
  bufferid: Int
  pinning_backends: Int
  relblocknumber: bigint
  relforknumber: smallint
  usagecount: smallint
}

"""Ordering options when selecting data from "pg_buffercache"."""
input pg_buffercache_order_by {
  bufferid: order_by
  isdirty: order_by
  pinning_backends: order_by
  relblocknumber: order_by
  reldatabase: order_by
  relfilenode: order_by
  relforknumber: order_by
  reltablespace: order_by
  usagecount: order_by
}

"""
select columns of table "pg_buffercache"
"""
enum pg_buffercache_select_column {
  """column name"""
  bufferid

  """column name"""
  isdirty

  """column name"""
  pinning_backends

  """column name"""
  relblocknumber

  """column name"""
  reldatabase

  """column name"""
  relfilenode

  """column name"""
  relforknumber

  """column name"""
  reltablespace

  """column name"""
  usagecount
}

"""aggregate stddev on columns"""
type pg_buffercache_stddev_fields {
  bufferid: Float
  pinning_backends: Float
  relblocknumber: Float
  relforknumber: Float
  usagecount: Float
}

"""aggregate stddev_pop on columns"""
type pg_buffercache_stddev_pop_fields {
  bufferid: Float
  pinning_backends: Float
  relblocknumber: Float
  relforknumber: Float
  usagecount: Float
}

"""aggregate stddev_samp on columns"""
type pg_buffercache_stddev_samp_fields {
  bufferid: Float
  pinning_backends: Float
  relblocknumber: Float
  relforknumber: Float
  usagecount: Float
}

"""
Streaming cursor of the table "pg_buffercache"
"""
input pg_buffercache_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: pg_buffercache_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input pg_buffercache_stream_cursor_value_input {
  bufferid: Int
  isdirty: Boolean
  pinning_backends: Int
  relblocknumber: bigint
  reldatabase: oid
  relfilenode: oid
  relforknumber: smallint
  reltablespace: oid
  usagecount: smallint
}

"""aggregate sum on columns"""
type pg_buffercache_sum_fields {
  bufferid: Int
  pinning_backends: Int
  relblocknumber: bigint
  relforknumber: smallint
  usagecount: smallint
}

"""aggregate var_pop on columns"""
type pg_buffercache_var_pop_fields {
  bufferid: Float
  pinning_backends: Float
  relblocknumber: Float
  relforknumber: Float
  usagecount: Float
}

"""aggregate var_samp on columns"""
type pg_buffercache_var_samp_fields {
  bufferid: Float
  pinning_backends: Float
  relblocknumber: Float
  relforknumber: Float
  usagecount: Float
}

"""aggregate variance on columns"""
type pg_buffercache_variance_fields {
  bufferid: Float
  pinning_backends: Float
  relblocknumber: Float
  relforknumber: Float
  usagecount: Float
}

"""
columns and relationships of "pg_stat_statements"
"""
type pg_stat_statements {
  blk_read_time: float8
  blk_write_time: float8
  calls: bigint
  dbid: oid
  jit_emission_count: bigint
  jit_emission_time: float8
  jit_functions: bigint
  jit_generation_time: float8
  jit_inlining_count: bigint
  jit_inlining_time: float8
  jit_optimization_count: bigint
  jit_optimization_time: float8
  local_blks_dirtied: bigint
  local_blks_hit: bigint
  local_blks_read: bigint
  local_blks_written: bigint
  max_exec_time: float8
  max_plan_time: float8
  mean_exec_time: float8
  mean_plan_time: float8
  min_exec_time: float8
  min_plan_time: float8
  plans: bigint
  query: String
  queryid: bigint
  rows: bigint
  shared_blks_dirtied: bigint
  shared_blks_hit: bigint
  shared_blks_read: bigint
  shared_blks_written: bigint
  stddev_exec_time: float8
  stddev_plan_time: float8
  temp_blk_read_time: float8
  temp_blk_write_time: float8
  temp_blks_read: bigint
  temp_blks_written: bigint
  toplevel: Boolean
  total_exec_time: float8
  total_plan_time: float8
  userid: oid
  wal_bytes: numeric
  wal_fpi: bigint
  wal_records: bigint
}

"""
aggregated selection of "pg_stat_statements"
"""
type pg_stat_statements_aggregate {
  aggregate: pg_stat_statements_aggregate_fields
  nodes: [pg_stat_statements!]!
}

"""
aggregate fields of "pg_stat_statements"
"""
type pg_stat_statements_aggregate_fields {
  avg: pg_stat_statements_avg_fields
  count(columns: [pg_stat_statements_select_column!], distinct: Boolean): Int!
  max: pg_stat_statements_max_fields
  min: pg_stat_statements_min_fields
  stddev: pg_stat_statements_stddev_fields
  stddev_pop: pg_stat_statements_stddev_pop_fields
  stddev_samp: pg_stat_statements_stddev_samp_fields
  sum: pg_stat_statements_sum_fields
  var_pop: pg_stat_statements_var_pop_fields
  var_samp: pg_stat_statements_var_samp_fields
  variance: pg_stat_statements_variance_fields
}

"""aggregate avg on columns"""
type pg_stat_statements_avg_fields {
  blk_read_time: Float
  blk_write_time: Float
  calls: Float
  jit_emission_count: Float
  jit_emission_time: Float
  jit_functions: Float
  jit_generation_time: Float
  jit_inlining_count: Float
  jit_inlining_time: Float
  jit_optimization_count: Float
  jit_optimization_time: Float
  local_blks_dirtied: Float
  local_blks_hit: Float
  local_blks_read: Float
  local_blks_written: Float
  max_exec_time: Float
  max_plan_time: Float
  mean_exec_time: Float
  mean_plan_time: Float
  min_exec_time: Float
  min_plan_time: Float
  plans: Float
  queryid: Float
  rows: Float
  shared_blks_dirtied: Float
  shared_blks_hit: Float
  shared_blks_read: Float
  shared_blks_written: Float
  stddev_exec_time: Float
  stddev_plan_time: Float
  temp_blk_read_time: Float
  temp_blk_write_time: Float
  temp_blks_read: Float
  temp_blks_written: Float
  total_exec_time: Float
  total_plan_time: Float
  wal_bytes: Float
  wal_fpi: Float
  wal_records: Float
}

"""
Boolean expression to filter rows from the table "pg_stat_statements". All fields are combined with a logical 'AND'.
"""
input pg_stat_statements_bool_exp {
  _and: [pg_stat_statements_bool_exp!]
  _not: pg_stat_statements_bool_exp
  _or: [pg_stat_statements_bool_exp!]
  blk_read_time: float8_comparison_exp
  blk_write_time: float8_comparison_exp
  calls: bigint_comparison_exp
  dbid: oid_comparison_exp
  jit_emission_count: bigint_comparison_exp
  jit_emission_time: float8_comparison_exp
  jit_functions: bigint_comparison_exp
  jit_generation_time: float8_comparison_exp
  jit_inlining_count: bigint_comparison_exp
  jit_inlining_time: float8_comparison_exp
  jit_optimization_count: bigint_comparison_exp
  jit_optimization_time: float8_comparison_exp
  local_blks_dirtied: bigint_comparison_exp
  local_blks_hit: bigint_comparison_exp
  local_blks_read: bigint_comparison_exp
  local_blks_written: bigint_comparison_exp
  max_exec_time: float8_comparison_exp
  max_plan_time: float8_comparison_exp
  mean_exec_time: float8_comparison_exp
  mean_plan_time: float8_comparison_exp
  min_exec_time: float8_comparison_exp
  min_plan_time: float8_comparison_exp
  plans: bigint_comparison_exp
  query: String_comparison_exp
  queryid: bigint_comparison_exp
  rows: bigint_comparison_exp
  shared_blks_dirtied: bigint_comparison_exp
  shared_blks_hit: bigint_comparison_exp
  shared_blks_read: bigint_comparison_exp
  shared_blks_written: bigint_comparison_exp
  stddev_exec_time: float8_comparison_exp
  stddev_plan_time: float8_comparison_exp
  temp_blk_read_time: float8_comparison_exp
  temp_blk_write_time: float8_comparison_exp
  temp_blks_read: bigint_comparison_exp
  temp_blks_written: bigint_comparison_exp
  toplevel: Boolean_comparison_exp
  total_exec_time: float8_comparison_exp
  total_plan_time: float8_comparison_exp
  userid: oid_comparison_exp
  wal_bytes: numeric_comparison_exp
  wal_fpi: bigint_comparison_exp
  wal_records: bigint_comparison_exp
}

"""
columns and relationships of "pg_stat_statements_info"
"""
type pg_stat_statements_info {
  dealloc: bigint
  stats_reset: timestamptz
}

"""
aggregated selection of "pg_stat_statements_info"
"""
type pg_stat_statements_info_aggregate {
  aggregate: pg_stat_statements_info_aggregate_fields
  nodes: [pg_stat_statements_info!]!
}

"""
aggregate fields of "pg_stat_statements_info"
"""
type pg_stat_statements_info_aggregate_fields {
  avg: pg_stat_statements_info_avg_fields
  count(columns: [pg_stat_statements_info_select_column!], distinct: Boolean): Int!
  max: pg_stat_statements_info_max_fields
  min: pg_stat_statements_info_min_fields
  stddev: pg_stat_statements_info_stddev_fields
  stddev_pop: pg_stat_statements_info_stddev_pop_fields
  stddev_samp: pg_stat_statements_info_stddev_samp_fields
  sum: pg_stat_statements_info_sum_fields
  var_pop: pg_stat_statements_info_var_pop_fields
  var_samp: pg_stat_statements_info_var_samp_fields
  variance: pg_stat_statements_info_variance_fields
}

"""aggregate avg on columns"""
type pg_stat_statements_info_avg_fields {
  dealloc: Float
}

"""
Boolean expression to filter rows from the table "pg_stat_statements_info". All fields are combined with a logical 'AND'.
"""
input pg_stat_statements_info_bool_exp {
  _and: [pg_stat_statements_info_bool_exp!]
  _not: pg_stat_statements_info_bool_exp
  _or: [pg_stat_statements_info_bool_exp!]
  dealloc: bigint_comparison_exp
  stats_reset: timestamptz_comparison_exp
}

"""aggregate max on columns"""
type pg_stat_statements_info_max_fields {
  dealloc: bigint
  stats_reset: timestamptz
}

"""aggregate min on columns"""
type pg_stat_statements_info_min_fields {
  dealloc: bigint
  stats_reset: timestamptz
}

"""Ordering options when selecting data from "pg_stat_statements_info"."""
input pg_stat_statements_info_order_by {
  dealloc: order_by
  stats_reset: order_by
}

"""
select columns of table "pg_stat_statements_info"
"""
enum pg_stat_statements_info_select_column {
  """column name"""
  dealloc

  """column name"""
  stats_reset
}

"""aggregate stddev on columns"""
type pg_stat_statements_info_stddev_fields {
  dealloc: Float
}

"""aggregate stddev_pop on columns"""
type pg_stat_statements_info_stddev_pop_fields {
  dealloc: Float
}

"""aggregate stddev_samp on columns"""
type pg_stat_statements_info_stddev_samp_fields {
  dealloc: Float
}

"""
Streaming cursor of the table "pg_stat_statements_info"
"""
input pg_stat_statements_info_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: pg_stat_statements_info_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input pg_stat_statements_info_stream_cursor_value_input {
  dealloc: bigint
  stats_reset: timestamptz
}

"""aggregate sum on columns"""
type pg_stat_statements_info_sum_fields {
  dealloc: bigint
}

"""aggregate var_pop on columns"""
type pg_stat_statements_info_var_pop_fields {
  dealloc: Float
}

"""aggregate var_samp on columns"""
type pg_stat_statements_info_var_samp_fields {
  dealloc: Float
}

"""aggregate variance on columns"""
type pg_stat_statements_info_variance_fields {
  dealloc: Float
}

"""aggregate max on columns"""
type pg_stat_statements_max_fields {
  blk_read_time: float8
  blk_write_time: float8
  calls: bigint
  jit_emission_count: bigint
  jit_emission_time: float8
  jit_functions: bigint
  jit_generation_time: float8
  jit_inlining_count: bigint
  jit_inlining_time: float8
  jit_optimization_count: bigint
  jit_optimization_time: float8
  local_blks_dirtied: bigint
  local_blks_hit: bigint
  local_blks_read: bigint
  local_blks_written: bigint
  max_exec_time: float8
  max_plan_time: float8
  mean_exec_time: float8
  mean_plan_time: float8
  min_exec_time: float8
  min_plan_time: float8
  plans: bigint
  query: String
  queryid: bigint
  rows: bigint
  shared_blks_dirtied: bigint
  shared_blks_hit: bigint
  shared_blks_read: bigint
  shared_blks_written: bigint
  stddev_exec_time: float8
  stddev_plan_time: float8
  temp_blk_read_time: float8
  temp_blk_write_time: float8
  temp_blks_read: bigint
  temp_blks_written: bigint
  total_exec_time: float8
  total_plan_time: float8
  wal_bytes: numeric
  wal_fpi: bigint
  wal_records: bigint
}

"""aggregate min on columns"""
type pg_stat_statements_min_fields {
  blk_read_time: float8
  blk_write_time: float8
  calls: bigint
  jit_emission_count: bigint
  jit_emission_time: float8
  jit_functions: bigint
  jit_generation_time: float8
  jit_inlining_count: bigint
  jit_inlining_time: float8
  jit_optimization_count: bigint
  jit_optimization_time: float8
  local_blks_dirtied: bigint
  local_blks_hit: bigint
  local_blks_read: bigint
  local_blks_written: bigint
  max_exec_time: float8
  max_plan_time: float8
  mean_exec_time: float8
  mean_plan_time: float8
  min_exec_time: float8
  min_plan_time: float8
  plans: bigint
  query: String
  queryid: bigint
  rows: bigint
  shared_blks_dirtied: bigint
  shared_blks_hit: bigint
  shared_blks_read: bigint
  shared_blks_written: bigint
  stddev_exec_time: float8
  stddev_plan_time: float8
  temp_blk_read_time: float8
  temp_blk_write_time: float8
  temp_blks_read: bigint
  temp_blks_written: bigint
  total_exec_time: float8
  total_plan_time: float8
  wal_bytes: numeric
  wal_fpi: bigint
  wal_records: bigint
}

"""Ordering options when selecting data from "pg_stat_statements"."""
input pg_stat_statements_order_by {
  blk_read_time: order_by
  blk_write_time: order_by
  calls: order_by
  dbid: order_by
  jit_emission_count: order_by
  jit_emission_time: order_by
  jit_functions: order_by
  jit_generation_time: order_by
  jit_inlining_count: order_by
  jit_inlining_time: order_by
  jit_optimization_count: order_by
  jit_optimization_time: order_by
  local_blks_dirtied: order_by
  local_blks_hit: order_by
  local_blks_read: order_by
  local_blks_written: order_by
  max_exec_time: order_by
  max_plan_time: order_by
  mean_exec_time: order_by
  mean_plan_time: order_by
  min_exec_time: order_by
  min_plan_time: order_by
  plans: order_by
  query: order_by
  queryid: order_by
  rows: order_by
  shared_blks_dirtied: order_by
  shared_blks_hit: order_by
  shared_blks_read: order_by
  shared_blks_written: order_by
  stddev_exec_time: order_by
  stddev_plan_time: order_by
  temp_blk_read_time: order_by
  temp_blk_write_time: order_by
  temp_blks_read: order_by
  temp_blks_written: order_by
  toplevel: order_by
  total_exec_time: order_by
  total_plan_time: order_by
  userid: order_by
  wal_bytes: order_by
  wal_fpi: order_by
  wal_records: order_by
}

"""
select columns of table "pg_stat_statements"
"""
enum pg_stat_statements_select_column {
  """column name"""
  blk_read_time

  """column name"""
  blk_write_time

  """column name"""
  calls

  """column name"""
  dbid

  """column name"""
  jit_emission_count

  """column name"""
  jit_emission_time

  """column name"""
  jit_functions

  """column name"""
  jit_generation_time

  """column name"""
  jit_inlining_count

  """column name"""
  jit_inlining_time

  """column name"""
  jit_optimization_count

  """column name"""
  jit_optimization_time

  """column name"""
  local_blks_dirtied

  """column name"""
  local_blks_hit

  """column name"""
  local_blks_read

  """column name"""
  local_blks_written

  """column name"""
  max_exec_time

  """column name"""
  max_plan_time

  """column name"""
  mean_exec_time

  """column name"""
  mean_plan_time

  """column name"""
  min_exec_time

  """column name"""
  min_plan_time

  """column name"""
  plans

  """column name"""
  query

  """column name"""
  queryid

  """column name"""
  rows

  """column name"""
  shared_blks_dirtied

  """column name"""
  shared_blks_hit

  """column name"""
  shared_blks_read

  """column name"""
  shared_blks_written

  """column name"""
  stddev_exec_time

  """column name"""
  stddev_plan_time

  """column name"""
  temp_blk_read_time

  """column name"""
  temp_blk_write_time

  """column name"""
  temp_blks_read

  """column name"""
  temp_blks_written

  """column name"""
  toplevel

  """column name"""
  total_exec_time

  """column name"""
  total_plan_time

  """column name"""
  userid

  """column name"""
  wal_bytes

  """column name"""
  wal_fpi

  """column name"""
  wal_records
}

"""aggregate stddev on columns"""
type pg_stat_statements_stddev_fields {
  blk_read_time: Float
  blk_write_time: Float
  calls: Float
  jit_emission_count: Float
  jit_emission_time: Float
  jit_functions: Float
  jit_generation_time: Float
  jit_inlining_count: Float
  jit_inlining_time: Float
  jit_optimization_count: Float
  jit_optimization_time: Float
  local_blks_dirtied: Float
  local_blks_hit: Float
  local_blks_read: Float
  local_blks_written: Float
  max_exec_time: Float
  max_plan_time: Float
  mean_exec_time: Float
  mean_plan_time: Float
  min_exec_time: Float
  min_plan_time: Float
  plans: Float
  queryid: Float
  rows: Float
  shared_blks_dirtied: Float
  shared_blks_hit: Float
  shared_blks_read: Float
  shared_blks_written: Float
  stddev_exec_time: Float
  stddev_plan_time: Float
  temp_blk_read_time: Float
  temp_blk_write_time: Float
  temp_blks_read: Float
  temp_blks_written: Float
  total_exec_time: Float
  total_plan_time: Float
  wal_bytes: Float
  wal_fpi: Float
  wal_records: Float
}

"""aggregate stddev_pop on columns"""
type pg_stat_statements_stddev_pop_fields {
  blk_read_time: Float
  blk_write_time: Float
  calls: Float
  jit_emission_count: Float
  jit_emission_time: Float
  jit_functions: Float
  jit_generation_time: Float
  jit_inlining_count: Float
  jit_inlining_time: Float
  jit_optimization_count: Float
  jit_optimization_time: Float
  local_blks_dirtied: Float
  local_blks_hit: Float
  local_blks_read: Float
  local_blks_written: Float
  max_exec_time: Float
  max_plan_time: Float
  mean_exec_time: Float
  mean_plan_time: Float
  min_exec_time: Float
  min_plan_time: Float
  plans: Float
  queryid: Float
  rows: Float
  shared_blks_dirtied: Float
  shared_blks_hit: Float
  shared_blks_read: Float
  shared_blks_written: Float
  stddev_exec_time: Float
  stddev_plan_time: Float
  temp_blk_read_time: Float
  temp_blk_write_time: Float
  temp_blks_read: Float
  temp_blks_written: Float
  total_exec_time: Float
  total_plan_time: Float
  wal_bytes: Float
  wal_fpi: Float
  wal_records: Float
}

"""aggregate stddev_samp on columns"""
type pg_stat_statements_stddev_samp_fields {
  blk_read_time: Float
  blk_write_time: Float
  calls: Float
  jit_emission_count: Float
  jit_emission_time: Float
  jit_functions: Float
  jit_generation_time: Float
  jit_inlining_count: Float
  jit_inlining_time: Float
  jit_optimization_count: Float
  jit_optimization_time: Float
  local_blks_dirtied: Float
  local_blks_hit: Float
  local_blks_read: Float
  local_blks_written: Float
  max_exec_time: Float
  max_plan_time: Float
  mean_exec_time: Float
  mean_plan_time: Float
  min_exec_time: Float
  min_plan_time: Float
  plans: Float
  queryid: Float
  rows: Float
  shared_blks_dirtied: Float
  shared_blks_hit: Float
  shared_blks_read: Float
  shared_blks_written: Float
  stddev_exec_time: Float
  stddev_plan_time: Float
  temp_blk_read_time: Float
  temp_blk_write_time: Float
  temp_blks_read: Float
  temp_blks_written: Float
  total_exec_time: Float
  total_plan_time: Float
  wal_bytes: Float
  wal_fpi: Float
  wal_records: Float
}

"""
Streaming cursor of the table "pg_stat_statements"
"""
input pg_stat_statements_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: pg_stat_statements_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input pg_stat_statements_stream_cursor_value_input {
  blk_read_time: float8
  blk_write_time: float8
  calls: bigint
  dbid: oid
  jit_emission_count: bigint
  jit_emission_time: float8
  jit_functions: bigint
  jit_generation_time: float8
  jit_inlining_count: bigint
  jit_inlining_time: float8
  jit_optimization_count: bigint
  jit_optimization_time: float8
  local_blks_dirtied: bigint
  local_blks_hit: bigint
  local_blks_read: bigint
  local_blks_written: bigint
  max_exec_time: float8
  max_plan_time: float8
  mean_exec_time: float8
  mean_plan_time: float8
  min_exec_time: float8
  min_plan_time: float8
  plans: bigint
  query: String
  queryid: bigint
  rows: bigint
  shared_blks_dirtied: bigint
  shared_blks_hit: bigint
  shared_blks_read: bigint
  shared_blks_written: bigint
  stddev_exec_time: float8
  stddev_plan_time: float8
  temp_blk_read_time: float8
  temp_blk_write_time: float8
  temp_blks_read: bigint
  temp_blks_written: bigint
  toplevel: Boolean
  total_exec_time: float8
  total_plan_time: float8
  userid: oid
  wal_bytes: numeric
  wal_fpi: bigint
  wal_records: bigint
}

"""aggregate sum on columns"""
type pg_stat_statements_sum_fields {
  blk_read_time: float8
  blk_write_time: float8
  calls: bigint
  jit_emission_count: bigint
  jit_emission_time: float8
  jit_functions: bigint
  jit_generation_time: float8
  jit_inlining_count: bigint
  jit_inlining_time: float8
  jit_optimization_count: bigint
  jit_optimization_time: float8
  local_blks_dirtied: bigint
  local_blks_hit: bigint
  local_blks_read: bigint
  local_blks_written: bigint
  max_exec_time: float8
  max_plan_time: float8
  mean_exec_time: float8
  mean_plan_time: float8
  min_exec_time: float8
  min_plan_time: float8
  plans: bigint
  queryid: bigint
  rows: bigint
  shared_blks_dirtied: bigint
  shared_blks_hit: bigint
  shared_blks_read: bigint
  shared_blks_written: bigint
  stddev_exec_time: float8
  stddev_plan_time: float8
  temp_blk_read_time: float8
  temp_blk_write_time: float8
  temp_blks_read: bigint
  temp_blks_written: bigint
  total_exec_time: float8
  total_plan_time: float8
  wal_bytes: numeric
  wal_fpi: bigint
  wal_records: bigint
}

"""aggregate var_pop on columns"""
type pg_stat_statements_var_pop_fields {
  blk_read_time: Float
  blk_write_time: Float
  calls: Float
  jit_emission_count: Float
  jit_emission_time: Float
  jit_functions: Float
  jit_generation_time: Float
  jit_inlining_count: Float
  jit_inlining_time: Float
  jit_optimization_count: Float
  jit_optimization_time: Float
  local_blks_dirtied: Float
  local_blks_hit: Float
  local_blks_read: Float
  local_blks_written: Float
  max_exec_time: Float
  max_plan_time: Float
  mean_exec_time: Float
  mean_plan_time: Float
  min_exec_time: Float
  min_plan_time: Float
  plans: Float
  queryid: Float
  rows: Float
  shared_blks_dirtied: Float
  shared_blks_hit: Float
  shared_blks_read: Float
  shared_blks_written: Float
  stddev_exec_time: Float
  stddev_plan_time: Float
  temp_blk_read_time: Float
  temp_blk_write_time: Float
  temp_blks_read: Float
  temp_blks_written: Float
  total_exec_time: Float
  total_plan_time: Float
  wal_bytes: Float
  wal_fpi: Float
  wal_records: Float
}

"""aggregate var_samp on columns"""
type pg_stat_statements_var_samp_fields {
  blk_read_time: Float
  blk_write_time: Float
  calls: Float
  jit_emission_count: Float
  jit_emission_time: Float
  jit_functions: Float
  jit_generation_time: Float
  jit_inlining_count: Float
  jit_inlining_time: Float
  jit_optimization_count: Float
  jit_optimization_time: Float
  local_blks_dirtied: Float
  local_blks_hit: Float
  local_blks_read: Float
  local_blks_written: Float
  max_exec_time: Float
  max_plan_time: Float
  mean_exec_time: Float
  mean_plan_time: Float
  min_exec_time: Float
  min_plan_time: Float
  plans: Float
  queryid: Float
  rows: Float
  shared_blks_dirtied: Float
  shared_blks_hit: Float
  shared_blks_read: Float
  shared_blks_written: Float
  stddev_exec_time: Float
  stddev_plan_time: Float
  temp_blk_read_time: Float
  temp_blk_write_time: Float
  temp_blks_read: Float
  temp_blks_written: Float
  total_exec_time: Float
  total_plan_time: Float
  wal_bytes: Float
  wal_fpi: Float
  wal_records: Float
}

"""aggregate variance on columns"""
type pg_stat_statements_variance_fields {
  blk_read_time: Float
  blk_write_time: Float
  calls: Float
  jit_emission_count: Float
  jit_emission_time: Float
  jit_functions: Float
  jit_generation_time: Float
  jit_inlining_count: Float
  jit_inlining_time: Float
  jit_optimization_count: Float
  jit_optimization_time: Float
  local_blks_dirtied: Float
  local_blks_hit: Float
  local_blks_read: Float
  local_blks_written: Float
  max_exec_time: Float
  max_plan_time: Float
  mean_exec_time: Float
  mean_plan_time: Float
  min_exec_time: Float
  min_plan_time: Float
  plans: Float
  queryid: Float
  rows: Float
  shared_blks_dirtied: Float
  shared_blks_hit: Float
  shared_blks_read: Float
  shared_blks_written: Float
  stddev_exec_time: Float
  stddev_plan_time: Float
  temp_blk_read_time: Float
  temp_blk_write_time: Float
  temp_blks_read: Float
  temp_blks_written: Float
  total_exec_time: Float
  total_plan_time: Float
  wal_bytes: Float
  wal_fpi: Float
  wal_records: Float
}

type query_root {
  """
  fetch data from the table: "ads"
  """
  ads(
    """distinct select on columns"""
    distinct_on: [ads_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [ads_order_by!]

    """filter the rows returned"""
    where: ads_bool_exp
  ): [ads!]!

  """
  fetch aggregated fields from the table: "ads"
  """
  ads_aggregate(
    """distinct select on columns"""
    distinct_on: [ads_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [ads_order_by!]

    """filter the rows returned"""
    where: ads_bool_exp
  ): ads_aggregate!

  """fetch data from the table: "ads" using primary key columns"""
  ads_by_pk(id: uuid!): ads

  """
  fetch data from the table: "application_sign_in_experiences"
  """
  application_sign_in_experiences(
    """distinct select on columns"""
    distinct_on: [application_sign_in_experiences_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [application_sign_in_experiences_order_by!]

    """filter the rows returned"""
    where: application_sign_in_experiences_bool_exp
  ): [application_sign_in_experiences!]!

  """
  fetch aggregated fields from the table: "application_sign_in_experiences"
  """
  application_sign_in_experiences_aggregate(
    """distinct select on columns"""
    distinct_on: [application_sign_in_experiences_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [application_sign_in_experiences_order_by!]

    """filter the rows returned"""
    where: application_sign_in_experiences_bool_exp
  ): application_sign_in_experiences_aggregate!

  """
  fetch data from the table: "application_sign_in_experiences" using primary key columns
  """
  application_sign_in_experiences_by_pk(application_id: String!, tenant_id: String!): application_sign_in_experiences

  """
  fetch data from the table: "application_user_consent_organization_scopes"
  """
  application_user_consent_organization_scopes(
    """distinct select on columns"""
    distinct_on: [application_user_consent_organization_scopes_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [application_user_consent_organization_scopes_order_by!]

    """filter the rows returned"""
    where: application_user_consent_organization_scopes_bool_exp
  ): [application_user_consent_organization_scopes!]!

  """
  fetch aggregated fields from the table: "application_user_consent_organization_scopes"
  """
  application_user_consent_organization_scopes_aggregate(
    """distinct select on columns"""
    distinct_on: [application_user_consent_organization_scopes_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [application_user_consent_organization_scopes_order_by!]

    """filter the rows returned"""
    where: application_user_consent_organization_scopes_bool_exp
  ): application_user_consent_organization_scopes_aggregate!

  """
  fetch data from the table: "application_user_consent_organization_scopes" using primary key columns
  """
  application_user_consent_organization_scopes_by_pk(application_id: String!, organization_scope_id: String!): application_user_consent_organization_scopes

  """
  fetch data from the table: "application_user_consent_organizations"
  """
  application_user_consent_organizations(
    """distinct select on columns"""
    distinct_on: [application_user_consent_organizations_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [application_user_consent_organizations_order_by!]

    """filter the rows returned"""
    where: application_user_consent_organizations_bool_exp
  ): [application_user_consent_organizations!]!

  """
  fetch aggregated fields from the table: "application_user_consent_organizations"
  """
  application_user_consent_organizations_aggregate(
    """distinct select on columns"""
    distinct_on: [application_user_consent_organizations_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [application_user_consent_organizations_order_by!]

    """filter the rows returned"""
    where: application_user_consent_organizations_bool_exp
  ): application_user_consent_organizations_aggregate!

  """
  fetch data from the table: "application_user_consent_organizations" using primary key columns
  """
  application_user_consent_organizations_by_pk(application_id: String!, organization_id: String!, tenant_id: String!, user_id: String!): application_user_consent_organizations

  """
  fetch data from the table: "application_user_consent_resource_scopes"
  """
  application_user_consent_resource_scopes(
    """distinct select on columns"""
    distinct_on: [application_user_consent_resource_scopes_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [application_user_consent_resource_scopes_order_by!]

    """filter the rows returned"""
    where: application_user_consent_resource_scopes_bool_exp
  ): [application_user_consent_resource_scopes!]!

  """
  fetch aggregated fields from the table: "application_user_consent_resource_scopes"
  """
  application_user_consent_resource_scopes_aggregate(
    """distinct select on columns"""
    distinct_on: [application_user_consent_resource_scopes_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [application_user_consent_resource_scopes_order_by!]

    """filter the rows returned"""
    where: application_user_consent_resource_scopes_bool_exp
  ): application_user_consent_resource_scopes_aggregate!

  """
  fetch data from the table: "application_user_consent_resource_scopes" using primary key columns
  """
  application_user_consent_resource_scopes_by_pk(application_id: String!, scope_id: String!): application_user_consent_resource_scopes

  """
  fetch data from the table: "application_user_consent_user_scopes"
  """
  application_user_consent_user_scopes(
    """distinct select on columns"""
    distinct_on: [application_user_consent_user_scopes_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [application_user_consent_user_scopes_order_by!]

    """filter the rows returned"""
    where: application_user_consent_user_scopes_bool_exp
  ): [application_user_consent_user_scopes!]!

  """
  fetch aggregated fields from the table: "application_user_consent_user_scopes"
  """
  application_user_consent_user_scopes_aggregate(
    """distinct select on columns"""
    distinct_on: [application_user_consent_user_scopes_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [application_user_consent_user_scopes_order_by!]

    """filter the rows returned"""
    where: application_user_consent_user_scopes_bool_exp
  ): application_user_consent_user_scopes_aggregate!

  """
  fetch data from the table: "application_user_consent_user_scopes" using primary key columns
  """
  application_user_consent_user_scopes_by_pk(application_id: String!, user_scope: String!): application_user_consent_user_scopes

  """
  fetch data from the table: "applications"
  """
  applications(
    """distinct select on columns"""
    distinct_on: [applications_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [applications_order_by!]

    """filter the rows returned"""
    where: applications_bool_exp
  ): [applications!]!

  """
  fetch aggregated fields from the table: "applications"
  """
  applications_aggregate(
    """distinct select on columns"""
    distinct_on: [applications_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [applications_order_by!]

    """filter the rows returned"""
    where: applications_bool_exp
  ): applications_aggregate!

  """fetch data from the table: "applications" using primary key columns"""
  applications_by_pk(id: String!): applications

  """
  fetch data from the table: "applications_roles"
  """
  applications_roles(
    """distinct select on columns"""
    distinct_on: [applications_roles_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [applications_roles_order_by!]

    """filter the rows returned"""
    where: applications_roles_bool_exp
  ): [applications_roles!]!

  """
  fetch aggregated fields from the table: "applications_roles"
  """
  applications_roles_aggregate(
    """distinct select on columns"""
    distinct_on: [applications_roles_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [applications_roles_order_by!]

    """filter the rows returned"""
    where: applications_roles_bool_exp
  ): applications_roles_aggregate!

  """
  fetch data from the table: "applications_roles" using primary key columns
  """
  applications_roles_by_pk(id: String!): applications_roles

  """
  fetch data from the table: "check_in_settings"
  """
  check_in_settings(
    """distinct select on columns"""
    distinct_on: [check_in_settings_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [check_in_settings_order_by!]

    """filter the rows returned"""
    where: check_in_settings_bool_exp
  ): [check_in_settings!]!

  """
  fetch aggregated fields from the table: "check_in_settings"
  """
  check_in_settings_aggregate(
    """distinct select on columns"""
    distinct_on: [check_in_settings_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [check_in_settings_order_by!]

    """filter the rows returned"""
    where: check_in_settings_bool_exp
  ): check_in_settings_aggregate!

  """
  fetch data from the table: "check_in_settings" using primary key columns
  """
  check_in_settings_by_pk(id: uuid!): check_in_settings

  """
  fetch data from the table: "check_ins"
  """
  check_ins(
    """distinct select on columns"""
    distinct_on: [check_ins_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [check_ins_order_by!]

    """filter the rows returned"""
    where: check_ins_bool_exp
  ): [check_ins!]!

  """
  fetch aggregated fields from the table: "check_ins"
  """
  check_ins_aggregate(
    """distinct select on columns"""
    distinct_on: [check_ins_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [check_ins_order_by!]

    """filter the rows returned"""
    where: check_ins_bool_exp
  ): check_ins_aggregate!

  """fetch data from the table: "check_ins" using primary key columns"""
  check_ins_by_pk(id: uuid!): check_ins

  """
  fetch data from the table: "cholesterol_records"
  """
  cholesterol_records(
    """distinct select on columns"""
    distinct_on: [cholesterol_records_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [cholesterol_records_order_by!]

    """filter the rows returned"""
    where: cholesterol_records_bool_exp
  ): [cholesterol_records!]!

  """
  fetch aggregated fields from the table: "cholesterol_records"
  """
  cholesterol_records_aggregate(
    """distinct select on columns"""
    distinct_on: [cholesterol_records_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [cholesterol_records_order_by!]

    """filter the rows returned"""
    where: cholesterol_records_bool_exp
  ): cholesterol_records_aggregate!

  """
  fetch data from the table: "cholesterol_records" using primary key columns
  """
  cholesterol_records_by_pk(id: uuid!): cholesterol_records

  """
  fetch data from the table: "cholesterol_standards"
  """
  cholesterol_standards(
    """distinct select on columns"""
    distinct_on: [cholesterol_standards_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [cholesterol_standards_order_by!]

    """filter the rows returned"""
    where: cholesterol_standards_bool_exp
  ): [cholesterol_standards!]!

  """
  fetch aggregated fields from the table: "cholesterol_standards"
  """
  cholesterol_standards_aggregate(
    """distinct select on columns"""
    distinct_on: [cholesterol_standards_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [cholesterol_standards_order_by!]

    """filter the rows returned"""
    where: cholesterol_standards_bool_exp
  ): cholesterol_standards_aggregate!

  """
  fetch data from the table: "cholesterol_standards" using primary key columns
  """
  cholesterol_standards_by_pk(id: uuid!): cholesterol_standards

  """
  fetch data from the table: "connectors"
  """
  connectors(
    """distinct select on columns"""
    distinct_on: [connectors_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [connectors_order_by!]

    """filter the rows returned"""
    where: connectors_bool_exp
  ): [connectors!]!

  """
  fetch aggregated fields from the table: "connectors"
  """
  connectors_aggregate(
    """distinct select on columns"""
    distinct_on: [connectors_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [connectors_order_by!]

    """filter the rows returned"""
    where: connectors_bool_exp
  ): connectors_aggregate!

  """fetch data from the table: "connectors" using primary key columns"""
  connectors_by_pk(id: String!): connectors

  """
  fetch data from the table: "custom_phrases"
  """
  custom_phrases(
    """distinct select on columns"""
    distinct_on: [custom_phrases_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [custom_phrases_order_by!]

    """filter the rows returned"""
    where: custom_phrases_bool_exp
  ): [custom_phrases!]!

  """
  fetch aggregated fields from the table: "custom_phrases"
  """
  custom_phrases_aggregate(
    """distinct select on columns"""
    distinct_on: [custom_phrases_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [custom_phrases_order_by!]

    """filter the rows returned"""
    where: custom_phrases_bool_exp
  ): custom_phrases_aggregate!

  """fetch data from the table: "custom_phrases" using primary key columns"""
  custom_phrases_by_pk(id: String!): custom_phrases

  """
  fetch data from the table: "daily_active_users"
  """
  daily_active_users(
    """distinct select on columns"""
    distinct_on: [daily_active_users_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [daily_active_users_order_by!]

    """filter the rows returned"""
    where: daily_active_users_bool_exp
  ): [daily_active_users!]!

  """
  fetch aggregated fields from the table: "daily_active_users"
  """
  daily_active_users_aggregate(
    """distinct select on columns"""
    distinct_on: [daily_active_users_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [daily_active_users_order_by!]

    """filter the rows returned"""
    where: daily_active_users_bool_exp
  ): daily_active_users_aggregate!

  """
  fetch data from the table: "daily_active_users" using primary key columns
  """
  daily_active_users_by_pk(id: String!): daily_active_users

  """
  fetch data from the table: "daily_token_usage"
  """
  daily_token_usage(
    """distinct select on columns"""
    distinct_on: [daily_token_usage_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [daily_token_usage_order_by!]

    """filter the rows returned"""
    where: daily_token_usage_bool_exp
  ): [daily_token_usage!]!

  """
  fetch aggregated fields from the table: "daily_token_usage"
  """
  daily_token_usage_aggregate(
    """distinct select on columns"""
    distinct_on: [daily_token_usage_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [daily_token_usage_order_by!]

    """filter the rows returned"""
    where: daily_token_usage_bool_exp
  ): daily_token_usage_aggregate!

  """
  fetch data from the table: "daily_token_usage" using primary key columns
  """
  daily_token_usage_by_pk(id: String!): daily_token_usage

  """
  fetch data from the table: "domains"
  """
  domains(
    """distinct select on columns"""
    distinct_on: [domains_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [domains_order_by!]

    """filter the rows returned"""
    where: domains_bool_exp
  ): [domains!]!

  """
  fetch aggregated fields from the table: "domains"
  """
  domains_aggregate(
    """distinct select on columns"""
    distinct_on: [domains_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [domains_order_by!]

    """filter the rows returned"""
    where: domains_bool_exp
  ): domains_aggregate!

  """fetch data from the table: "domains" using primary key columns"""
  domains_by_pk(id: String!): domains

  """
  fetch data from the table: "glucose_records"
  """
  glucose_records(
    """distinct select on columns"""
    distinct_on: [glucose_records_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [glucose_records_order_by!]

    """filter the rows returned"""
    where: glucose_records_bool_exp
  ): [glucose_records!]!

  """
  fetch aggregated fields from the table: "glucose_records"
  """
  glucose_records_aggregate(
    """distinct select on columns"""
    distinct_on: [glucose_records_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [glucose_records_order_by!]

    """filter the rows returned"""
    where: glucose_records_bool_exp
  ): glucose_records_aggregate!

  """fetch data from the table: "glucose_records" using primary key columns"""
  glucose_records_by_pk(id: uuid!): glucose_records

  """
  fetch data from the table: "glucose_standards"
  """
  glucose_standards(
    """distinct select on columns"""
    distinct_on: [glucose_standards_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [glucose_standards_order_by!]

    """filter the rows returned"""
    where: glucose_standards_bool_exp
  ): [glucose_standards!]!

  """
  fetch aggregated fields from the table: "glucose_standards"
  """
  glucose_standards_aggregate(
    """distinct select on columns"""
    distinct_on: [glucose_standards_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [glucose_standards_order_by!]

    """filter the rows returned"""
    where: glucose_standards_bool_exp
  ): glucose_standards_aggregate!

  """
  fetch data from the table: "glucose_standards" using primary key columns
  """
  glucose_standards_by_pk(id: uuid!): glucose_standards

  """
  fetch data from the table: "hooks"
  """
  hooks(
    """distinct select on columns"""
    distinct_on: [hooks_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [hooks_order_by!]

    """filter the rows returned"""
    where: hooks_bool_exp
  ): [hooks!]!

  """
  fetch aggregated fields from the table: "hooks"
  """
  hooks_aggregate(
    """distinct select on columns"""
    distinct_on: [hooks_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [hooks_order_by!]

    """filter the rows returned"""
    where: hooks_bool_exp
  ): hooks_aggregate!

  """fetch data from the table: "hooks" using primary key columns"""
  hooks_by_pk(id: String!): hooks

  """
  fetch data from the table: "lab_report_records"
  """
  lab_report_records(
    """distinct select on columns"""
    distinct_on: [lab_report_records_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [lab_report_records_order_by!]

    """filter the rows returned"""
    where: lab_report_records_bool_exp
  ): [lab_report_records!]!

  """
  fetch aggregated fields from the table: "lab_report_records"
  """
  lab_report_records_aggregate(
    """distinct select on columns"""
    distinct_on: [lab_report_records_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [lab_report_records_order_by!]

    """filter the rows returned"""
    where: lab_report_records_bool_exp
  ): lab_report_records_aggregate!

  """
  fetch data from the table: "lab_report_records" using primary key columns
  """
  lab_report_records_by_pk(id: uuid!): lab_report_records

  """
  fetch data from the table: "logs"
  """
  logs(
    """distinct select on columns"""
    distinct_on: [logs_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [logs_order_by!]

    """filter the rows returned"""
    where: logs_bool_exp
  ): [logs!]!

  """
  fetch aggregated fields from the table: "logs"
  """
  logs_aggregate(
    """distinct select on columns"""
    distinct_on: [logs_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [logs_order_by!]

    """filter the rows returned"""
    where: logs_bool_exp
  ): logs_aggregate!

  """fetch data from the table: "logs" using primary key columns"""
  logs_by_pk(id: String!): logs

  """
  fetch data from the table: "logto_configs"
  """
  logto_configs(
    """distinct select on columns"""
    distinct_on: [logto_configs_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [logto_configs_order_by!]

    """filter the rows returned"""
    where: logto_configs_bool_exp
  ): [logto_configs!]!

  """
  fetch aggregated fields from the table: "logto_configs"
  """
  logto_configs_aggregate(
    """distinct select on columns"""
    distinct_on: [logto_configs_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [logto_configs_order_by!]

    """filter the rows returned"""
    where: logto_configs_bool_exp
  ): logto_configs_aggregate!

  """fetch data from the table: "logto_configs" using primary key columns"""
  logto_configs_by_pk(key: String!, tenant_id: String!): logto_configs

  """
  fetch data from the table: "medical_examination_records"
  """
  medical_examination_records(
    """distinct select on columns"""
    distinct_on: [medical_examination_records_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [medical_examination_records_order_by!]

    """filter the rows returned"""
    where: medical_examination_records_bool_exp
  ): [medical_examination_records!]!

  """
  fetch aggregated fields from the table: "medical_examination_records"
  """
  medical_examination_records_aggregate(
    """distinct select on columns"""
    distinct_on: [medical_examination_records_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [medical_examination_records_order_by!]

    """filter the rows returned"""
    where: medical_examination_records_bool_exp
  ): medical_examination_records_aggregate!

  """
  fetch data from the table: "medical_examination_records" using primary key columns
  """
  medical_examination_records_by_pk(id: uuid!): medical_examination_records

  """
  fetch data from the table: "medication_reminders"
  """
  medication_reminders(
    """distinct select on columns"""
    distinct_on: [medication_reminders_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [medication_reminders_order_by!]

    """filter the rows returned"""
    where: medication_reminders_bool_exp
  ): [medication_reminders!]!

  """
  fetch aggregated fields from the table: "medication_reminders"
  """
  medication_reminders_aggregate(
    """distinct select on columns"""
    distinct_on: [medication_reminders_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [medication_reminders_order_by!]

    """filter the rows returned"""
    where: medication_reminders_bool_exp
  ): medication_reminders_aggregate!

  """
  fetch data from the table: "medication_reminders" using primary key columns
  """
  medication_reminders_by_pk(id: uuid!): medication_reminders

  """
  fetch data from the table: "oidc_model_instances"
  """
  oidc_model_instances(
    """distinct select on columns"""
    distinct_on: [oidc_model_instances_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [oidc_model_instances_order_by!]

    """filter the rows returned"""
    where: oidc_model_instances_bool_exp
  ): [oidc_model_instances!]!

  """
  fetch aggregated fields from the table: "oidc_model_instances"
  """
  oidc_model_instances_aggregate(
    """distinct select on columns"""
    distinct_on: [oidc_model_instances_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [oidc_model_instances_order_by!]

    """filter the rows returned"""
    where: oidc_model_instances_bool_exp
  ): oidc_model_instances_aggregate!

  """
  fetch data from the table: "oidc_model_instances" using primary key columns
  """
  oidc_model_instances_by_pk(id: String!): oidc_model_instances

  """
  fetch data from the table: "organization_invitation_role_relations"
  """
  organization_invitation_role_relations(
    """distinct select on columns"""
    distinct_on: [organization_invitation_role_relations_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [organization_invitation_role_relations_order_by!]

    """filter the rows returned"""
    where: organization_invitation_role_relations_bool_exp
  ): [organization_invitation_role_relations!]!

  """
  fetch aggregated fields from the table: "organization_invitation_role_relations"
  """
  organization_invitation_role_relations_aggregate(
    """distinct select on columns"""
    distinct_on: [organization_invitation_role_relations_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [organization_invitation_role_relations_order_by!]

    """filter the rows returned"""
    where: organization_invitation_role_relations_bool_exp
  ): organization_invitation_role_relations_aggregate!

  """
  fetch data from the table: "organization_invitation_role_relations" using primary key columns
  """
  organization_invitation_role_relations_by_pk(organization_invitation_id: String!, organization_role_id: String!, tenant_id: String!): organization_invitation_role_relations

  """
  fetch data from the table: "organization_invitations"
  """
  organization_invitations(
    """distinct select on columns"""
    distinct_on: [organization_invitations_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [organization_invitations_order_by!]

    """filter the rows returned"""
    where: organization_invitations_bool_exp
  ): [organization_invitations!]!

  """
  fetch aggregated fields from the table: "organization_invitations"
  """
  organization_invitations_aggregate(
    """distinct select on columns"""
    distinct_on: [organization_invitations_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [organization_invitations_order_by!]

    """filter the rows returned"""
    where: organization_invitations_bool_exp
  ): organization_invitations_aggregate!

  """
  fetch data from the table: "organization_invitations" using primary key columns
  """
  organization_invitations_by_pk(id: String!): organization_invitations

  """
  fetch data from the table: "organization_role_scope_relations"
  """
  organization_role_scope_relations(
    """distinct select on columns"""
    distinct_on: [organization_role_scope_relations_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [organization_role_scope_relations_order_by!]

    """filter the rows returned"""
    where: organization_role_scope_relations_bool_exp
  ): [organization_role_scope_relations!]!

  """
  fetch aggregated fields from the table: "organization_role_scope_relations"
  """
  organization_role_scope_relations_aggregate(
    """distinct select on columns"""
    distinct_on: [organization_role_scope_relations_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [organization_role_scope_relations_order_by!]

    """filter the rows returned"""
    where: organization_role_scope_relations_bool_exp
  ): organization_role_scope_relations_aggregate!

  """
  fetch data from the table: "organization_role_scope_relations" using primary key columns
  """
  organization_role_scope_relations_by_pk(organization_role_id: String!, organization_scope_id: String!, tenant_id: String!): organization_role_scope_relations

  """
  fetch data from the table: "organization_role_user_relations"
  """
  organization_role_user_relations(
    """distinct select on columns"""
    distinct_on: [organization_role_user_relations_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [organization_role_user_relations_order_by!]

    """filter the rows returned"""
    where: organization_role_user_relations_bool_exp
  ): [organization_role_user_relations!]!

  """
  fetch aggregated fields from the table: "organization_role_user_relations"
  """
  organization_role_user_relations_aggregate(
    """distinct select on columns"""
    distinct_on: [organization_role_user_relations_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [organization_role_user_relations_order_by!]

    """filter the rows returned"""
    where: organization_role_user_relations_bool_exp
  ): organization_role_user_relations_aggregate!

  """
  fetch data from the table: "organization_role_user_relations" using primary key columns
  """
  organization_role_user_relations_by_pk(organization_id: String!, organization_role_id: String!, tenant_id: String!, user_id: String!): organization_role_user_relations

  """
  fetch data from the table: "organization_roles"
  """
  organization_roles(
    """distinct select on columns"""
    distinct_on: [organization_roles_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [organization_roles_order_by!]

    """filter the rows returned"""
    where: organization_roles_bool_exp
  ): [organization_roles!]!

  """
  fetch aggregated fields from the table: "organization_roles"
  """
  organization_roles_aggregate(
    """distinct select on columns"""
    distinct_on: [organization_roles_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [organization_roles_order_by!]

    """filter the rows returned"""
    where: organization_roles_bool_exp
  ): organization_roles_aggregate!

  """
  fetch data from the table: "organization_roles" using primary key columns
  """
  organization_roles_by_pk(id: String!): organization_roles

  """
  fetch data from the table: "organization_scopes"
  """
  organization_scopes(
    """distinct select on columns"""
    distinct_on: [organization_scopes_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [organization_scopes_order_by!]

    """filter the rows returned"""
    where: organization_scopes_bool_exp
  ): [organization_scopes!]!

  """
  fetch aggregated fields from the table: "organization_scopes"
  """
  organization_scopes_aggregate(
    """distinct select on columns"""
    distinct_on: [organization_scopes_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [organization_scopes_order_by!]

    """filter the rows returned"""
    where: organization_scopes_bool_exp
  ): organization_scopes_aggregate!

  """
  fetch data from the table: "organization_scopes" using primary key columns
  """
  organization_scopes_by_pk(id: String!): organization_scopes

  """
  fetch data from the table: "organization_user_relations"
  """
  organization_user_relations(
    """distinct select on columns"""
    distinct_on: [organization_user_relations_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [organization_user_relations_order_by!]

    """filter the rows returned"""
    where: organization_user_relations_bool_exp
  ): [organization_user_relations!]!

  """
  fetch aggregated fields from the table: "organization_user_relations"
  """
  organization_user_relations_aggregate(
    """distinct select on columns"""
    distinct_on: [organization_user_relations_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [organization_user_relations_order_by!]

    """filter the rows returned"""
    where: organization_user_relations_bool_exp
  ): organization_user_relations_aggregate!

  """
  fetch data from the table: "organization_user_relations" using primary key columns
  """
  organization_user_relations_by_pk(organization_id: String!, tenant_id: String!, user_id: String!): organization_user_relations

  """
  fetch data from the table: "organizations"
  """
  organizations(
    """distinct select on columns"""
    distinct_on: [organizations_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [organizations_order_by!]

    """filter the rows returned"""
    where: organizations_bool_exp
  ): [organizations!]!

  """
  fetch aggregated fields from the table: "organizations"
  """
  organizations_aggregate(
    """distinct select on columns"""
    distinct_on: [organizations_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [organizations_order_by!]

    """filter the rows returned"""
    where: organizations_bool_exp
  ): organizations_aggregate!

  """fetch data from the table: "organizations" using primary key columns"""
  organizations_by_pk(id: String!): organizations

  """
  fetch data from the table: "passcodes"
  """
  passcodes(
    """distinct select on columns"""
    distinct_on: [passcodes_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [passcodes_order_by!]

    """filter the rows returned"""
    where: passcodes_bool_exp
  ): [passcodes!]!

  """
  fetch aggregated fields from the table: "passcodes"
  """
  passcodes_aggregate(
    """distinct select on columns"""
    distinct_on: [passcodes_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [passcodes_order_by!]

    """filter the rows returned"""
    where: passcodes_bool_exp
  ): passcodes_aggregate!

  """fetch data from the table: "passcodes" using primary key columns"""
  passcodes_by_pk(id: String!): passcodes

  """
  fetch data from the table: "pg_buffercache"
  """
  pg_buffercache(
    """distinct select on columns"""
    distinct_on: [pg_buffercache_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [pg_buffercache_order_by!]

    """filter the rows returned"""
    where: pg_buffercache_bool_exp
  ): [pg_buffercache!]!

  """
  fetch aggregated fields from the table: "pg_buffercache"
  """
  pg_buffercache_aggregate(
    """distinct select on columns"""
    distinct_on: [pg_buffercache_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [pg_buffercache_order_by!]

    """filter the rows returned"""
    where: pg_buffercache_bool_exp
  ): pg_buffercache_aggregate!

  """
  fetch data from the table: "pg_stat_statements"
  """
  pg_stat_statements(
    """distinct select on columns"""
    distinct_on: [pg_stat_statements_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [pg_stat_statements_order_by!]

    """filter the rows returned"""
    where: pg_stat_statements_bool_exp
  ): [pg_stat_statements!]!

  """
  fetch aggregated fields from the table: "pg_stat_statements"
  """
  pg_stat_statements_aggregate(
    """distinct select on columns"""
    distinct_on: [pg_stat_statements_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [pg_stat_statements_order_by!]

    """filter the rows returned"""
    where: pg_stat_statements_bool_exp
  ): pg_stat_statements_aggregate!

  """
  fetch data from the table: "pg_stat_statements_info"
  """
  pg_stat_statements_info(
    """distinct select on columns"""
    distinct_on: [pg_stat_statements_info_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [pg_stat_statements_info_order_by!]

    """filter the rows returned"""
    where: pg_stat_statements_info_bool_exp
  ): [pg_stat_statements_info!]!

  """
  fetch aggregated fields from the table: "pg_stat_statements_info"
  """
  pg_stat_statements_info_aggregate(
    """distinct select on columns"""
    distinct_on: [pg_stat_statements_info_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [pg_stat_statements_info_order_by!]

    """filter the rows returned"""
    where: pg_stat_statements_info_bool_exp
  ): pg_stat_statements_info_aggregate!

  """
  fetch data from the table: "resources"
  """
  resources(
    """distinct select on columns"""
    distinct_on: [resources_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [resources_order_by!]

    """filter the rows returned"""
    where: resources_bool_exp
  ): [resources!]!

  """
  fetch aggregated fields from the table: "resources"
  """
  resources_aggregate(
    """distinct select on columns"""
    distinct_on: [resources_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [resources_order_by!]

    """filter the rows returned"""
    where: resources_bool_exp
  ): resources_aggregate!

  """fetch data from the table: "resources" using primary key columns"""
  resources_by_pk(id: String!): resources

  """
  fetch data from the table: "roles"
  """
  roles(
    """distinct select on columns"""
    distinct_on: [roles_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [roles_order_by!]

    """filter the rows returned"""
    where: roles_bool_exp
  ): [roles!]!

  """
  fetch aggregated fields from the table: "roles"
  """
  roles_aggregate(
    """distinct select on columns"""
    distinct_on: [roles_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [roles_order_by!]

    """filter the rows returned"""
    where: roles_bool_exp
  ): roles_aggregate!

  """fetch data from the table: "roles" using primary key columns"""
  roles_by_pk(id: String!): roles

  """
  fetch data from the table: "roles_scopes"
  """
  roles_scopes(
    """distinct select on columns"""
    distinct_on: [roles_scopes_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [roles_scopes_order_by!]

    """filter the rows returned"""
    where: roles_scopes_bool_exp
  ): [roles_scopes!]!

  """
  fetch aggregated fields from the table: "roles_scopes"
  """
  roles_scopes_aggregate(
    """distinct select on columns"""
    distinct_on: [roles_scopes_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [roles_scopes_order_by!]

    """filter the rows returned"""
    where: roles_scopes_bool_exp
  ): roles_scopes_aggregate!

  """fetch data from the table: "roles_scopes" using primary key columns"""
  roles_scopes_by_pk(id: String!): roles_scopes

  """
  fetch data from the table: "scopes"
  """
  scopes(
    """distinct select on columns"""
    distinct_on: [scopes_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [scopes_order_by!]

    """filter the rows returned"""
    where: scopes_bool_exp
  ): [scopes!]!

  """
  fetch aggregated fields from the table: "scopes"
  """
  scopes_aggregate(
    """distinct select on columns"""
    distinct_on: [scopes_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [scopes_order_by!]

    """filter the rows returned"""
    where: scopes_bool_exp
  ): scopes_aggregate!

  """fetch data from the table: "scopes" using primary key columns"""
  scopes_by_pk(id: String!): scopes

  """
  fetch data from the table: "sentinel_activities"
  """
  sentinel_activities(
    """distinct select on columns"""
    distinct_on: [sentinel_activities_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [sentinel_activities_order_by!]

    """filter the rows returned"""
    where: sentinel_activities_bool_exp
  ): [sentinel_activities!]!

  """
  fetch aggregated fields from the table: "sentinel_activities"
  """
  sentinel_activities_aggregate(
    """distinct select on columns"""
    distinct_on: [sentinel_activities_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [sentinel_activities_order_by!]

    """filter the rows returned"""
    where: sentinel_activities_bool_exp
  ): sentinel_activities_aggregate!

  """
  fetch data from the table: "sentinel_activities" using primary key columns
  """
  sentinel_activities_by_pk(id: String!): sentinel_activities

  """
  fetch data from the table: "service_logs"
  """
  service_logs(
    """distinct select on columns"""
    distinct_on: [service_logs_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [service_logs_order_by!]

    """filter the rows returned"""
    where: service_logs_bool_exp
  ): [service_logs!]!

  """
  fetch aggregated fields from the table: "service_logs"
  """
  service_logs_aggregate(
    """distinct select on columns"""
    distinct_on: [service_logs_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [service_logs_order_by!]

    """filter the rows returned"""
    where: service_logs_bool_exp
  ): service_logs_aggregate!

  """fetch data from the table: "service_logs" using primary key columns"""
  service_logs_by_pk(id: String!): service_logs

  """
  fetch data from the table: "sign_in_experiences"
  """
  sign_in_experiences(
    """distinct select on columns"""
    distinct_on: [sign_in_experiences_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [sign_in_experiences_order_by!]

    """filter the rows returned"""
    where: sign_in_experiences_bool_exp
  ): [sign_in_experiences!]!

  """
  fetch aggregated fields from the table: "sign_in_experiences"
  """
  sign_in_experiences_aggregate(
    """distinct select on columns"""
    distinct_on: [sign_in_experiences_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [sign_in_experiences_order_by!]

    """filter the rows returned"""
    where: sign_in_experiences_bool_exp
  ): sign_in_experiences_aggregate!

  """
  fetch data from the table: "sign_in_experiences" using primary key columns
  """
  sign_in_experiences_by_pk(id: String!, tenant_id: String!): sign_in_experiences

  """
  fetch data from the table: "sms_codes"
  """
  sms_codes(
    """distinct select on columns"""
    distinct_on: [sms_codes_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [sms_codes_order_by!]

    """filter the rows returned"""
    where: sms_codes_bool_exp
  ): [sms_codes!]!

  """
  fetch aggregated fields from the table: "sms_codes"
  """
  sms_codes_aggregate(
    """distinct select on columns"""
    distinct_on: [sms_codes_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [sms_codes_order_by!]

    """filter the rows returned"""
    where: sms_codes_bool_exp
  ): sms_codes_aggregate!

  """fetch data from the table: "sms_codes" using primary key columns"""
  sms_codes_by_pk(id: uuid!): sms_codes

  """
  fetch data from the table: "sso_connectors"
  """
  sso_connectors(
    """distinct select on columns"""
    distinct_on: [sso_connectors_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [sso_connectors_order_by!]

    """filter the rows returned"""
    where: sso_connectors_bool_exp
  ): [sso_connectors!]!

  """
  fetch aggregated fields from the table: "sso_connectors"
  """
  sso_connectors_aggregate(
    """distinct select on columns"""
    distinct_on: [sso_connectors_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [sso_connectors_order_by!]

    """filter the rows returned"""
    where: sso_connectors_bool_exp
  ): sso_connectors_aggregate!

  """fetch data from the table: "sso_connectors" using primary key columns"""
  sso_connectors_by_pk(id: String!): sso_connectors

  """
  fetch data from the table: "systems"
  """
  systems(
    """distinct select on columns"""
    distinct_on: [systems_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [systems_order_by!]

    """filter the rows returned"""
    where: systems_bool_exp
  ): [systems!]!

  """
  fetch aggregated fields from the table: "systems"
  """
  systems_aggregate(
    """distinct select on columns"""
    distinct_on: [systems_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [systems_order_by!]

    """filter the rows returned"""
    where: systems_bool_exp
  ): systems_aggregate!

  """fetch data from the table: "systems" using primary key columns"""
  systems_by_pk(key: String!): systems

  """
  fetch data from the table: "tenants"
  """
  tenants(
    """distinct select on columns"""
    distinct_on: [tenants_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [tenants_order_by!]

    """filter the rows returned"""
    where: tenants_bool_exp
  ): [tenants!]!

  """
  fetch aggregated fields from the table: "tenants"
  """
  tenants_aggregate(
    """distinct select on columns"""
    distinct_on: [tenants_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [tenants_order_by!]

    """filter the rows returned"""
    where: tenants_bool_exp
  ): tenants_aggregate!

  """fetch data from the table: "tenants" using primary key columns"""
  tenants_by_pk(id: String!): tenants

  """
  fetch data from the table: "user_cholesterol_standards"
  """
  user_cholesterol_standards(
    """distinct select on columns"""
    distinct_on: [user_cholesterol_standards_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [user_cholesterol_standards_order_by!]

    """filter the rows returned"""
    where: user_cholesterol_standards_bool_exp
  ): [user_cholesterol_standards!]!

  """
  fetch aggregated fields from the table: "user_cholesterol_standards"
  """
  user_cholesterol_standards_aggregate(
    """distinct select on columns"""
    distinct_on: [user_cholesterol_standards_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [user_cholesterol_standards_order_by!]

    """filter the rows returned"""
    where: user_cholesterol_standards_bool_exp
  ): user_cholesterol_standards_aggregate!

  """
  fetch data from the table: "user_cholesterol_standards" using primary key columns
  """
  user_cholesterol_standards_by_pk(id: uuid!): user_cholesterol_standards

  """
  fetch data from the table: "user_glucose_standards"
  """
  user_glucose_standards(
    """distinct select on columns"""
    distinct_on: [user_glucose_standards_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [user_glucose_standards_order_by!]

    """filter the rows returned"""
    where: user_glucose_standards_bool_exp
  ): [user_glucose_standards!]!

  """
  fetch aggregated fields from the table: "user_glucose_standards"
  """
  user_glucose_standards_aggregate(
    """distinct select on columns"""
    distinct_on: [user_glucose_standards_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [user_glucose_standards_order_by!]

    """filter the rows returned"""
    where: user_glucose_standards_bool_exp
  ): user_glucose_standards_aggregate!

  """
  fetch data from the table: "user_glucose_standards" using primary key columns
  """
  user_glucose_standards_by_pk(id: uuid!): user_glucose_standards

  """
  fetch data from the table: "user_sso_identities"
  """
  user_sso_identities(
    """distinct select on columns"""
    distinct_on: [user_sso_identities_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [user_sso_identities_order_by!]

    """filter the rows returned"""
    where: user_sso_identities_bool_exp
  ): [user_sso_identities!]!

  """
  fetch aggregated fields from the table: "user_sso_identities"
  """
  user_sso_identities_aggregate(
    """distinct select on columns"""
    distinct_on: [user_sso_identities_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [user_sso_identities_order_by!]

    """filter the rows returned"""
    where: user_sso_identities_bool_exp
  ): user_sso_identities_aggregate!

  """
  fetch data from the table: "user_sso_identities" using primary key columns
  """
  user_sso_identities_by_pk(id: String!): user_sso_identities

  """
  fetch data from the table: "users"
  """
  users(
    """distinct select on columns"""
    distinct_on: [users_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [users_order_by!]

    """filter the rows returned"""
    where: users_bool_exp
  ): [users!]!

  """
  fetch aggregated fields from the table: "users"
  """
  users_aggregate(
    """distinct select on columns"""
    distinct_on: [users_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [users_order_by!]

    """filter the rows returned"""
    where: users_bool_exp
  ): users_aggregate!

  """fetch data from the table: "users" using primary key columns"""
  users_by_pk(id: String!): users

  """An array relationship"""
  users_roles(
    """distinct select on columns"""
    distinct_on: [users_roles_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [users_roles_order_by!]

    """filter the rows returned"""
    where: users_roles_bool_exp
  ): [users_roles!]!

  """An aggregate relationship"""
  users_roles_aggregate(
    """distinct select on columns"""
    distinct_on: [users_roles_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [users_roles_order_by!]

    """filter the rows returned"""
    where: users_roles_bool_exp
  ): users_roles_aggregate!

  """fetch data from the table: "users_roles" using primary key columns"""
  users_roles_by_pk(id: String!): users_roles

  """
  fetch data from the table: "verification_statuses"
  """
  verification_statuses(
    """distinct select on columns"""
    distinct_on: [verification_statuses_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [verification_statuses_order_by!]

    """filter the rows returned"""
    where: verification_statuses_bool_exp
  ): [verification_statuses!]!

  """
  fetch aggregated fields from the table: "verification_statuses"
  """
  verification_statuses_aggregate(
    """distinct select on columns"""
    distinct_on: [verification_statuses_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [verification_statuses_order_by!]

    """filter the rows returned"""
    where: verification_statuses_bool_exp
  ): verification_statuses_aggregate!

  """
  fetch data from the table: "verification_statuses" using primary key columns
  """
  verification_statuses_by_pk(id: String!): verification_statuses
}

"""
columns and relationships of "resources"
"""
type resources {
  access_token_ttl: bigint!
  id: String!
  indicator: String!
  is_default: Boolean!
  name: String!
  tenant_id: String!
}

"""
aggregated selection of "resources"
"""
type resources_aggregate {
  aggregate: resources_aggregate_fields
  nodes: [resources!]!
}

"""
aggregate fields of "resources"
"""
type resources_aggregate_fields {
  avg: resources_avg_fields
  count(columns: [resources_select_column!], distinct: Boolean): Int!
  max: resources_max_fields
  min: resources_min_fields
  stddev: resources_stddev_fields
  stddev_pop: resources_stddev_pop_fields
  stddev_samp: resources_stddev_samp_fields
  sum: resources_sum_fields
  var_pop: resources_var_pop_fields
  var_samp: resources_var_samp_fields
  variance: resources_variance_fields
}

"""aggregate avg on columns"""
type resources_avg_fields {
  access_token_ttl: Float
}

"""
Boolean expression to filter rows from the table "resources". All fields are combined with a logical 'AND'.
"""
input resources_bool_exp {
  _and: [resources_bool_exp!]
  _not: resources_bool_exp
  _or: [resources_bool_exp!]
  access_token_ttl: bigint_comparison_exp
  id: String_comparison_exp
  indicator: String_comparison_exp
  is_default: Boolean_comparison_exp
  name: String_comparison_exp
  tenant_id: String_comparison_exp
}

"""
unique or primary key constraints on table "resources"
"""
enum resources_constraint {
  """
  unique or primary key constraint on columns "indicator", "tenant_id"
  """
  resources__indicator

  """
  unique or primary key constraint on columns "tenant_id"
  """
  resources__is_default_true

  """
  unique or primary key constraint on columns "id"
  """
  resources_pkey
}

"""
input type for incrementing numeric columns in table "resources"
"""
input resources_inc_input {
  access_token_ttl: bigint
}

"""
input type for inserting data into table "resources"
"""
input resources_insert_input {
  access_token_ttl: bigint
  id: String
  indicator: String
  is_default: Boolean
  name: String
  tenant_id: String
}

"""aggregate max on columns"""
type resources_max_fields {
  access_token_ttl: bigint
  id: String
  indicator: String
  name: String
  tenant_id: String
}

"""aggregate min on columns"""
type resources_min_fields {
  access_token_ttl: bigint
  id: String
  indicator: String
  name: String
  tenant_id: String
}

"""
response of any mutation on the table "resources"
"""
type resources_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [resources!]!
}

"""
on_conflict condition type for table "resources"
"""
input resources_on_conflict {
  constraint: resources_constraint!
  update_columns: [resources_update_column!]! = []
  where: resources_bool_exp
}

"""Ordering options when selecting data from "resources"."""
input resources_order_by {
  access_token_ttl: order_by
  id: order_by
  indicator: order_by
  is_default: order_by
  name: order_by
  tenant_id: order_by
}

"""primary key columns input for table: resources"""
input resources_pk_columns_input {
  id: String!
}

"""
select columns of table "resources"
"""
enum resources_select_column {
  """column name"""
  access_token_ttl

  """column name"""
  id

  """column name"""
  indicator

  """column name"""
  is_default

  """column name"""
  name

  """column name"""
  tenant_id
}

"""
input type for updating data in table "resources"
"""
input resources_set_input {
  access_token_ttl: bigint
  id: String
  indicator: String
  is_default: Boolean
  name: String
  tenant_id: String
}

"""aggregate stddev on columns"""
type resources_stddev_fields {
  access_token_ttl: Float
}

"""aggregate stddev_pop on columns"""
type resources_stddev_pop_fields {
  access_token_ttl: Float
}

"""aggregate stddev_samp on columns"""
type resources_stddev_samp_fields {
  access_token_ttl: Float
}

"""
Streaming cursor of the table "resources"
"""
input resources_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: resources_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input resources_stream_cursor_value_input {
  access_token_ttl: bigint
  id: String
  indicator: String
  is_default: Boolean
  name: String
  tenant_id: String
}

"""aggregate sum on columns"""
type resources_sum_fields {
  access_token_ttl: bigint
}

"""
update columns of table "resources"
"""
enum resources_update_column {
  """column name"""
  access_token_ttl

  """column name"""
  id

  """column name"""
  indicator

  """column name"""
  is_default

  """column name"""
  name

  """column name"""
  tenant_id
}

input resources_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: resources_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: resources_set_input

  """filter the rows which have to be updated"""
  where: resources_bool_exp!
}

"""aggregate var_pop on columns"""
type resources_var_pop_fields {
  access_token_ttl: Float
}

"""aggregate var_samp on columns"""
type resources_var_samp_fields {
  access_token_ttl: Float
}

"""aggregate variance on columns"""
type resources_variance_fields {
  access_token_ttl: Float
}

scalar role_type

"""
Boolean expression to compare columns of type "role_type". All fields are combined with logical 'AND'.
"""
input role_type_comparison_exp {
  _eq: role_type
  _gt: role_type
  _gte: role_type
  _in: [role_type!]
  _is_null: Boolean
  _lt: role_type
  _lte: role_type
  _neq: role_type
  _nin: [role_type!]
}

"""
columns and relationships of "roles"
"""
type roles {
  description: String!
  id: String!
  name: String!
  tenant_id: String!
  type: role_type!
}

"""
aggregated selection of "roles"
"""
type roles_aggregate {
  aggregate: roles_aggregate_fields
  nodes: [roles!]!
}

"""
aggregate fields of "roles"
"""
type roles_aggregate_fields {
  count(columns: [roles_select_column!], distinct: Boolean): Int!
  max: roles_max_fields
  min: roles_min_fields
}

"""
Boolean expression to filter rows from the table "roles". All fields are combined with a logical 'AND'.
"""
input roles_bool_exp {
  _and: [roles_bool_exp!]
  _not: roles_bool_exp
  _or: [roles_bool_exp!]
  description: String_comparison_exp
  id: String_comparison_exp
  name: String_comparison_exp
  tenant_id: String_comparison_exp
  type: role_type_comparison_exp
}

"""
unique or primary key constraints on table "roles"
"""
enum roles_constraint {
  """
  unique or primary key constraint on columns "tenant_id", "name"
  """
  roles__name

  """
  unique or primary key constraint on columns "id"
  """
  roles_pkey
}

"""
input type for inserting data into table "roles"
"""
input roles_insert_input {
  description: String
  id: String
  name: String
  tenant_id: String
  type: role_type
}

"""aggregate max on columns"""
type roles_max_fields {
  description: String
  id: String
  name: String
  tenant_id: String
  type: role_type
}

"""aggregate min on columns"""
type roles_min_fields {
  description: String
  id: String
  name: String
  tenant_id: String
  type: role_type
}

"""
response of any mutation on the table "roles"
"""
type roles_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [roles!]!
}

"""
input type for inserting object relation for remote table "roles"
"""
input roles_obj_rel_insert_input {
  data: roles_insert_input!

  """upsert condition"""
  on_conflict: roles_on_conflict
}

"""
on_conflict condition type for table "roles"
"""
input roles_on_conflict {
  constraint: roles_constraint!
  update_columns: [roles_update_column!]! = []
  where: roles_bool_exp
}

"""Ordering options when selecting data from "roles"."""
input roles_order_by {
  description: order_by
  id: order_by
  name: order_by
  tenant_id: order_by
  type: order_by
}

"""primary key columns input for table: roles"""
input roles_pk_columns_input {
  id: String!
}

"""
columns and relationships of "roles_scopes"
"""
type roles_scopes {
  id: String!
  role_id: String!
  scope_id: String!
  tenant_id: String!
}

"""
aggregated selection of "roles_scopes"
"""
type roles_scopes_aggregate {
  aggregate: roles_scopes_aggregate_fields
  nodes: [roles_scopes!]!
}

"""
aggregate fields of "roles_scopes"
"""
type roles_scopes_aggregate_fields {
  count(columns: [roles_scopes_select_column!], distinct: Boolean): Int!
  max: roles_scopes_max_fields
  min: roles_scopes_min_fields
}

"""
Boolean expression to filter rows from the table "roles_scopes". All fields are combined with a logical 'AND'.
"""
input roles_scopes_bool_exp {
  _and: [roles_scopes_bool_exp!]
  _not: roles_scopes_bool_exp
  _or: [roles_scopes_bool_exp!]
  id: String_comparison_exp
  role_id: String_comparison_exp
  scope_id: String_comparison_exp
  tenant_id: String_comparison_exp
}

"""
unique or primary key constraints on table "roles_scopes"
"""
enum roles_scopes_constraint {
  """
  unique or primary key constraint on columns "role_id", "tenant_id", "scope_id"
  """
  roles_scopes__role_id_scope_id

  """
  unique or primary key constraint on columns "id"
  """
  roles_scopes_pkey
}

"""
input type for inserting data into table "roles_scopes"
"""
input roles_scopes_insert_input {
  id: String
  role_id: String
  scope_id: String
  tenant_id: String
}

"""aggregate max on columns"""
type roles_scopes_max_fields {
  id: String
  role_id: String
  scope_id: String
  tenant_id: String
}

"""aggregate min on columns"""
type roles_scopes_min_fields {
  id: String
  role_id: String
  scope_id: String
  tenant_id: String
}

"""
response of any mutation on the table "roles_scopes"
"""
type roles_scopes_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [roles_scopes!]!
}

"""
on_conflict condition type for table "roles_scopes"
"""
input roles_scopes_on_conflict {
  constraint: roles_scopes_constraint!
  update_columns: [roles_scopes_update_column!]! = []
  where: roles_scopes_bool_exp
}

"""Ordering options when selecting data from "roles_scopes"."""
input roles_scopes_order_by {
  id: order_by
  role_id: order_by
  scope_id: order_by
  tenant_id: order_by
}

"""primary key columns input for table: roles_scopes"""
input roles_scopes_pk_columns_input {
  id: String!
}

"""
select columns of table "roles_scopes"
"""
enum roles_scopes_select_column {
  """column name"""
  id

  """column name"""
  role_id

  """column name"""
  scope_id

  """column name"""
  tenant_id
}

"""
input type for updating data in table "roles_scopes"
"""
input roles_scopes_set_input {
  id: String
  role_id: String
  scope_id: String
  tenant_id: String
}

"""
Streaming cursor of the table "roles_scopes"
"""
input roles_scopes_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: roles_scopes_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input roles_scopes_stream_cursor_value_input {
  id: String
  role_id: String
  scope_id: String
  tenant_id: String
}

"""
update columns of table "roles_scopes"
"""
enum roles_scopes_update_column {
  """column name"""
  id

  """column name"""
  role_id

  """column name"""
  scope_id

  """column name"""
  tenant_id
}

input roles_scopes_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: roles_scopes_set_input

  """filter the rows which have to be updated"""
  where: roles_scopes_bool_exp!
}

"""
select columns of table "roles"
"""
enum roles_select_column {
  """column name"""
  description

  """column name"""
  id

  """column name"""
  name

  """column name"""
  tenant_id

  """column name"""
  type
}

"""
input type for updating data in table "roles"
"""
input roles_set_input {
  description: String
  id: String
  name: String
  tenant_id: String
  type: role_type
}

"""
Streaming cursor of the table "roles"
"""
input roles_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: roles_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input roles_stream_cursor_value_input {
  description: String
  id: String
  name: String
  tenant_id: String
  type: role_type
}

"""
update columns of table "roles"
"""
enum roles_update_column {
  """column name"""
  description

  """column name"""
  id

  """column name"""
  name

  """column name"""
  tenant_id

  """column name"""
  type
}

input roles_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: roles_set_input

  """filter the rows which have to be updated"""
  where: roles_bool_exp!
}

"""
columns and relationships of "scopes"
"""
type scopes {
  created_at: timestamptz!
  description: String!
  id: String!
  name: String!
  resource_id: String!
  tenant_id: String!
}

"""
aggregated selection of "scopes"
"""
type scopes_aggregate {
  aggregate: scopes_aggregate_fields
  nodes: [scopes!]!
}

"""
aggregate fields of "scopes"
"""
type scopes_aggregate_fields {
  count(columns: [scopes_select_column!], distinct: Boolean): Int!
  max: scopes_max_fields
  min: scopes_min_fields
}

"""
Boolean expression to filter rows from the table "scopes". All fields are combined with a logical 'AND'.
"""
input scopes_bool_exp {
  _and: [scopes_bool_exp!]
  _not: scopes_bool_exp
  _or: [scopes_bool_exp!]
  created_at: timestamptz_comparison_exp
  description: String_comparison_exp
  id: String_comparison_exp
  name: String_comparison_exp
  resource_id: String_comparison_exp
  tenant_id: String_comparison_exp
}

"""
unique or primary key constraints on table "scopes"
"""
enum scopes_constraint {
  """
  unique or primary key constraint on columns "resource_id", "tenant_id", "name"
  """
  scopes__resource_id_name

  """
  unique or primary key constraint on columns "id"
  """
  scopes_pkey
}

"""
input type for inserting data into table "scopes"
"""
input scopes_insert_input {
  created_at: timestamptz
  description: String
  id: String
  name: String
  resource_id: String
  tenant_id: String
}

"""aggregate max on columns"""
type scopes_max_fields {
  created_at: timestamptz
  description: String
  id: String
  name: String
  resource_id: String
  tenant_id: String
}

"""aggregate min on columns"""
type scopes_min_fields {
  created_at: timestamptz
  description: String
  id: String
  name: String
  resource_id: String
  tenant_id: String
}

"""
response of any mutation on the table "scopes"
"""
type scopes_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [scopes!]!
}

"""
on_conflict condition type for table "scopes"
"""
input scopes_on_conflict {
  constraint: scopes_constraint!
  update_columns: [scopes_update_column!]! = []
  where: scopes_bool_exp
}

"""Ordering options when selecting data from "scopes"."""
input scopes_order_by {
  created_at: order_by
  description: order_by
  id: order_by
  name: order_by
  resource_id: order_by
  tenant_id: order_by
}

"""primary key columns input for table: scopes"""
input scopes_pk_columns_input {
  id: String!
}

"""
select columns of table "scopes"
"""
enum scopes_select_column {
  """column name"""
  created_at

  """column name"""
  description

  """column name"""
  id

  """column name"""
  name

  """column name"""
  resource_id

  """column name"""
  tenant_id
}

"""
input type for updating data in table "scopes"
"""
input scopes_set_input {
  created_at: timestamptz
  description: String
  id: String
  name: String
  resource_id: String
  tenant_id: String
}

"""
Streaming cursor of the table "scopes"
"""
input scopes_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: scopes_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input scopes_stream_cursor_value_input {
  created_at: timestamptz
  description: String
  id: String
  name: String
  resource_id: String
  tenant_id: String
}

"""
update columns of table "scopes"
"""
enum scopes_update_column {
  """column name"""
  created_at

  """column name"""
  description

  """column name"""
  id

  """column name"""
  name

  """column name"""
  resource_id

  """column name"""
  tenant_id
}

input scopes_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: scopes_set_input

  """filter the rows which have to be updated"""
  where: scopes_bool_exp!
}

scalar sentinel_action_result

"""
Boolean expression to compare columns of type "sentinel_action_result". All fields are combined with logical 'AND'.
"""
input sentinel_action_result_comparison_exp {
  _eq: sentinel_action_result
  _gt: sentinel_action_result
  _gte: sentinel_action_result
  _in: [sentinel_action_result!]
  _is_null: Boolean
  _lt: sentinel_action_result
  _lte: sentinel_action_result
  _neq: sentinel_action_result
  _nin: [sentinel_action_result!]
}

"""
columns and relationships of "sentinel_activities"
"""
type sentinel_activities {
  action: String!
  action_result: sentinel_action_result!
  created_at: timestamptz!
  decision: sentinel_decision!
  decision_expires_at: timestamptz!
  id: String!
  payload(
    """JSON select path"""
    path: String
  ): jsonb!
  target_hash: String!
  target_type: String!
  tenant_id: String!
}

"""
aggregated selection of "sentinel_activities"
"""
type sentinel_activities_aggregate {
  aggregate: sentinel_activities_aggregate_fields
  nodes: [sentinel_activities!]!
}

"""
aggregate fields of "sentinel_activities"
"""
type sentinel_activities_aggregate_fields {
  count(columns: [sentinel_activities_select_column!], distinct: Boolean): Int!
  max: sentinel_activities_max_fields
  min: sentinel_activities_min_fields
}

"""append existing jsonb value of filtered columns with new jsonb value"""
input sentinel_activities_append_input {
  payload: jsonb
}

"""
Boolean expression to filter rows from the table "sentinel_activities". All fields are combined with a logical 'AND'.
"""
input sentinel_activities_bool_exp {
  _and: [sentinel_activities_bool_exp!]
  _not: sentinel_activities_bool_exp
  _or: [sentinel_activities_bool_exp!]
  action: String_comparison_exp
  action_result: sentinel_action_result_comparison_exp
  created_at: timestamptz_comparison_exp
  decision: sentinel_decision_comparison_exp
  decision_expires_at: timestamptz_comparison_exp
  id: String_comparison_exp
  payload: jsonb_comparison_exp
  target_hash: String_comparison_exp
  target_type: String_comparison_exp
  tenant_id: String_comparison_exp
}

"""
unique or primary key constraints on table "sentinel_activities"
"""
enum sentinel_activities_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  sentinel_activities_pkey
}

"""
delete the field or element with specified path (for JSON arrays, negative integers count from the end)
"""
input sentinel_activities_delete_at_path_input {
  payload: [String!]
}

"""
delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
"""
input sentinel_activities_delete_elem_input {
  payload: Int
}

"""
delete key/value pair or string element. key/value pairs are matched based on their key value
"""
input sentinel_activities_delete_key_input {
  payload: String
}

"""
input type for inserting data into table "sentinel_activities"
"""
input sentinel_activities_insert_input {
  action: String
  action_result: sentinel_action_result
  created_at: timestamptz
  decision: sentinel_decision
  decision_expires_at: timestamptz
  id: String
  payload: jsonb
  target_hash: String
  target_type: String
  tenant_id: String
}

"""aggregate max on columns"""
type sentinel_activities_max_fields {
  action: String
  action_result: sentinel_action_result
  created_at: timestamptz
  decision: sentinel_decision
  decision_expires_at: timestamptz
  id: String
  target_hash: String
  target_type: String
  tenant_id: String
}

"""aggregate min on columns"""
type sentinel_activities_min_fields {
  action: String
  action_result: sentinel_action_result
  created_at: timestamptz
  decision: sentinel_decision
  decision_expires_at: timestamptz
  id: String
  target_hash: String
  target_type: String
  tenant_id: String
}

"""
response of any mutation on the table "sentinel_activities"
"""
type sentinel_activities_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [sentinel_activities!]!
}

"""
on_conflict condition type for table "sentinel_activities"
"""
input sentinel_activities_on_conflict {
  constraint: sentinel_activities_constraint!
  update_columns: [sentinel_activities_update_column!]! = []
  where: sentinel_activities_bool_exp
}

"""Ordering options when selecting data from "sentinel_activities"."""
input sentinel_activities_order_by {
  action: order_by
  action_result: order_by
  created_at: order_by
  decision: order_by
  decision_expires_at: order_by
  id: order_by
  payload: order_by
  target_hash: order_by
  target_type: order_by
  tenant_id: order_by
}

"""primary key columns input for table: sentinel_activities"""
input sentinel_activities_pk_columns_input {
  id: String!
}

"""prepend existing jsonb value of filtered columns with new jsonb value"""
input sentinel_activities_prepend_input {
  payload: jsonb
}

"""
select columns of table "sentinel_activities"
"""
enum sentinel_activities_select_column {
  """column name"""
  action

  """column name"""
  action_result

  """column name"""
  created_at

  """column name"""
  decision

  """column name"""
  decision_expires_at

  """column name"""
  id

  """column name"""
  payload

  """column name"""
  target_hash

  """column name"""
  target_type

  """column name"""
  tenant_id
}

"""
input type for updating data in table "sentinel_activities"
"""
input sentinel_activities_set_input {
  action: String
  action_result: sentinel_action_result
  created_at: timestamptz
  decision: sentinel_decision
  decision_expires_at: timestamptz
  id: String
  payload: jsonb
  target_hash: String
  target_type: String
  tenant_id: String
}

"""
Streaming cursor of the table "sentinel_activities"
"""
input sentinel_activities_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: sentinel_activities_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input sentinel_activities_stream_cursor_value_input {
  action: String
  action_result: sentinel_action_result
  created_at: timestamptz
  decision: sentinel_decision
  decision_expires_at: timestamptz
  id: String
  payload: jsonb
  target_hash: String
  target_type: String
  tenant_id: String
}

"""
update columns of table "sentinel_activities"
"""
enum sentinel_activities_update_column {
  """column name"""
  action

  """column name"""
  action_result

  """column name"""
  created_at

  """column name"""
  decision

  """column name"""
  decision_expires_at

  """column name"""
  id

  """column name"""
  payload

  """column name"""
  target_hash

  """column name"""
  target_type

  """column name"""
  tenant_id
}

input sentinel_activities_updates {
  """append existing jsonb value of filtered columns with new jsonb value"""
  _append: sentinel_activities_append_input

  """
  delete the field or element with specified path (for JSON arrays, negative integers count from the end)
  """
  _delete_at_path: sentinel_activities_delete_at_path_input

  """
  delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
  """
  _delete_elem: sentinel_activities_delete_elem_input

  """
  delete key/value pair or string element. key/value pairs are matched based on their key value
  """
  _delete_key: sentinel_activities_delete_key_input

  """prepend existing jsonb value of filtered columns with new jsonb value"""
  _prepend: sentinel_activities_prepend_input

  """sets the columns of the filtered rows to the given values"""
  _set: sentinel_activities_set_input

  """filter the rows which have to be updated"""
  where: sentinel_activities_bool_exp!
}

scalar sentinel_decision

"""
Boolean expression to compare columns of type "sentinel_decision". All fields are combined with logical 'AND'.
"""
input sentinel_decision_comparison_exp {
  _eq: sentinel_decision
  _gt: sentinel_decision
  _gte: sentinel_decision
  _in: [sentinel_decision!]
  _is_null: Boolean
  _lt: sentinel_decision
  _lte: sentinel_decision
  _neq: sentinel_decision
  _nin: [sentinel_decision!]
}

"""
columns and relationships of "service_logs"
"""
type service_logs {
  created_at: timestamptz!
  id: String!
  payload(
    """JSON select path"""
    path: String
  ): jsonb!
  tenant_id: String!
  type: String!
}

"""
aggregated selection of "service_logs"
"""
type service_logs_aggregate {
  aggregate: service_logs_aggregate_fields
  nodes: [service_logs!]!
}

"""
aggregate fields of "service_logs"
"""
type service_logs_aggregate_fields {
  count(columns: [service_logs_select_column!], distinct: Boolean): Int!
  max: service_logs_max_fields
  min: service_logs_min_fields
}

"""append existing jsonb value of filtered columns with new jsonb value"""
input service_logs_append_input {
  payload: jsonb
}

"""
Boolean expression to filter rows from the table "service_logs". All fields are combined with a logical 'AND'.
"""
input service_logs_bool_exp {
  _and: [service_logs_bool_exp!]
  _not: service_logs_bool_exp
  _or: [service_logs_bool_exp!]
  created_at: timestamptz_comparison_exp
  id: String_comparison_exp
  payload: jsonb_comparison_exp
  tenant_id: String_comparison_exp
  type: String_comparison_exp
}

"""
unique or primary key constraints on table "service_logs"
"""
enum service_logs_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  service_logs_pkey
}

"""
delete the field or element with specified path (for JSON arrays, negative integers count from the end)
"""
input service_logs_delete_at_path_input {
  payload: [String!]
}

"""
delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
"""
input service_logs_delete_elem_input {
  payload: Int
}

"""
delete key/value pair or string element. key/value pairs are matched based on their key value
"""
input service_logs_delete_key_input {
  payload: String
}

"""
input type for inserting data into table "service_logs"
"""
input service_logs_insert_input {
  created_at: timestamptz
  id: String
  payload: jsonb
  tenant_id: String
  type: String
}

"""aggregate max on columns"""
type service_logs_max_fields {
  created_at: timestamptz
  id: String
  tenant_id: String
  type: String
}

"""aggregate min on columns"""
type service_logs_min_fields {
  created_at: timestamptz
  id: String
  tenant_id: String
  type: String
}

"""
response of any mutation on the table "service_logs"
"""
type service_logs_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [service_logs!]!
}

"""
on_conflict condition type for table "service_logs"
"""
input service_logs_on_conflict {
  constraint: service_logs_constraint!
  update_columns: [service_logs_update_column!]! = []
  where: service_logs_bool_exp
}

"""Ordering options when selecting data from "service_logs"."""
input service_logs_order_by {
  created_at: order_by
  id: order_by
  payload: order_by
  tenant_id: order_by
  type: order_by
}

"""primary key columns input for table: service_logs"""
input service_logs_pk_columns_input {
  id: String!
}

"""prepend existing jsonb value of filtered columns with new jsonb value"""
input service_logs_prepend_input {
  payload: jsonb
}

"""
select columns of table "service_logs"
"""
enum service_logs_select_column {
  """column name"""
  created_at

  """column name"""
  id

  """column name"""
  payload

  """column name"""
  tenant_id

  """column name"""
  type
}

"""
input type for updating data in table "service_logs"
"""
input service_logs_set_input {
  created_at: timestamptz
  id: String
  payload: jsonb
  tenant_id: String
  type: String
}

"""
Streaming cursor of the table "service_logs"
"""
input service_logs_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: service_logs_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input service_logs_stream_cursor_value_input {
  created_at: timestamptz
  id: String
  payload: jsonb
  tenant_id: String
  type: String
}

"""
update columns of table "service_logs"
"""
enum service_logs_update_column {
  """column name"""
  created_at

  """column name"""
  id

  """column name"""
  payload

  """column name"""
  tenant_id

  """column name"""
  type
}

input service_logs_updates {
  """append existing jsonb value of filtered columns with new jsonb value"""
  _append: service_logs_append_input

  """
  delete the field or element with specified path (for JSON arrays, negative integers count from the end)
  """
  _delete_at_path: service_logs_delete_at_path_input

  """
  delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
  """
  _delete_elem: service_logs_delete_elem_input

  """
  delete key/value pair or string element. key/value pairs are matched based on their key value
  """
  _delete_key: service_logs_delete_key_input

  """prepend existing jsonb value of filtered columns with new jsonb value"""
  _prepend: service_logs_prepend_input

  """sets the columns of the filtered rows to the given values"""
  _set: service_logs_set_input

  """filter the rows which have to be updated"""
  where: service_logs_bool_exp!
}

"""
columns and relationships of "sign_in_experiences"
"""
type sign_in_experiences {
  branding(
    """JSON select path"""
    path: String
  ): jsonb!
  color(
    """JSON select path"""
    path: String
  ): jsonb!
  custom_content(
    """JSON select path"""
    path: String
  ): jsonb!
  custom_css: String
  id: String!
  language_info(
    """JSON select path"""
    path: String
  ): jsonb!
  mfa(
    """JSON select path"""
    path: String
  ): jsonb!
  password_policy(
    """JSON select path"""
    path: String
  ): jsonb!
  privacy_policy_url: String
  sign_in(
    """JSON select path"""
    path: String
  ): jsonb!
  sign_in_mode: sign_in_mode!
  sign_up(
    """JSON select path"""
    path: String
  ): jsonb!
  single_sign_on_enabled: Boolean!
  social_sign_in_connector_targets(
    """JSON select path"""
    path: String
  ): jsonb!
  tenant_id: String!
  terms_of_use_url: String
}

"""
aggregated selection of "sign_in_experiences"
"""
type sign_in_experiences_aggregate {
  aggregate: sign_in_experiences_aggregate_fields
  nodes: [sign_in_experiences!]!
}

"""
aggregate fields of "sign_in_experiences"
"""
type sign_in_experiences_aggregate_fields {
  count(columns: [sign_in_experiences_select_column!], distinct: Boolean): Int!
  max: sign_in_experiences_max_fields
  min: sign_in_experiences_min_fields
}

"""append existing jsonb value of filtered columns with new jsonb value"""
input sign_in_experiences_append_input {
  branding: jsonb
  color: jsonb
  custom_content: jsonb
  language_info: jsonb
  mfa: jsonb
  password_policy: jsonb
  sign_in: jsonb
  sign_up: jsonb
  social_sign_in_connector_targets: jsonb
}

"""
Boolean expression to filter rows from the table "sign_in_experiences". All fields are combined with a logical 'AND'.
"""
input sign_in_experiences_bool_exp {
  _and: [sign_in_experiences_bool_exp!]
  _not: sign_in_experiences_bool_exp
  _or: [sign_in_experiences_bool_exp!]
  branding: jsonb_comparison_exp
  color: jsonb_comparison_exp
  custom_content: jsonb_comparison_exp
  custom_css: String_comparison_exp
  id: String_comparison_exp
  language_info: jsonb_comparison_exp
  mfa: jsonb_comparison_exp
  password_policy: jsonb_comparison_exp
  privacy_policy_url: String_comparison_exp
  sign_in: jsonb_comparison_exp
  sign_in_mode: sign_in_mode_comparison_exp
  sign_up: jsonb_comparison_exp
  single_sign_on_enabled: Boolean_comparison_exp
  social_sign_in_connector_targets: jsonb_comparison_exp
  tenant_id: String_comparison_exp
  terms_of_use_url: String_comparison_exp
}

"""
unique or primary key constraints on table "sign_in_experiences"
"""
enum sign_in_experiences_constraint {
  """
  unique or primary key constraint on columns "id", "tenant_id"
  """
  sign_in_experiences_pkey
}

"""
delete the field or element with specified path (for JSON arrays, negative integers count from the end)
"""
input sign_in_experiences_delete_at_path_input {
  branding: [String!]
  color: [String!]
  custom_content: [String!]
  language_info: [String!]
  mfa: [String!]
  password_policy: [String!]
  sign_in: [String!]
  sign_up: [String!]
  social_sign_in_connector_targets: [String!]
}

"""
delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
"""
input sign_in_experiences_delete_elem_input {
  branding: Int
  color: Int
  custom_content: Int
  language_info: Int
  mfa: Int
  password_policy: Int
  sign_in: Int
  sign_up: Int
  social_sign_in_connector_targets: Int
}

"""
delete key/value pair or string element. key/value pairs are matched based on their key value
"""
input sign_in_experiences_delete_key_input {
  branding: String
  color: String
  custom_content: String
  language_info: String
  mfa: String
  password_policy: String
  sign_in: String
  sign_up: String
  social_sign_in_connector_targets: String
}

"""
input type for inserting data into table "sign_in_experiences"
"""
input sign_in_experiences_insert_input {
  branding: jsonb
  color: jsonb
  custom_content: jsonb
  custom_css: String
  id: String
  language_info: jsonb
  mfa: jsonb
  password_policy: jsonb
  privacy_policy_url: String
  sign_in: jsonb
  sign_in_mode: sign_in_mode
  sign_up: jsonb
  single_sign_on_enabled: Boolean
  social_sign_in_connector_targets: jsonb
  tenant_id: String
  terms_of_use_url: String
}

"""aggregate max on columns"""
type sign_in_experiences_max_fields {
  custom_css: String
  id: String
  privacy_policy_url: String
  sign_in_mode: sign_in_mode
  tenant_id: String
  terms_of_use_url: String
}

"""aggregate min on columns"""
type sign_in_experiences_min_fields {
  custom_css: String
  id: String
  privacy_policy_url: String
  sign_in_mode: sign_in_mode
  tenant_id: String
  terms_of_use_url: String
}

"""
response of any mutation on the table "sign_in_experiences"
"""
type sign_in_experiences_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [sign_in_experiences!]!
}

"""
on_conflict condition type for table "sign_in_experiences"
"""
input sign_in_experiences_on_conflict {
  constraint: sign_in_experiences_constraint!
  update_columns: [sign_in_experiences_update_column!]! = []
  where: sign_in_experiences_bool_exp
}

"""Ordering options when selecting data from "sign_in_experiences"."""
input sign_in_experiences_order_by {
  branding: order_by
  color: order_by
  custom_content: order_by
  custom_css: order_by
  id: order_by
  language_info: order_by
  mfa: order_by
  password_policy: order_by
  privacy_policy_url: order_by
  sign_in: order_by
  sign_in_mode: order_by
  sign_up: order_by
  single_sign_on_enabled: order_by
  social_sign_in_connector_targets: order_by
  tenant_id: order_by
  terms_of_use_url: order_by
}

"""primary key columns input for table: sign_in_experiences"""
input sign_in_experiences_pk_columns_input {
  id: String!
  tenant_id: String!
}

"""prepend existing jsonb value of filtered columns with new jsonb value"""
input sign_in_experiences_prepend_input {
  branding: jsonb
  color: jsonb
  custom_content: jsonb
  language_info: jsonb
  mfa: jsonb
  password_policy: jsonb
  sign_in: jsonb
  sign_up: jsonb
  social_sign_in_connector_targets: jsonb
}

"""
select columns of table "sign_in_experiences"
"""
enum sign_in_experiences_select_column {
  """column name"""
  branding

  """column name"""
  color

  """column name"""
  custom_content

  """column name"""
  custom_css

  """column name"""
  id

  """column name"""
  language_info

  """column name"""
  mfa

  """column name"""
  password_policy

  """column name"""
  privacy_policy_url

  """column name"""
  sign_in

  """column name"""
  sign_in_mode

  """column name"""
  sign_up

  """column name"""
  single_sign_on_enabled

  """column name"""
  social_sign_in_connector_targets

  """column name"""
  tenant_id

  """column name"""
  terms_of_use_url
}

"""
input type for updating data in table "sign_in_experiences"
"""
input sign_in_experiences_set_input {
  branding: jsonb
  color: jsonb
  custom_content: jsonb
  custom_css: String
  id: String
  language_info: jsonb
  mfa: jsonb
  password_policy: jsonb
  privacy_policy_url: String
  sign_in: jsonb
  sign_in_mode: sign_in_mode
  sign_up: jsonb
  single_sign_on_enabled: Boolean
  social_sign_in_connector_targets: jsonb
  tenant_id: String
  terms_of_use_url: String
}

"""
Streaming cursor of the table "sign_in_experiences"
"""
input sign_in_experiences_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: sign_in_experiences_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input sign_in_experiences_stream_cursor_value_input {
  branding: jsonb
  color: jsonb
  custom_content: jsonb
  custom_css: String
  id: String
  language_info: jsonb
  mfa: jsonb
  password_policy: jsonb
  privacy_policy_url: String
  sign_in: jsonb
  sign_in_mode: sign_in_mode
  sign_up: jsonb
  single_sign_on_enabled: Boolean
  social_sign_in_connector_targets: jsonb
  tenant_id: String
  terms_of_use_url: String
}

"""
update columns of table "sign_in_experiences"
"""
enum sign_in_experiences_update_column {
  """column name"""
  branding

  """column name"""
  color

  """column name"""
  custom_content

  """column name"""
  custom_css

  """column name"""
  id

  """column name"""
  language_info

  """column name"""
  mfa

  """column name"""
  password_policy

  """column name"""
  privacy_policy_url

  """column name"""
  sign_in

  """column name"""
  sign_in_mode

  """column name"""
  sign_up

  """column name"""
  single_sign_on_enabled

  """column name"""
  social_sign_in_connector_targets

  """column name"""
  tenant_id

  """column name"""
  terms_of_use_url
}

input sign_in_experiences_updates {
  """append existing jsonb value of filtered columns with new jsonb value"""
  _append: sign_in_experiences_append_input

  """
  delete the field or element with specified path (for JSON arrays, negative integers count from the end)
  """
  _delete_at_path: sign_in_experiences_delete_at_path_input

  """
  delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
  """
  _delete_elem: sign_in_experiences_delete_elem_input

  """
  delete key/value pair or string element. key/value pairs are matched based on their key value
  """
  _delete_key: sign_in_experiences_delete_key_input

  """prepend existing jsonb value of filtered columns with new jsonb value"""
  _prepend: sign_in_experiences_prepend_input

  """sets the columns of the filtered rows to the given values"""
  _set: sign_in_experiences_set_input

  """filter the rows which have to be updated"""
  where: sign_in_experiences_bool_exp!
}

scalar sign_in_mode

"""
Boolean expression to compare columns of type "sign_in_mode". All fields are combined with logical 'AND'.
"""
input sign_in_mode_comparison_exp {
  _eq: sign_in_mode
  _gt: sign_in_mode
  _gte: sign_in_mode
  _in: [sign_in_mode!]
  _is_null: Boolean
  _lt: sign_in_mode
  _lte: sign_in_mode
  _neq: sign_in_mode
  _nin: [sign_in_mode!]
}

scalar smallint

"""
Boolean expression to compare columns of type "smallint". All fields are combined with logical 'AND'.
"""
input smallint_comparison_exp {
  _eq: smallint
  _gt: smallint
  _gte: smallint
  _in: [smallint!]
  _is_null: Boolean
  _lt: smallint
  _lte: smallint
  _neq: smallint
  _nin: [smallint!]
}

"""短信验证码"""
type sms_codes {
  captcha: String!
  created_at: timestamptz!
  id: uuid!
  phone_number: String!
  user_id: String!
}

"""
aggregated selection of "sms_codes"
"""
type sms_codes_aggregate {
  aggregate: sms_codes_aggregate_fields
  nodes: [sms_codes!]!
}

"""
aggregate fields of "sms_codes"
"""
type sms_codes_aggregate_fields {
  count(columns: [sms_codes_select_column!], distinct: Boolean): Int!
  max: sms_codes_max_fields
  min: sms_codes_min_fields
}

"""
Boolean expression to filter rows from the table "sms_codes". All fields are combined with a logical 'AND'.
"""
input sms_codes_bool_exp {
  _and: [sms_codes_bool_exp!]
  _not: sms_codes_bool_exp
  _or: [sms_codes_bool_exp!]
  captcha: String_comparison_exp
  created_at: timestamptz_comparison_exp
  id: uuid_comparison_exp
  phone_number: String_comparison_exp
  user_id: String_comparison_exp
}

"""
unique or primary key constraints on table "sms_codes"
"""
enum sms_codes_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  sms_codes_pkey
}

"""
input type for inserting data into table "sms_codes"
"""
input sms_codes_insert_input {
  captcha: String
  created_at: timestamptz
  id: uuid
  phone_number: String
  user_id: String
}

"""aggregate max on columns"""
type sms_codes_max_fields {
  captcha: String
  created_at: timestamptz
  id: uuid
  phone_number: String
  user_id: String
}

"""aggregate min on columns"""
type sms_codes_min_fields {
  captcha: String
  created_at: timestamptz
  id: uuid
  phone_number: String
  user_id: String
}

"""
response of any mutation on the table "sms_codes"
"""
type sms_codes_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [sms_codes!]!
}

"""
on_conflict condition type for table "sms_codes"
"""
input sms_codes_on_conflict {
  constraint: sms_codes_constraint!
  update_columns: [sms_codes_update_column!]! = []
  where: sms_codes_bool_exp
}

"""Ordering options when selecting data from "sms_codes"."""
input sms_codes_order_by {
  captcha: order_by
  created_at: order_by
  id: order_by
  phone_number: order_by
  user_id: order_by
}

"""primary key columns input for table: sms_codes"""
input sms_codes_pk_columns_input {
  id: uuid!
}

"""
select columns of table "sms_codes"
"""
enum sms_codes_select_column {
  """column name"""
  captcha

  """column name"""
  created_at

  """column name"""
  id

  """column name"""
  phone_number

  """column name"""
  user_id
}

"""
input type for updating data in table "sms_codes"
"""
input sms_codes_set_input {
  captcha: String
  created_at: timestamptz
  id: uuid
  phone_number: String
  user_id: String
}

"""
Streaming cursor of the table "sms_codes"
"""
input sms_codes_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: sms_codes_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input sms_codes_stream_cursor_value_input {
  captcha: String
  created_at: timestamptz
  id: uuid
  phone_number: String
  user_id: String
}

"""
update columns of table "sms_codes"
"""
enum sms_codes_update_column {
  """column name"""
  captcha

  """column name"""
  created_at

  """column name"""
  id

  """column name"""
  phone_number

  """column name"""
  user_id
}

input sms_codes_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: sms_codes_set_input

  """filter the rows which have to be updated"""
  where: sms_codes_bool_exp!
}

"""
columns and relationships of "sso_connectors"
"""
type sso_connectors {
  branding(
    """JSON select path"""
    path: String
  ): jsonb!
  config(
    """JSON select path"""
    path: String
  ): jsonb!
  connector_name: String!
  created_at: timestamptz!
  domains(
    """JSON select path"""
    path: String
  ): jsonb!
  id: String!
  provider_name: String!
  sync_profile: Boolean!
  tenant_id: String!
}

"""
aggregated selection of "sso_connectors"
"""
type sso_connectors_aggregate {
  aggregate: sso_connectors_aggregate_fields
  nodes: [sso_connectors!]!
}

"""
aggregate fields of "sso_connectors"
"""
type sso_connectors_aggregate_fields {
  count(columns: [sso_connectors_select_column!], distinct: Boolean): Int!
  max: sso_connectors_max_fields
  min: sso_connectors_min_fields
}

"""append existing jsonb value of filtered columns with new jsonb value"""
input sso_connectors_append_input {
  branding: jsonb
  config: jsonb
  domains: jsonb
}

"""
Boolean expression to filter rows from the table "sso_connectors". All fields are combined with a logical 'AND'.
"""
input sso_connectors_bool_exp {
  _and: [sso_connectors_bool_exp!]
  _not: sso_connectors_bool_exp
  _or: [sso_connectors_bool_exp!]
  branding: jsonb_comparison_exp
  config: jsonb_comparison_exp
  connector_name: String_comparison_exp
  created_at: timestamptz_comparison_exp
  domains: jsonb_comparison_exp
  id: String_comparison_exp
  provider_name: String_comparison_exp
  sync_profile: Boolean_comparison_exp
  tenant_id: String_comparison_exp
}

"""
unique or primary key constraints on table "sso_connectors"
"""
enum sso_connectors_constraint {
  """
  unique or primary key constraint on columns "tenant_id", "connector_name"
  """
  sso_connectors__connector_name__unique

  """
  unique or primary key constraint on columns "id"
  """
  sso_connectors_pkey
}

"""
delete the field or element with specified path (for JSON arrays, negative integers count from the end)
"""
input sso_connectors_delete_at_path_input {
  branding: [String!]
  config: [String!]
  domains: [String!]
}

"""
delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
"""
input sso_connectors_delete_elem_input {
  branding: Int
  config: Int
  domains: Int
}

"""
delete key/value pair or string element. key/value pairs are matched based on their key value
"""
input sso_connectors_delete_key_input {
  branding: String
  config: String
  domains: String
}

"""
input type for inserting data into table "sso_connectors"
"""
input sso_connectors_insert_input {
  branding: jsonb
  config: jsonb
  connector_name: String
  created_at: timestamptz
  domains: jsonb
  id: String
  provider_name: String
  sync_profile: Boolean
  tenant_id: String
}

"""aggregate max on columns"""
type sso_connectors_max_fields {
  connector_name: String
  created_at: timestamptz
  id: String
  provider_name: String
  tenant_id: String
}

"""aggregate min on columns"""
type sso_connectors_min_fields {
  connector_name: String
  created_at: timestamptz
  id: String
  provider_name: String
  tenant_id: String
}

"""
response of any mutation on the table "sso_connectors"
"""
type sso_connectors_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [sso_connectors!]!
}

"""
on_conflict condition type for table "sso_connectors"
"""
input sso_connectors_on_conflict {
  constraint: sso_connectors_constraint!
  update_columns: [sso_connectors_update_column!]! = []
  where: sso_connectors_bool_exp
}

"""Ordering options when selecting data from "sso_connectors"."""
input sso_connectors_order_by {
  branding: order_by
  config: order_by
  connector_name: order_by
  created_at: order_by
  domains: order_by
  id: order_by
  provider_name: order_by
  sync_profile: order_by
  tenant_id: order_by
}

"""primary key columns input for table: sso_connectors"""
input sso_connectors_pk_columns_input {
  id: String!
}

"""prepend existing jsonb value of filtered columns with new jsonb value"""
input sso_connectors_prepend_input {
  branding: jsonb
  config: jsonb
  domains: jsonb
}

"""
select columns of table "sso_connectors"
"""
enum sso_connectors_select_column {
  """column name"""
  branding

  """column name"""
  config

  """column name"""
  connector_name

  """column name"""
  created_at

  """column name"""
  domains

  """column name"""
  id

  """column name"""
  provider_name

  """column name"""
  sync_profile

  """column name"""
  tenant_id
}

"""
input type for updating data in table "sso_connectors"
"""
input sso_connectors_set_input {
  branding: jsonb
  config: jsonb
  connector_name: String
  created_at: timestamptz
  domains: jsonb
  id: String
  provider_name: String
  sync_profile: Boolean
  tenant_id: String
}

"""
Streaming cursor of the table "sso_connectors"
"""
input sso_connectors_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: sso_connectors_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input sso_connectors_stream_cursor_value_input {
  branding: jsonb
  config: jsonb
  connector_name: String
  created_at: timestamptz
  domains: jsonb
  id: String
  provider_name: String
  sync_profile: Boolean
  tenant_id: String
}

"""
update columns of table "sso_connectors"
"""
enum sso_connectors_update_column {
  """column name"""
  branding

  """column name"""
  config

  """column name"""
  connector_name

  """column name"""
  created_at

  """column name"""
  domains

  """column name"""
  id

  """column name"""
  provider_name

  """column name"""
  sync_profile

  """column name"""
  tenant_id
}

input sso_connectors_updates {
  """append existing jsonb value of filtered columns with new jsonb value"""
  _append: sso_connectors_append_input

  """
  delete the field or element with specified path (for JSON arrays, negative integers count from the end)
  """
  _delete_at_path: sso_connectors_delete_at_path_input

  """
  delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
  """
  _delete_elem: sso_connectors_delete_elem_input

  """
  delete key/value pair or string element. key/value pairs are matched based on their key value
  """
  _delete_key: sso_connectors_delete_key_input

  """prepend existing jsonb value of filtered columns with new jsonb value"""
  _prepend: sso_connectors_prepend_input

  """sets the columns of the filtered rows to the given values"""
  _set: sso_connectors_set_input

  """filter the rows which have to be updated"""
  where: sso_connectors_bool_exp!
}

type subscription_root {
  """
  fetch data from the table: "ads"
  """
  ads(
    """distinct select on columns"""
    distinct_on: [ads_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [ads_order_by!]

    """filter the rows returned"""
    where: ads_bool_exp
  ): [ads!]!

  """
  fetch aggregated fields from the table: "ads"
  """
  ads_aggregate(
    """distinct select on columns"""
    distinct_on: [ads_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [ads_order_by!]

    """filter the rows returned"""
    where: ads_bool_exp
  ): ads_aggregate!

  """fetch data from the table: "ads" using primary key columns"""
  ads_by_pk(id: uuid!): ads

  """
  fetch data from the table in a streaming manner: "ads"
  """
  ads_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [ads_stream_cursor_input]!

    """filter the rows returned"""
    where: ads_bool_exp
  ): [ads!]!

  """
  fetch data from the table: "application_sign_in_experiences"
  """
  application_sign_in_experiences(
    """distinct select on columns"""
    distinct_on: [application_sign_in_experiences_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [application_sign_in_experiences_order_by!]

    """filter the rows returned"""
    where: application_sign_in_experiences_bool_exp
  ): [application_sign_in_experiences!]!

  """
  fetch aggregated fields from the table: "application_sign_in_experiences"
  """
  application_sign_in_experiences_aggregate(
    """distinct select on columns"""
    distinct_on: [application_sign_in_experiences_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [application_sign_in_experiences_order_by!]

    """filter the rows returned"""
    where: application_sign_in_experiences_bool_exp
  ): application_sign_in_experiences_aggregate!

  """
  fetch data from the table: "application_sign_in_experiences" using primary key columns
  """
  application_sign_in_experiences_by_pk(application_id: String!, tenant_id: String!): application_sign_in_experiences

  """
  fetch data from the table in a streaming manner: "application_sign_in_experiences"
  """
  application_sign_in_experiences_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [application_sign_in_experiences_stream_cursor_input]!

    """filter the rows returned"""
    where: application_sign_in_experiences_bool_exp
  ): [application_sign_in_experiences!]!

  """
  fetch data from the table: "application_user_consent_organization_scopes"
  """
  application_user_consent_organization_scopes(
    """distinct select on columns"""
    distinct_on: [application_user_consent_organization_scopes_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [application_user_consent_organization_scopes_order_by!]

    """filter the rows returned"""
    where: application_user_consent_organization_scopes_bool_exp
  ): [application_user_consent_organization_scopes!]!

  """
  fetch aggregated fields from the table: "application_user_consent_organization_scopes"
  """
  application_user_consent_organization_scopes_aggregate(
    """distinct select on columns"""
    distinct_on: [application_user_consent_organization_scopes_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [application_user_consent_organization_scopes_order_by!]

    """filter the rows returned"""
    where: application_user_consent_organization_scopes_bool_exp
  ): application_user_consent_organization_scopes_aggregate!

  """
  fetch data from the table: "application_user_consent_organization_scopes" using primary key columns
  """
  application_user_consent_organization_scopes_by_pk(application_id: String!, organization_scope_id: String!): application_user_consent_organization_scopes

  """
  fetch data from the table in a streaming manner: "application_user_consent_organization_scopes"
  """
  application_user_consent_organization_scopes_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [application_user_consent_organization_scopes_stream_cursor_input]!

    """filter the rows returned"""
    where: application_user_consent_organization_scopes_bool_exp
  ): [application_user_consent_organization_scopes!]!

  """
  fetch data from the table: "application_user_consent_organizations"
  """
  application_user_consent_organizations(
    """distinct select on columns"""
    distinct_on: [application_user_consent_organizations_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [application_user_consent_organizations_order_by!]

    """filter the rows returned"""
    where: application_user_consent_organizations_bool_exp
  ): [application_user_consent_organizations!]!

  """
  fetch aggregated fields from the table: "application_user_consent_organizations"
  """
  application_user_consent_organizations_aggregate(
    """distinct select on columns"""
    distinct_on: [application_user_consent_organizations_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [application_user_consent_organizations_order_by!]

    """filter the rows returned"""
    where: application_user_consent_organizations_bool_exp
  ): application_user_consent_organizations_aggregate!

  """
  fetch data from the table: "application_user_consent_organizations" using primary key columns
  """
  application_user_consent_organizations_by_pk(application_id: String!, organization_id: String!, tenant_id: String!, user_id: String!): application_user_consent_organizations

  """
  fetch data from the table in a streaming manner: "application_user_consent_organizations"
  """
  application_user_consent_organizations_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [application_user_consent_organizations_stream_cursor_input]!

    """filter the rows returned"""
    where: application_user_consent_organizations_bool_exp
  ): [application_user_consent_organizations!]!

  """
  fetch data from the table: "application_user_consent_resource_scopes"
  """
  application_user_consent_resource_scopes(
    """distinct select on columns"""
    distinct_on: [application_user_consent_resource_scopes_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [application_user_consent_resource_scopes_order_by!]

    """filter the rows returned"""
    where: application_user_consent_resource_scopes_bool_exp
  ): [application_user_consent_resource_scopes!]!

  """
  fetch aggregated fields from the table: "application_user_consent_resource_scopes"
  """
  application_user_consent_resource_scopes_aggregate(
    """distinct select on columns"""
    distinct_on: [application_user_consent_resource_scopes_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [application_user_consent_resource_scopes_order_by!]

    """filter the rows returned"""
    where: application_user_consent_resource_scopes_bool_exp
  ): application_user_consent_resource_scopes_aggregate!

  """
  fetch data from the table: "application_user_consent_resource_scopes" using primary key columns
  """
  application_user_consent_resource_scopes_by_pk(application_id: String!, scope_id: String!): application_user_consent_resource_scopes

  """
  fetch data from the table in a streaming manner: "application_user_consent_resource_scopes"
  """
  application_user_consent_resource_scopes_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [application_user_consent_resource_scopes_stream_cursor_input]!

    """filter the rows returned"""
    where: application_user_consent_resource_scopes_bool_exp
  ): [application_user_consent_resource_scopes!]!

  """
  fetch data from the table: "application_user_consent_user_scopes"
  """
  application_user_consent_user_scopes(
    """distinct select on columns"""
    distinct_on: [application_user_consent_user_scopes_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [application_user_consent_user_scopes_order_by!]

    """filter the rows returned"""
    where: application_user_consent_user_scopes_bool_exp
  ): [application_user_consent_user_scopes!]!

  """
  fetch aggregated fields from the table: "application_user_consent_user_scopes"
  """
  application_user_consent_user_scopes_aggregate(
    """distinct select on columns"""
    distinct_on: [application_user_consent_user_scopes_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [application_user_consent_user_scopes_order_by!]

    """filter the rows returned"""
    where: application_user_consent_user_scopes_bool_exp
  ): application_user_consent_user_scopes_aggregate!

  """
  fetch data from the table: "application_user_consent_user_scopes" using primary key columns
  """
  application_user_consent_user_scopes_by_pk(application_id: String!, user_scope: String!): application_user_consent_user_scopes

  """
  fetch data from the table in a streaming manner: "application_user_consent_user_scopes"
  """
  application_user_consent_user_scopes_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [application_user_consent_user_scopes_stream_cursor_input]!

    """filter the rows returned"""
    where: application_user_consent_user_scopes_bool_exp
  ): [application_user_consent_user_scopes!]!

  """
  fetch data from the table: "applications"
  """
  applications(
    """distinct select on columns"""
    distinct_on: [applications_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [applications_order_by!]

    """filter the rows returned"""
    where: applications_bool_exp
  ): [applications!]!

  """
  fetch aggregated fields from the table: "applications"
  """
  applications_aggregate(
    """distinct select on columns"""
    distinct_on: [applications_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [applications_order_by!]

    """filter the rows returned"""
    where: applications_bool_exp
  ): applications_aggregate!

  """fetch data from the table: "applications" using primary key columns"""
  applications_by_pk(id: String!): applications

  """
  fetch data from the table: "applications_roles"
  """
  applications_roles(
    """distinct select on columns"""
    distinct_on: [applications_roles_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [applications_roles_order_by!]

    """filter the rows returned"""
    where: applications_roles_bool_exp
  ): [applications_roles!]!

  """
  fetch aggregated fields from the table: "applications_roles"
  """
  applications_roles_aggregate(
    """distinct select on columns"""
    distinct_on: [applications_roles_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [applications_roles_order_by!]

    """filter the rows returned"""
    where: applications_roles_bool_exp
  ): applications_roles_aggregate!

  """
  fetch data from the table: "applications_roles" using primary key columns
  """
  applications_roles_by_pk(id: String!): applications_roles

  """
  fetch data from the table in a streaming manner: "applications_roles"
  """
  applications_roles_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [applications_roles_stream_cursor_input]!

    """filter the rows returned"""
    where: applications_roles_bool_exp
  ): [applications_roles!]!

  """
  fetch data from the table in a streaming manner: "applications"
  """
  applications_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [applications_stream_cursor_input]!

    """filter the rows returned"""
    where: applications_bool_exp
  ): [applications!]!

  """
  fetch data from the table: "check_in_settings"
  """
  check_in_settings(
    """distinct select on columns"""
    distinct_on: [check_in_settings_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [check_in_settings_order_by!]

    """filter the rows returned"""
    where: check_in_settings_bool_exp
  ): [check_in_settings!]!

  """
  fetch aggregated fields from the table: "check_in_settings"
  """
  check_in_settings_aggregate(
    """distinct select on columns"""
    distinct_on: [check_in_settings_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [check_in_settings_order_by!]

    """filter the rows returned"""
    where: check_in_settings_bool_exp
  ): check_in_settings_aggregate!

  """
  fetch data from the table: "check_in_settings" using primary key columns
  """
  check_in_settings_by_pk(id: uuid!): check_in_settings

  """
  fetch data from the table in a streaming manner: "check_in_settings"
  """
  check_in_settings_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [check_in_settings_stream_cursor_input]!

    """filter the rows returned"""
    where: check_in_settings_bool_exp
  ): [check_in_settings!]!

  """
  fetch data from the table: "check_ins"
  """
  check_ins(
    """distinct select on columns"""
    distinct_on: [check_ins_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [check_ins_order_by!]

    """filter the rows returned"""
    where: check_ins_bool_exp
  ): [check_ins!]!

  """
  fetch aggregated fields from the table: "check_ins"
  """
  check_ins_aggregate(
    """distinct select on columns"""
    distinct_on: [check_ins_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [check_ins_order_by!]

    """filter the rows returned"""
    where: check_ins_bool_exp
  ): check_ins_aggregate!

  """fetch data from the table: "check_ins" using primary key columns"""
  check_ins_by_pk(id: uuid!): check_ins

  """
  fetch data from the table in a streaming manner: "check_ins"
  """
  check_ins_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [check_ins_stream_cursor_input]!

    """filter the rows returned"""
    where: check_ins_bool_exp
  ): [check_ins!]!

  """
  fetch data from the table: "cholesterol_records"
  """
  cholesterol_records(
    """distinct select on columns"""
    distinct_on: [cholesterol_records_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [cholesterol_records_order_by!]

    """filter the rows returned"""
    where: cholesterol_records_bool_exp
  ): [cholesterol_records!]!

  """
  fetch aggregated fields from the table: "cholesterol_records"
  """
  cholesterol_records_aggregate(
    """distinct select on columns"""
    distinct_on: [cholesterol_records_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [cholesterol_records_order_by!]

    """filter the rows returned"""
    where: cholesterol_records_bool_exp
  ): cholesterol_records_aggregate!

  """
  fetch data from the table: "cholesterol_records" using primary key columns
  """
  cholesterol_records_by_pk(id: uuid!): cholesterol_records

  """
  fetch data from the table in a streaming manner: "cholesterol_records"
  """
  cholesterol_records_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [cholesterol_records_stream_cursor_input]!

    """filter the rows returned"""
    where: cholesterol_records_bool_exp
  ): [cholesterol_records!]!

  """
  fetch data from the table: "cholesterol_standards"
  """
  cholesterol_standards(
    """distinct select on columns"""
    distinct_on: [cholesterol_standards_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [cholesterol_standards_order_by!]

    """filter the rows returned"""
    where: cholesterol_standards_bool_exp
  ): [cholesterol_standards!]!

  """
  fetch aggregated fields from the table: "cholesterol_standards"
  """
  cholesterol_standards_aggregate(
    """distinct select on columns"""
    distinct_on: [cholesterol_standards_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [cholesterol_standards_order_by!]

    """filter the rows returned"""
    where: cholesterol_standards_bool_exp
  ): cholesterol_standards_aggregate!

  """
  fetch data from the table: "cholesterol_standards" using primary key columns
  """
  cholesterol_standards_by_pk(id: uuid!): cholesterol_standards

  """
  fetch data from the table in a streaming manner: "cholesterol_standards"
  """
  cholesterol_standards_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [cholesterol_standards_stream_cursor_input]!

    """filter the rows returned"""
    where: cholesterol_standards_bool_exp
  ): [cholesterol_standards!]!

  """
  fetch data from the table: "connectors"
  """
  connectors(
    """distinct select on columns"""
    distinct_on: [connectors_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [connectors_order_by!]

    """filter the rows returned"""
    where: connectors_bool_exp
  ): [connectors!]!

  """
  fetch aggregated fields from the table: "connectors"
  """
  connectors_aggregate(
    """distinct select on columns"""
    distinct_on: [connectors_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [connectors_order_by!]

    """filter the rows returned"""
    where: connectors_bool_exp
  ): connectors_aggregate!

  """fetch data from the table: "connectors" using primary key columns"""
  connectors_by_pk(id: String!): connectors

  """
  fetch data from the table in a streaming manner: "connectors"
  """
  connectors_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [connectors_stream_cursor_input]!

    """filter the rows returned"""
    where: connectors_bool_exp
  ): [connectors!]!

  """
  fetch data from the table: "custom_phrases"
  """
  custom_phrases(
    """distinct select on columns"""
    distinct_on: [custom_phrases_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [custom_phrases_order_by!]

    """filter the rows returned"""
    where: custom_phrases_bool_exp
  ): [custom_phrases!]!

  """
  fetch aggregated fields from the table: "custom_phrases"
  """
  custom_phrases_aggregate(
    """distinct select on columns"""
    distinct_on: [custom_phrases_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [custom_phrases_order_by!]

    """filter the rows returned"""
    where: custom_phrases_bool_exp
  ): custom_phrases_aggregate!

  """fetch data from the table: "custom_phrases" using primary key columns"""
  custom_phrases_by_pk(id: String!): custom_phrases

  """
  fetch data from the table in a streaming manner: "custom_phrases"
  """
  custom_phrases_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [custom_phrases_stream_cursor_input]!

    """filter the rows returned"""
    where: custom_phrases_bool_exp
  ): [custom_phrases!]!

  """
  fetch data from the table: "daily_active_users"
  """
  daily_active_users(
    """distinct select on columns"""
    distinct_on: [daily_active_users_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [daily_active_users_order_by!]

    """filter the rows returned"""
    where: daily_active_users_bool_exp
  ): [daily_active_users!]!

  """
  fetch aggregated fields from the table: "daily_active_users"
  """
  daily_active_users_aggregate(
    """distinct select on columns"""
    distinct_on: [daily_active_users_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [daily_active_users_order_by!]

    """filter the rows returned"""
    where: daily_active_users_bool_exp
  ): daily_active_users_aggregate!

  """
  fetch data from the table: "daily_active_users" using primary key columns
  """
  daily_active_users_by_pk(id: String!): daily_active_users

  """
  fetch data from the table in a streaming manner: "daily_active_users"
  """
  daily_active_users_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [daily_active_users_stream_cursor_input]!

    """filter the rows returned"""
    where: daily_active_users_bool_exp
  ): [daily_active_users!]!

  """
  fetch data from the table: "daily_token_usage"
  """
  daily_token_usage(
    """distinct select on columns"""
    distinct_on: [daily_token_usage_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [daily_token_usage_order_by!]

    """filter the rows returned"""
    where: daily_token_usage_bool_exp
  ): [daily_token_usage!]!

  """
  fetch aggregated fields from the table: "daily_token_usage"
  """
  daily_token_usage_aggregate(
    """distinct select on columns"""
    distinct_on: [daily_token_usage_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [daily_token_usage_order_by!]

    """filter the rows returned"""
    where: daily_token_usage_bool_exp
  ): daily_token_usage_aggregate!

  """
  fetch data from the table: "daily_token_usage" using primary key columns
  """
  daily_token_usage_by_pk(id: String!): daily_token_usage

  """
  fetch data from the table in a streaming manner: "daily_token_usage"
  """
  daily_token_usage_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [daily_token_usage_stream_cursor_input]!

    """filter the rows returned"""
    where: daily_token_usage_bool_exp
  ): [daily_token_usage!]!

  """
  fetch data from the table: "domains"
  """
  domains(
    """distinct select on columns"""
    distinct_on: [domains_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [domains_order_by!]

    """filter the rows returned"""
    where: domains_bool_exp
  ): [domains!]!

  """
  fetch aggregated fields from the table: "domains"
  """
  domains_aggregate(
    """distinct select on columns"""
    distinct_on: [domains_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [domains_order_by!]

    """filter the rows returned"""
    where: domains_bool_exp
  ): domains_aggregate!

  """fetch data from the table: "domains" using primary key columns"""
  domains_by_pk(id: String!): domains

  """
  fetch data from the table in a streaming manner: "domains"
  """
  domains_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [domains_stream_cursor_input]!

    """filter the rows returned"""
    where: domains_bool_exp
  ): [domains!]!

  """
  fetch data from the table: "glucose_records"
  """
  glucose_records(
    """distinct select on columns"""
    distinct_on: [glucose_records_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [glucose_records_order_by!]

    """filter the rows returned"""
    where: glucose_records_bool_exp
  ): [glucose_records!]!

  """
  fetch aggregated fields from the table: "glucose_records"
  """
  glucose_records_aggregate(
    """distinct select on columns"""
    distinct_on: [glucose_records_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [glucose_records_order_by!]

    """filter the rows returned"""
    where: glucose_records_bool_exp
  ): glucose_records_aggregate!

  """fetch data from the table: "glucose_records" using primary key columns"""
  glucose_records_by_pk(id: uuid!): glucose_records

  """
  fetch data from the table in a streaming manner: "glucose_records"
  """
  glucose_records_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [glucose_records_stream_cursor_input]!

    """filter the rows returned"""
    where: glucose_records_bool_exp
  ): [glucose_records!]!

  """
  fetch data from the table: "glucose_standards"
  """
  glucose_standards(
    """distinct select on columns"""
    distinct_on: [glucose_standards_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [glucose_standards_order_by!]

    """filter the rows returned"""
    where: glucose_standards_bool_exp
  ): [glucose_standards!]!

  """
  fetch aggregated fields from the table: "glucose_standards"
  """
  glucose_standards_aggregate(
    """distinct select on columns"""
    distinct_on: [glucose_standards_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [glucose_standards_order_by!]

    """filter the rows returned"""
    where: glucose_standards_bool_exp
  ): glucose_standards_aggregate!

  """
  fetch data from the table: "glucose_standards" using primary key columns
  """
  glucose_standards_by_pk(id: uuid!): glucose_standards

  """
  fetch data from the table in a streaming manner: "glucose_standards"
  """
  glucose_standards_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [glucose_standards_stream_cursor_input]!

    """filter the rows returned"""
    where: glucose_standards_bool_exp
  ): [glucose_standards!]!

  """
  fetch data from the table: "hooks"
  """
  hooks(
    """distinct select on columns"""
    distinct_on: [hooks_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [hooks_order_by!]

    """filter the rows returned"""
    where: hooks_bool_exp
  ): [hooks!]!

  """
  fetch aggregated fields from the table: "hooks"
  """
  hooks_aggregate(
    """distinct select on columns"""
    distinct_on: [hooks_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [hooks_order_by!]

    """filter the rows returned"""
    where: hooks_bool_exp
  ): hooks_aggregate!

  """fetch data from the table: "hooks" using primary key columns"""
  hooks_by_pk(id: String!): hooks

  """
  fetch data from the table in a streaming manner: "hooks"
  """
  hooks_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [hooks_stream_cursor_input]!

    """filter the rows returned"""
    where: hooks_bool_exp
  ): [hooks!]!

  """
  fetch data from the table: "lab_report_records"
  """
  lab_report_records(
    """distinct select on columns"""
    distinct_on: [lab_report_records_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [lab_report_records_order_by!]

    """filter the rows returned"""
    where: lab_report_records_bool_exp
  ): [lab_report_records!]!

  """
  fetch aggregated fields from the table: "lab_report_records"
  """
  lab_report_records_aggregate(
    """distinct select on columns"""
    distinct_on: [lab_report_records_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [lab_report_records_order_by!]

    """filter the rows returned"""
    where: lab_report_records_bool_exp
  ): lab_report_records_aggregate!

  """
  fetch data from the table: "lab_report_records" using primary key columns
  """
  lab_report_records_by_pk(id: uuid!): lab_report_records

  """
  fetch data from the table in a streaming manner: "lab_report_records"
  """
  lab_report_records_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [lab_report_records_stream_cursor_input]!

    """filter the rows returned"""
    where: lab_report_records_bool_exp
  ): [lab_report_records!]!

  """
  fetch data from the table: "logs"
  """
  logs(
    """distinct select on columns"""
    distinct_on: [logs_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [logs_order_by!]

    """filter the rows returned"""
    where: logs_bool_exp
  ): [logs!]!

  """
  fetch aggregated fields from the table: "logs"
  """
  logs_aggregate(
    """distinct select on columns"""
    distinct_on: [logs_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [logs_order_by!]

    """filter the rows returned"""
    where: logs_bool_exp
  ): logs_aggregate!

  """fetch data from the table: "logs" using primary key columns"""
  logs_by_pk(id: String!): logs

  """
  fetch data from the table in a streaming manner: "logs"
  """
  logs_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [logs_stream_cursor_input]!

    """filter the rows returned"""
    where: logs_bool_exp
  ): [logs!]!

  """
  fetch data from the table: "logto_configs"
  """
  logto_configs(
    """distinct select on columns"""
    distinct_on: [logto_configs_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [logto_configs_order_by!]

    """filter the rows returned"""
    where: logto_configs_bool_exp
  ): [logto_configs!]!

  """
  fetch aggregated fields from the table: "logto_configs"
  """
  logto_configs_aggregate(
    """distinct select on columns"""
    distinct_on: [logto_configs_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [logto_configs_order_by!]

    """filter the rows returned"""
    where: logto_configs_bool_exp
  ): logto_configs_aggregate!

  """fetch data from the table: "logto_configs" using primary key columns"""
  logto_configs_by_pk(key: String!, tenant_id: String!): logto_configs

  """
  fetch data from the table in a streaming manner: "logto_configs"
  """
  logto_configs_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [logto_configs_stream_cursor_input]!

    """filter the rows returned"""
    where: logto_configs_bool_exp
  ): [logto_configs!]!

  """
  fetch data from the table: "medical_examination_records"
  """
  medical_examination_records(
    """distinct select on columns"""
    distinct_on: [medical_examination_records_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [medical_examination_records_order_by!]

    """filter the rows returned"""
    where: medical_examination_records_bool_exp
  ): [medical_examination_records!]!

  """
  fetch aggregated fields from the table: "medical_examination_records"
  """
  medical_examination_records_aggregate(
    """distinct select on columns"""
    distinct_on: [medical_examination_records_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [medical_examination_records_order_by!]

    """filter the rows returned"""
    where: medical_examination_records_bool_exp
  ): medical_examination_records_aggregate!

  """
  fetch data from the table: "medical_examination_records" using primary key columns
  """
  medical_examination_records_by_pk(id: uuid!): medical_examination_records

  """
  fetch data from the table in a streaming manner: "medical_examination_records"
  """
  medical_examination_records_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [medical_examination_records_stream_cursor_input]!

    """filter the rows returned"""
    where: medical_examination_records_bool_exp
  ): [medical_examination_records!]!

  """
  fetch data from the table: "medication_reminders"
  """
  medication_reminders(
    """distinct select on columns"""
    distinct_on: [medication_reminders_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [medication_reminders_order_by!]

    """filter the rows returned"""
    where: medication_reminders_bool_exp
  ): [medication_reminders!]!

  """
  fetch aggregated fields from the table: "medication_reminders"
  """
  medication_reminders_aggregate(
    """distinct select on columns"""
    distinct_on: [medication_reminders_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [medication_reminders_order_by!]

    """filter the rows returned"""
    where: medication_reminders_bool_exp
  ): medication_reminders_aggregate!

  """
  fetch data from the table: "medication_reminders" using primary key columns
  """
  medication_reminders_by_pk(id: uuid!): medication_reminders

  """
  fetch data from the table in a streaming manner: "medication_reminders"
  """
  medication_reminders_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [medication_reminders_stream_cursor_input]!

    """filter the rows returned"""
    where: medication_reminders_bool_exp
  ): [medication_reminders!]!

  """
  fetch data from the table: "oidc_model_instances"
  """
  oidc_model_instances(
    """distinct select on columns"""
    distinct_on: [oidc_model_instances_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [oidc_model_instances_order_by!]

    """filter the rows returned"""
    where: oidc_model_instances_bool_exp
  ): [oidc_model_instances!]!

  """
  fetch aggregated fields from the table: "oidc_model_instances"
  """
  oidc_model_instances_aggregate(
    """distinct select on columns"""
    distinct_on: [oidc_model_instances_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [oidc_model_instances_order_by!]

    """filter the rows returned"""
    where: oidc_model_instances_bool_exp
  ): oidc_model_instances_aggregate!

  """
  fetch data from the table: "oidc_model_instances" using primary key columns
  """
  oidc_model_instances_by_pk(id: String!): oidc_model_instances

  """
  fetch data from the table in a streaming manner: "oidc_model_instances"
  """
  oidc_model_instances_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [oidc_model_instances_stream_cursor_input]!

    """filter the rows returned"""
    where: oidc_model_instances_bool_exp
  ): [oidc_model_instances!]!

  """
  fetch data from the table: "organization_invitation_role_relations"
  """
  organization_invitation_role_relations(
    """distinct select on columns"""
    distinct_on: [organization_invitation_role_relations_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [organization_invitation_role_relations_order_by!]

    """filter the rows returned"""
    where: organization_invitation_role_relations_bool_exp
  ): [organization_invitation_role_relations!]!

  """
  fetch aggregated fields from the table: "organization_invitation_role_relations"
  """
  organization_invitation_role_relations_aggregate(
    """distinct select on columns"""
    distinct_on: [organization_invitation_role_relations_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [organization_invitation_role_relations_order_by!]

    """filter the rows returned"""
    where: organization_invitation_role_relations_bool_exp
  ): organization_invitation_role_relations_aggregate!

  """
  fetch data from the table: "organization_invitation_role_relations" using primary key columns
  """
  organization_invitation_role_relations_by_pk(organization_invitation_id: String!, organization_role_id: String!, tenant_id: String!): organization_invitation_role_relations

  """
  fetch data from the table in a streaming manner: "organization_invitation_role_relations"
  """
  organization_invitation_role_relations_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [organization_invitation_role_relations_stream_cursor_input]!

    """filter the rows returned"""
    where: organization_invitation_role_relations_bool_exp
  ): [organization_invitation_role_relations!]!

  """
  fetch data from the table: "organization_invitations"
  """
  organization_invitations(
    """distinct select on columns"""
    distinct_on: [organization_invitations_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [organization_invitations_order_by!]

    """filter the rows returned"""
    where: organization_invitations_bool_exp
  ): [organization_invitations!]!

  """
  fetch aggregated fields from the table: "organization_invitations"
  """
  organization_invitations_aggregate(
    """distinct select on columns"""
    distinct_on: [organization_invitations_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [organization_invitations_order_by!]

    """filter the rows returned"""
    where: organization_invitations_bool_exp
  ): organization_invitations_aggregate!

  """
  fetch data from the table: "organization_invitations" using primary key columns
  """
  organization_invitations_by_pk(id: String!): organization_invitations

  """
  fetch data from the table in a streaming manner: "organization_invitations"
  """
  organization_invitations_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [organization_invitations_stream_cursor_input]!

    """filter the rows returned"""
    where: organization_invitations_bool_exp
  ): [organization_invitations!]!

  """
  fetch data from the table: "organization_role_scope_relations"
  """
  organization_role_scope_relations(
    """distinct select on columns"""
    distinct_on: [organization_role_scope_relations_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [organization_role_scope_relations_order_by!]

    """filter the rows returned"""
    where: organization_role_scope_relations_bool_exp
  ): [organization_role_scope_relations!]!

  """
  fetch aggregated fields from the table: "organization_role_scope_relations"
  """
  organization_role_scope_relations_aggregate(
    """distinct select on columns"""
    distinct_on: [organization_role_scope_relations_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [organization_role_scope_relations_order_by!]

    """filter the rows returned"""
    where: organization_role_scope_relations_bool_exp
  ): organization_role_scope_relations_aggregate!

  """
  fetch data from the table: "organization_role_scope_relations" using primary key columns
  """
  organization_role_scope_relations_by_pk(organization_role_id: String!, organization_scope_id: String!, tenant_id: String!): organization_role_scope_relations

  """
  fetch data from the table in a streaming manner: "organization_role_scope_relations"
  """
  organization_role_scope_relations_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [organization_role_scope_relations_stream_cursor_input]!

    """filter the rows returned"""
    where: organization_role_scope_relations_bool_exp
  ): [organization_role_scope_relations!]!

  """
  fetch data from the table: "organization_role_user_relations"
  """
  organization_role_user_relations(
    """distinct select on columns"""
    distinct_on: [organization_role_user_relations_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [organization_role_user_relations_order_by!]

    """filter the rows returned"""
    where: organization_role_user_relations_bool_exp
  ): [organization_role_user_relations!]!

  """
  fetch aggregated fields from the table: "organization_role_user_relations"
  """
  organization_role_user_relations_aggregate(
    """distinct select on columns"""
    distinct_on: [organization_role_user_relations_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [organization_role_user_relations_order_by!]

    """filter the rows returned"""
    where: organization_role_user_relations_bool_exp
  ): organization_role_user_relations_aggregate!

  """
  fetch data from the table: "organization_role_user_relations" using primary key columns
  """
  organization_role_user_relations_by_pk(organization_id: String!, organization_role_id: String!, tenant_id: String!, user_id: String!): organization_role_user_relations

  """
  fetch data from the table in a streaming manner: "organization_role_user_relations"
  """
  organization_role_user_relations_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [organization_role_user_relations_stream_cursor_input]!

    """filter the rows returned"""
    where: organization_role_user_relations_bool_exp
  ): [organization_role_user_relations!]!

  """
  fetch data from the table: "organization_roles"
  """
  organization_roles(
    """distinct select on columns"""
    distinct_on: [organization_roles_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [organization_roles_order_by!]

    """filter the rows returned"""
    where: organization_roles_bool_exp
  ): [organization_roles!]!

  """
  fetch aggregated fields from the table: "organization_roles"
  """
  organization_roles_aggregate(
    """distinct select on columns"""
    distinct_on: [organization_roles_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [organization_roles_order_by!]

    """filter the rows returned"""
    where: organization_roles_bool_exp
  ): organization_roles_aggregate!

  """
  fetch data from the table: "organization_roles" using primary key columns
  """
  organization_roles_by_pk(id: String!): organization_roles

  """
  fetch data from the table in a streaming manner: "organization_roles"
  """
  organization_roles_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [organization_roles_stream_cursor_input]!

    """filter the rows returned"""
    where: organization_roles_bool_exp
  ): [organization_roles!]!

  """
  fetch data from the table: "organization_scopes"
  """
  organization_scopes(
    """distinct select on columns"""
    distinct_on: [organization_scopes_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [organization_scopes_order_by!]

    """filter the rows returned"""
    where: organization_scopes_bool_exp
  ): [organization_scopes!]!

  """
  fetch aggregated fields from the table: "organization_scopes"
  """
  organization_scopes_aggregate(
    """distinct select on columns"""
    distinct_on: [organization_scopes_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [organization_scopes_order_by!]

    """filter the rows returned"""
    where: organization_scopes_bool_exp
  ): organization_scopes_aggregate!

  """
  fetch data from the table: "organization_scopes" using primary key columns
  """
  organization_scopes_by_pk(id: String!): organization_scopes

  """
  fetch data from the table in a streaming manner: "organization_scopes"
  """
  organization_scopes_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [organization_scopes_stream_cursor_input]!

    """filter the rows returned"""
    where: organization_scopes_bool_exp
  ): [organization_scopes!]!

  """
  fetch data from the table: "organization_user_relations"
  """
  organization_user_relations(
    """distinct select on columns"""
    distinct_on: [organization_user_relations_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [organization_user_relations_order_by!]

    """filter the rows returned"""
    where: organization_user_relations_bool_exp
  ): [organization_user_relations!]!

  """
  fetch aggregated fields from the table: "organization_user_relations"
  """
  organization_user_relations_aggregate(
    """distinct select on columns"""
    distinct_on: [organization_user_relations_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [organization_user_relations_order_by!]

    """filter the rows returned"""
    where: organization_user_relations_bool_exp
  ): organization_user_relations_aggregate!

  """
  fetch data from the table: "organization_user_relations" using primary key columns
  """
  organization_user_relations_by_pk(organization_id: String!, tenant_id: String!, user_id: String!): organization_user_relations

  """
  fetch data from the table in a streaming manner: "organization_user_relations"
  """
  organization_user_relations_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [organization_user_relations_stream_cursor_input]!

    """filter the rows returned"""
    where: organization_user_relations_bool_exp
  ): [organization_user_relations!]!

  """
  fetch data from the table: "organizations"
  """
  organizations(
    """distinct select on columns"""
    distinct_on: [organizations_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [organizations_order_by!]

    """filter the rows returned"""
    where: organizations_bool_exp
  ): [organizations!]!

  """
  fetch aggregated fields from the table: "organizations"
  """
  organizations_aggregate(
    """distinct select on columns"""
    distinct_on: [organizations_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [organizations_order_by!]

    """filter the rows returned"""
    where: organizations_bool_exp
  ): organizations_aggregate!

  """fetch data from the table: "organizations" using primary key columns"""
  organizations_by_pk(id: String!): organizations

  """
  fetch data from the table in a streaming manner: "organizations"
  """
  organizations_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [organizations_stream_cursor_input]!

    """filter the rows returned"""
    where: organizations_bool_exp
  ): [organizations!]!

  """
  fetch data from the table: "passcodes"
  """
  passcodes(
    """distinct select on columns"""
    distinct_on: [passcodes_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [passcodes_order_by!]

    """filter the rows returned"""
    where: passcodes_bool_exp
  ): [passcodes!]!

  """
  fetch aggregated fields from the table: "passcodes"
  """
  passcodes_aggregate(
    """distinct select on columns"""
    distinct_on: [passcodes_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [passcodes_order_by!]

    """filter the rows returned"""
    where: passcodes_bool_exp
  ): passcodes_aggregate!

  """fetch data from the table: "passcodes" using primary key columns"""
  passcodes_by_pk(id: String!): passcodes

  """
  fetch data from the table in a streaming manner: "passcodes"
  """
  passcodes_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [passcodes_stream_cursor_input]!

    """filter the rows returned"""
    where: passcodes_bool_exp
  ): [passcodes!]!

  """
  fetch data from the table: "pg_buffercache"
  """
  pg_buffercache(
    """distinct select on columns"""
    distinct_on: [pg_buffercache_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [pg_buffercache_order_by!]

    """filter the rows returned"""
    where: pg_buffercache_bool_exp
  ): [pg_buffercache!]!

  """
  fetch aggregated fields from the table: "pg_buffercache"
  """
  pg_buffercache_aggregate(
    """distinct select on columns"""
    distinct_on: [pg_buffercache_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [pg_buffercache_order_by!]

    """filter the rows returned"""
    where: pg_buffercache_bool_exp
  ): pg_buffercache_aggregate!

  """
  fetch data from the table in a streaming manner: "pg_buffercache"
  """
  pg_buffercache_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [pg_buffercache_stream_cursor_input]!

    """filter the rows returned"""
    where: pg_buffercache_bool_exp
  ): [pg_buffercache!]!

  """
  fetch data from the table: "pg_stat_statements"
  """
  pg_stat_statements(
    """distinct select on columns"""
    distinct_on: [pg_stat_statements_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [pg_stat_statements_order_by!]

    """filter the rows returned"""
    where: pg_stat_statements_bool_exp
  ): [pg_stat_statements!]!

  """
  fetch aggregated fields from the table: "pg_stat_statements"
  """
  pg_stat_statements_aggregate(
    """distinct select on columns"""
    distinct_on: [pg_stat_statements_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [pg_stat_statements_order_by!]

    """filter the rows returned"""
    where: pg_stat_statements_bool_exp
  ): pg_stat_statements_aggregate!

  """
  fetch data from the table: "pg_stat_statements_info"
  """
  pg_stat_statements_info(
    """distinct select on columns"""
    distinct_on: [pg_stat_statements_info_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [pg_stat_statements_info_order_by!]

    """filter the rows returned"""
    where: pg_stat_statements_info_bool_exp
  ): [pg_stat_statements_info!]!

  """
  fetch aggregated fields from the table: "pg_stat_statements_info"
  """
  pg_stat_statements_info_aggregate(
    """distinct select on columns"""
    distinct_on: [pg_stat_statements_info_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [pg_stat_statements_info_order_by!]

    """filter the rows returned"""
    where: pg_stat_statements_info_bool_exp
  ): pg_stat_statements_info_aggregate!

  """
  fetch data from the table in a streaming manner: "pg_stat_statements_info"
  """
  pg_stat_statements_info_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [pg_stat_statements_info_stream_cursor_input]!

    """filter the rows returned"""
    where: pg_stat_statements_info_bool_exp
  ): [pg_stat_statements_info!]!

  """
  fetch data from the table in a streaming manner: "pg_stat_statements"
  """
  pg_stat_statements_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [pg_stat_statements_stream_cursor_input]!

    """filter the rows returned"""
    where: pg_stat_statements_bool_exp
  ): [pg_stat_statements!]!

  """
  fetch data from the table: "resources"
  """
  resources(
    """distinct select on columns"""
    distinct_on: [resources_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [resources_order_by!]

    """filter the rows returned"""
    where: resources_bool_exp
  ): [resources!]!

  """
  fetch aggregated fields from the table: "resources"
  """
  resources_aggregate(
    """distinct select on columns"""
    distinct_on: [resources_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [resources_order_by!]

    """filter the rows returned"""
    where: resources_bool_exp
  ): resources_aggregate!

  """fetch data from the table: "resources" using primary key columns"""
  resources_by_pk(id: String!): resources

  """
  fetch data from the table in a streaming manner: "resources"
  """
  resources_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [resources_stream_cursor_input]!

    """filter the rows returned"""
    where: resources_bool_exp
  ): [resources!]!

  """
  fetch data from the table: "roles"
  """
  roles(
    """distinct select on columns"""
    distinct_on: [roles_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [roles_order_by!]

    """filter the rows returned"""
    where: roles_bool_exp
  ): [roles!]!

  """
  fetch aggregated fields from the table: "roles"
  """
  roles_aggregate(
    """distinct select on columns"""
    distinct_on: [roles_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [roles_order_by!]

    """filter the rows returned"""
    where: roles_bool_exp
  ): roles_aggregate!

  """fetch data from the table: "roles" using primary key columns"""
  roles_by_pk(id: String!): roles

  """
  fetch data from the table: "roles_scopes"
  """
  roles_scopes(
    """distinct select on columns"""
    distinct_on: [roles_scopes_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [roles_scopes_order_by!]

    """filter the rows returned"""
    where: roles_scopes_bool_exp
  ): [roles_scopes!]!

  """
  fetch aggregated fields from the table: "roles_scopes"
  """
  roles_scopes_aggregate(
    """distinct select on columns"""
    distinct_on: [roles_scopes_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [roles_scopes_order_by!]

    """filter the rows returned"""
    where: roles_scopes_bool_exp
  ): roles_scopes_aggregate!

  """fetch data from the table: "roles_scopes" using primary key columns"""
  roles_scopes_by_pk(id: String!): roles_scopes

  """
  fetch data from the table in a streaming manner: "roles_scopes"
  """
  roles_scopes_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [roles_scopes_stream_cursor_input]!

    """filter the rows returned"""
    where: roles_scopes_bool_exp
  ): [roles_scopes!]!

  """
  fetch data from the table in a streaming manner: "roles"
  """
  roles_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [roles_stream_cursor_input]!

    """filter the rows returned"""
    where: roles_bool_exp
  ): [roles!]!

  """
  fetch data from the table: "scopes"
  """
  scopes(
    """distinct select on columns"""
    distinct_on: [scopes_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [scopes_order_by!]

    """filter the rows returned"""
    where: scopes_bool_exp
  ): [scopes!]!

  """
  fetch aggregated fields from the table: "scopes"
  """
  scopes_aggregate(
    """distinct select on columns"""
    distinct_on: [scopes_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [scopes_order_by!]

    """filter the rows returned"""
    where: scopes_bool_exp
  ): scopes_aggregate!

  """fetch data from the table: "scopes" using primary key columns"""
  scopes_by_pk(id: String!): scopes

  """
  fetch data from the table in a streaming manner: "scopes"
  """
  scopes_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [scopes_stream_cursor_input]!

    """filter the rows returned"""
    where: scopes_bool_exp
  ): [scopes!]!

  """
  fetch data from the table: "sentinel_activities"
  """
  sentinel_activities(
    """distinct select on columns"""
    distinct_on: [sentinel_activities_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [sentinel_activities_order_by!]

    """filter the rows returned"""
    where: sentinel_activities_bool_exp
  ): [sentinel_activities!]!

  """
  fetch aggregated fields from the table: "sentinel_activities"
  """
  sentinel_activities_aggregate(
    """distinct select on columns"""
    distinct_on: [sentinel_activities_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [sentinel_activities_order_by!]

    """filter the rows returned"""
    where: sentinel_activities_bool_exp
  ): sentinel_activities_aggregate!

  """
  fetch data from the table: "sentinel_activities" using primary key columns
  """
  sentinel_activities_by_pk(id: String!): sentinel_activities

  """
  fetch data from the table in a streaming manner: "sentinel_activities"
  """
  sentinel_activities_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [sentinel_activities_stream_cursor_input]!

    """filter the rows returned"""
    where: sentinel_activities_bool_exp
  ): [sentinel_activities!]!

  """
  fetch data from the table: "service_logs"
  """
  service_logs(
    """distinct select on columns"""
    distinct_on: [service_logs_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [service_logs_order_by!]

    """filter the rows returned"""
    where: service_logs_bool_exp
  ): [service_logs!]!

  """
  fetch aggregated fields from the table: "service_logs"
  """
  service_logs_aggregate(
    """distinct select on columns"""
    distinct_on: [service_logs_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [service_logs_order_by!]

    """filter the rows returned"""
    where: service_logs_bool_exp
  ): service_logs_aggregate!

  """fetch data from the table: "service_logs" using primary key columns"""
  service_logs_by_pk(id: String!): service_logs

  """
  fetch data from the table in a streaming manner: "service_logs"
  """
  service_logs_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [service_logs_stream_cursor_input]!

    """filter the rows returned"""
    where: service_logs_bool_exp
  ): [service_logs!]!

  """
  fetch data from the table: "sign_in_experiences"
  """
  sign_in_experiences(
    """distinct select on columns"""
    distinct_on: [sign_in_experiences_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [sign_in_experiences_order_by!]

    """filter the rows returned"""
    where: sign_in_experiences_bool_exp
  ): [sign_in_experiences!]!

  """
  fetch aggregated fields from the table: "sign_in_experiences"
  """
  sign_in_experiences_aggregate(
    """distinct select on columns"""
    distinct_on: [sign_in_experiences_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [sign_in_experiences_order_by!]

    """filter the rows returned"""
    where: sign_in_experiences_bool_exp
  ): sign_in_experiences_aggregate!

  """
  fetch data from the table: "sign_in_experiences" using primary key columns
  """
  sign_in_experiences_by_pk(id: String!, tenant_id: String!): sign_in_experiences

  """
  fetch data from the table in a streaming manner: "sign_in_experiences"
  """
  sign_in_experiences_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [sign_in_experiences_stream_cursor_input]!

    """filter the rows returned"""
    where: sign_in_experiences_bool_exp
  ): [sign_in_experiences!]!

  """
  fetch data from the table: "sms_codes"
  """
  sms_codes(
    """distinct select on columns"""
    distinct_on: [sms_codes_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [sms_codes_order_by!]

    """filter the rows returned"""
    where: sms_codes_bool_exp
  ): [sms_codes!]!

  """
  fetch aggregated fields from the table: "sms_codes"
  """
  sms_codes_aggregate(
    """distinct select on columns"""
    distinct_on: [sms_codes_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [sms_codes_order_by!]

    """filter the rows returned"""
    where: sms_codes_bool_exp
  ): sms_codes_aggregate!

  """fetch data from the table: "sms_codes" using primary key columns"""
  sms_codes_by_pk(id: uuid!): sms_codes

  """
  fetch data from the table in a streaming manner: "sms_codes"
  """
  sms_codes_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [sms_codes_stream_cursor_input]!

    """filter the rows returned"""
    where: sms_codes_bool_exp
  ): [sms_codes!]!

  """
  fetch data from the table: "sso_connectors"
  """
  sso_connectors(
    """distinct select on columns"""
    distinct_on: [sso_connectors_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [sso_connectors_order_by!]

    """filter the rows returned"""
    where: sso_connectors_bool_exp
  ): [sso_connectors!]!

  """
  fetch aggregated fields from the table: "sso_connectors"
  """
  sso_connectors_aggregate(
    """distinct select on columns"""
    distinct_on: [sso_connectors_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [sso_connectors_order_by!]

    """filter the rows returned"""
    where: sso_connectors_bool_exp
  ): sso_connectors_aggregate!

  """fetch data from the table: "sso_connectors" using primary key columns"""
  sso_connectors_by_pk(id: String!): sso_connectors

  """
  fetch data from the table in a streaming manner: "sso_connectors"
  """
  sso_connectors_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [sso_connectors_stream_cursor_input]!

    """filter the rows returned"""
    where: sso_connectors_bool_exp
  ): [sso_connectors!]!

  """
  fetch data from the table: "systems"
  """
  systems(
    """distinct select on columns"""
    distinct_on: [systems_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [systems_order_by!]

    """filter the rows returned"""
    where: systems_bool_exp
  ): [systems!]!

  """
  fetch aggregated fields from the table: "systems"
  """
  systems_aggregate(
    """distinct select on columns"""
    distinct_on: [systems_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [systems_order_by!]

    """filter the rows returned"""
    where: systems_bool_exp
  ): systems_aggregate!

  """fetch data from the table: "systems" using primary key columns"""
  systems_by_pk(key: String!): systems

  """
  fetch data from the table in a streaming manner: "systems"
  """
  systems_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [systems_stream_cursor_input]!

    """filter the rows returned"""
    where: systems_bool_exp
  ): [systems!]!

  """
  fetch data from the table: "tenants"
  """
  tenants(
    """distinct select on columns"""
    distinct_on: [tenants_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [tenants_order_by!]

    """filter the rows returned"""
    where: tenants_bool_exp
  ): [tenants!]!

  """
  fetch aggregated fields from the table: "tenants"
  """
  tenants_aggregate(
    """distinct select on columns"""
    distinct_on: [tenants_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [tenants_order_by!]

    """filter the rows returned"""
    where: tenants_bool_exp
  ): tenants_aggregate!

  """fetch data from the table: "tenants" using primary key columns"""
  tenants_by_pk(id: String!): tenants

  """
  fetch data from the table in a streaming manner: "tenants"
  """
  tenants_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [tenants_stream_cursor_input]!

    """filter the rows returned"""
    where: tenants_bool_exp
  ): [tenants!]!

  """
  fetch data from the table: "user_cholesterol_standards"
  """
  user_cholesterol_standards(
    """distinct select on columns"""
    distinct_on: [user_cholesterol_standards_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [user_cholesterol_standards_order_by!]

    """filter the rows returned"""
    where: user_cholesterol_standards_bool_exp
  ): [user_cholesterol_standards!]!

  """
  fetch aggregated fields from the table: "user_cholesterol_standards"
  """
  user_cholesterol_standards_aggregate(
    """distinct select on columns"""
    distinct_on: [user_cholesterol_standards_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [user_cholesterol_standards_order_by!]

    """filter the rows returned"""
    where: user_cholesterol_standards_bool_exp
  ): user_cholesterol_standards_aggregate!

  """
  fetch data from the table: "user_cholesterol_standards" using primary key columns
  """
  user_cholesterol_standards_by_pk(id: uuid!): user_cholesterol_standards

  """
  fetch data from the table in a streaming manner: "user_cholesterol_standards"
  """
  user_cholesterol_standards_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [user_cholesterol_standards_stream_cursor_input]!

    """filter the rows returned"""
    where: user_cholesterol_standards_bool_exp
  ): [user_cholesterol_standards!]!

  """
  fetch data from the table: "user_glucose_standards"
  """
  user_glucose_standards(
    """distinct select on columns"""
    distinct_on: [user_glucose_standards_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [user_glucose_standards_order_by!]

    """filter the rows returned"""
    where: user_glucose_standards_bool_exp
  ): [user_glucose_standards!]!

  """
  fetch aggregated fields from the table: "user_glucose_standards"
  """
  user_glucose_standards_aggregate(
    """distinct select on columns"""
    distinct_on: [user_glucose_standards_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [user_glucose_standards_order_by!]

    """filter the rows returned"""
    where: user_glucose_standards_bool_exp
  ): user_glucose_standards_aggregate!

  """
  fetch data from the table: "user_glucose_standards" using primary key columns
  """
  user_glucose_standards_by_pk(id: uuid!): user_glucose_standards

  """
  fetch data from the table in a streaming manner: "user_glucose_standards"
  """
  user_glucose_standards_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [user_glucose_standards_stream_cursor_input]!

    """filter the rows returned"""
    where: user_glucose_standards_bool_exp
  ): [user_glucose_standards!]!

  """
  fetch data from the table: "user_sso_identities"
  """
  user_sso_identities(
    """distinct select on columns"""
    distinct_on: [user_sso_identities_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [user_sso_identities_order_by!]

    """filter the rows returned"""
    where: user_sso_identities_bool_exp
  ): [user_sso_identities!]!

  """
  fetch aggregated fields from the table: "user_sso_identities"
  """
  user_sso_identities_aggregate(
    """distinct select on columns"""
    distinct_on: [user_sso_identities_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [user_sso_identities_order_by!]

    """filter the rows returned"""
    where: user_sso_identities_bool_exp
  ): user_sso_identities_aggregate!

  """
  fetch data from the table: "user_sso_identities" using primary key columns
  """
  user_sso_identities_by_pk(id: String!): user_sso_identities

  """
  fetch data from the table in a streaming manner: "user_sso_identities"
  """
  user_sso_identities_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [user_sso_identities_stream_cursor_input]!

    """filter the rows returned"""
    where: user_sso_identities_bool_exp
  ): [user_sso_identities!]!

  """
  fetch data from the table: "users"
  """
  users(
    """distinct select on columns"""
    distinct_on: [users_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [users_order_by!]

    """filter the rows returned"""
    where: users_bool_exp
  ): [users!]!

  """
  fetch aggregated fields from the table: "users"
  """
  users_aggregate(
    """distinct select on columns"""
    distinct_on: [users_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [users_order_by!]

    """filter the rows returned"""
    where: users_bool_exp
  ): users_aggregate!

  """fetch data from the table: "users" using primary key columns"""
  users_by_pk(id: String!): users

  """An array relationship"""
  users_roles(
    """distinct select on columns"""
    distinct_on: [users_roles_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [users_roles_order_by!]

    """filter the rows returned"""
    where: users_roles_bool_exp
  ): [users_roles!]!

  """An aggregate relationship"""
  users_roles_aggregate(
    """distinct select on columns"""
    distinct_on: [users_roles_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [users_roles_order_by!]

    """filter the rows returned"""
    where: users_roles_bool_exp
  ): users_roles_aggregate!

  """fetch data from the table: "users_roles" using primary key columns"""
  users_roles_by_pk(id: String!): users_roles

  """
  fetch data from the table in a streaming manner: "users_roles"
  """
  users_roles_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [users_roles_stream_cursor_input]!

    """filter the rows returned"""
    where: users_roles_bool_exp
  ): [users_roles!]!

  """
  fetch data from the table in a streaming manner: "users"
  """
  users_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [users_stream_cursor_input]!

    """filter the rows returned"""
    where: users_bool_exp
  ): [users!]!

  """
  fetch data from the table: "verification_statuses"
  """
  verification_statuses(
    """distinct select on columns"""
    distinct_on: [verification_statuses_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [verification_statuses_order_by!]

    """filter the rows returned"""
    where: verification_statuses_bool_exp
  ): [verification_statuses!]!

  """
  fetch aggregated fields from the table: "verification_statuses"
  """
  verification_statuses_aggregate(
    """distinct select on columns"""
    distinct_on: [verification_statuses_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [verification_statuses_order_by!]

    """filter the rows returned"""
    where: verification_statuses_bool_exp
  ): verification_statuses_aggregate!

  """
  fetch data from the table: "verification_statuses" using primary key columns
  """
  verification_statuses_by_pk(id: String!): verification_statuses

  """
  fetch data from the table in a streaming manner: "verification_statuses"
  """
  verification_statuses_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [verification_statuses_stream_cursor_input]!

    """filter the rows returned"""
    where: verification_statuses_bool_exp
  ): [verification_statuses!]!
}

"""
columns and relationships of "systems"
"""
type systems {
  key: String!
  value(
    """JSON select path"""
    path: String
  ): jsonb!
}

"""
aggregated selection of "systems"
"""
type systems_aggregate {
  aggregate: systems_aggregate_fields
  nodes: [systems!]!
}

"""
aggregate fields of "systems"
"""
type systems_aggregate_fields {
  count(columns: [systems_select_column!], distinct: Boolean): Int!
  max: systems_max_fields
  min: systems_min_fields
}

"""append existing jsonb value of filtered columns with new jsonb value"""
input systems_append_input {
  value: jsonb
}

"""
Boolean expression to filter rows from the table "systems". All fields are combined with a logical 'AND'.
"""
input systems_bool_exp {
  _and: [systems_bool_exp!]
  _not: systems_bool_exp
  _or: [systems_bool_exp!]
  key: String_comparison_exp
  value: jsonb_comparison_exp
}

"""
unique or primary key constraints on table "systems"
"""
enum systems_constraint {
  """
  unique or primary key constraint on columns "key"
  """
  systems_pkey
}

"""
delete the field or element with specified path (for JSON arrays, negative integers count from the end)
"""
input systems_delete_at_path_input {
  value: [String!]
}

"""
delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
"""
input systems_delete_elem_input {
  value: Int
}

"""
delete key/value pair or string element. key/value pairs are matched based on their key value
"""
input systems_delete_key_input {
  value: String
}

"""
input type for inserting data into table "systems"
"""
input systems_insert_input {
  key: String
  value: jsonb
}

"""aggregate max on columns"""
type systems_max_fields {
  key: String
}

"""aggregate min on columns"""
type systems_min_fields {
  key: String
}

"""
response of any mutation on the table "systems"
"""
type systems_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [systems!]!
}

"""
on_conflict condition type for table "systems"
"""
input systems_on_conflict {
  constraint: systems_constraint!
  update_columns: [systems_update_column!]! = []
  where: systems_bool_exp
}

"""Ordering options when selecting data from "systems"."""
input systems_order_by {
  key: order_by
  value: order_by
}

"""primary key columns input for table: systems"""
input systems_pk_columns_input {
  key: String!
}

"""prepend existing jsonb value of filtered columns with new jsonb value"""
input systems_prepend_input {
  value: jsonb
}

"""
select columns of table "systems"
"""
enum systems_select_column {
  """column name"""
  key

  """column name"""
  value
}

"""
input type for updating data in table "systems"
"""
input systems_set_input {
  key: String
  value: jsonb
}

"""
Streaming cursor of the table "systems"
"""
input systems_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: systems_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input systems_stream_cursor_value_input {
  key: String
  value: jsonb
}

"""
update columns of table "systems"
"""
enum systems_update_column {
  """column name"""
  key

  """column name"""
  value
}

input systems_updates {
  """append existing jsonb value of filtered columns with new jsonb value"""
  _append: systems_append_input

  """
  delete the field or element with specified path (for JSON arrays, negative integers count from the end)
  """
  _delete_at_path: systems_delete_at_path_input

  """
  delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
  """
  _delete_elem: systems_delete_elem_input

  """
  delete key/value pair or string element. key/value pairs are matched based on their key value
  """
  _delete_key: systems_delete_key_input

  """prepend existing jsonb value of filtered columns with new jsonb value"""
  _prepend: systems_prepend_input

  """sets the columns of the filtered rows to the given values"""
  _set: systems_set_input

  """filter the rows which have to be updated"""
  where: systems_bool_exp!
}

"""
columns and relationships of "tenants"
"""
type tenants {
  created_at: timestamptz!
  db_user: String
  db_user_password: String
  id: String!
  is_suspended: Boolean!
  name: String!
  tag: String!
}

"""
aggregated selection of "tenants"
"""
type tenants_aggregate {
  aggregate: tenants_aggregate_fields
  nodes: [tenants!]!
}

"""
aggregate fields of "tenants"
"""
type tenants_aggregate_fields {
  count(columns: [tenants_select_column!], distinct: Boolean): Int!
  max: tenants_max_fields
  min: tenants_min_fields
}

"""
Boolean expression to filter rows from the table "tenants". All fields are combined with a logical 'AND'.
"""
input tenants_bool_exp {
  _and: [tenants_bool_exp!]
  _not: tenants_bool_exp
  _or: [tenants_bool_exp!]
  created_at: timestamptz_comparison_exp
  db_user: String_comparison_exp
  db_user_password: String_comparison_exp
  id: String_comparison_exp
  is_suspended: Boolean_comparison_exp
  name: String_comparison_exp
  tag: String_comparison_exp
}

"""
unique or primary key constraints on table "tenants"
"""
enum tenants_constraint {
  """
  unique or primary key constraint on columns "db_user"
  """
  tenants__db_user

  """
  unique or primary key constraint on columns "id"
  """
  tenants_pkey
}

"""
input type for inserting data into table "tenants"
"""
input tenants_insert_input {
  created_at: timestamptz
  db_user: String
  db_user_password: String
  id: String
  is_suspended: Boolean
  name: String
  tag: String
}

"""aggregate max on columns"""
type tenants_max_fields {
  created_at: timestamptz
  db_user: String
  db_user_password: String
  id: String
  name: String
  tag: String
}

"""aggregate min on columns"""
type tenants_min_fields {
  created_at: timestamptz
  db_user: String
  db_user_password: String
  id: String
  name: String
  tag: String
}

"""
response of any mutation on the table "tenants"
"""
type tenants_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [tenants!]!
}

"""
on_conflict condition type for table "tenants"
"""
input tenants_on_conflict {
  constraint: tenants_constraint!
  update_columns: [tenants_update_column!]! = []
  where: tenants_bool_exp
}

"""Ordering options when selecting data from "tenants"."""
input tenants_order_by {
  created_at: order_by
  db_user: order_by
  db_user_password: order_by
  id: order_by
  is_suspended: order_by
  name: order_by
  tag: order_by
}

"""primary key columns input for table: tenants"""
input tenants_pk_columns_input {
  id: String!
}

"""
select columns of table "tenants"
"""
enum tenants_select_column {
  """column name"""
  created_at

  """column name"""
  db_user

  """column name"""
  db_user_password

  """column name"""
  id

  """column name"""
  is_suspended

  """column name"""
  name

  """column name"""
  tag
}

"""
input type for updating data in table "tenants"
"""
input tenants_set_input {
  created_at: timestamptz
  db_user: String
  db_user_password: String
  id: String
  is_suspended: Boolean
  name: String
  tag: String
}

"""
Streaming cursor of the table "tenants"
"""
input tenants_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: tenants_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input tenants_stream_cursor_value_input {
  created_at: timestamptz
  db_user: String
  db_user_password: String
  id: String
  is_suspended: Boolean
  name: String
  tag: String
}

"""
update columns of table "tenants"
"""
enum tenants_update_column {
  """column name"""
  created_at

  """column name"""
  db_user

  """column name"""
  db_user_password

  """column name"""
  id

  """column name"""
  is_suspended

  """column name"""
  name

  """column name"""
  tag
}

input tenants_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: tenants_set_input

  """filter the rows which have to be updated"""
  where: tenants_bool_exp!
}

scalar timestamp

"""
Boolean expression to compare columns of type "timestamp". All fields are combined with logical 'AND'.
"""
input timestamp_comparison_exp {
  _eq: timestamp
  _gt: timestamp
  _gte: timestamp
  _in: [timestamp!]
  _is_null: Boolean
  _lt: timestamp
  _lte: timestamp
  _neq: timestamp
  _nin: [timestamp!]
}

scalar timestamptz

"""
Boolean expression to compare columns of type "timestamptz". All fields are combined with logical 'AND'.
"""
input timestamptz_comparison_exp {
  _eq: timestamptz
  _gt: timestamptz
  _gte: timestamptz
  _in: [timestamptz!]
  _is_null: Boolean
  _lt: timestamptz
  _lte: timestamptz
  _neq: timestamptz
  _nin: [timestamptz!]
}

"""用户的血压标准表"""
type user_cholesterol_standards {
  diastolic_pressure: numeric!
  id: uuid!
  systolic_pressure: numeric!
  user_id: String!
}

"""
aggregated selection of "user_cholesterol_standards"
"""
type user_cholesterol_standards_aggregate {
  aggregate: user_cholesterol_standards_aggregate_fields
  nodes: [user_cholesterol_standards!]!
}

"""
aggregate fields of "user_cholesterol_standards"
"""
type user_cholesterol_standards_aggregate_fields {
  avg: user_cholesterol_standards_avg_fields
  count(columns: [user_cholesterol_standards_select_column!], distinct: Boolean): Int!
  max: user_cholesterol_standards_max_fields
  min: user_cholesterol_standards_min_fields
  stddev: user_cholesterol_standards_stddev_fields
  stddev_pop: user_cholesterol_standards_stddev_pop_fields
  stddev_samp: user_cholesterol_standards_stddev_samp_fields
  sum: user_cholesterol_standards_sum_fields
  var_pop: user_cholesterol_standards_var_pop_fields
  var_samp: user_cholesterol_standards_var_samp_fields
  variance: user_cholesterol_standards_variance_fields
}

"""aggregate avg on columns"""
type user_cholesterol_standards_avg_fields {
  diastolic_pressure: Float
  systolic_pressure: Float
}

"""
Boolean expression to filter rows from the table "user_cholesterol_standards". All fields are combined with a logical 'AND'.
"""
input user_cholesterol_standards_bool_exp {
  _and: [user_cholesterol_standards_bool_exp!]
  _not: user_cholesterol_standards_bool_exp
  _or: [user_cholesterol_standards_bool_exp!]
  diastolic_pressure: numeric_comparison_exp
  id: uuid_comparison_exp
  systolic_pressure: numeric_comparison_exp
  user_id: String_comparison_exp
}

"""
unique or primary key constraints on table "user_cholesterol_standards"
"""
enum user_cholesterol_standards_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  user_cholesterol_standards_pkey
}

"""
input type for incrementing numeric columns in table "user_cholesterol_standards"
"""
input user_cholesterol_standards_inc_input {
  diastolic_pressure: numeric
  systolic_pressure: numeric
}

"""
input type for inserting data into table "user_cholesterol_standards"
"""
input user_cholesterol_standards_insert_input {
  diastolic_pressure: numeric
  id: uuid
  systolic_pressure: numeric
  user_id: String
}

"""aggregate max on columns"""
type user_cholesterol_standards_max_fields {
  diastolic_pressure: numeric
  id: uuid
  systolic_pressure: numeric
  user_id: String
}

"""aggregate min on columns"""
type user_cholesterol_standards_min_fields {
  diastolic_pressure: numeric
  id: uuid
  systolic_pressure: numeric
  user_id: String
}

"""
response of any mutation on the table "user_cholesterol_standards"
"""
type user_cholesterol_standards_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [user_cholesterol_standards!]!
}

"""
on_conflict condition type for table "user_cholesterol_standards"
"""
input user_cholesterol_standards_on_conflict {
  constraint: user_cholesterol_standards_constraint!
  update_columns: [user_cholesterol_standards_update_column!]! = []
  where: user_cholesterol_standards_bool_exp
}

"""
Ordering options when selecting data from "user_cholesterol_standards".
"""
input user_cholesterol_standards_order_by {
  diastolic_pressure: order_by
  id: order_by
  systolic_pressure: order_by
  user_id: order_by
}

"""primary key columns input for table: user_cholesterol_standards"""
input user_cholesterol_standards_pk_columns_input {
  id: uuid!
}

"""
select columns of table "user_cholesterol_standards"
"""
enum user_cholesterol_standards_select_column {
  """column name"""
  diastolic_pressure

  """column name"""
  id

  """column name"""
  systolic_pressure

  """column name"""
  user_id
}

"""
input type for updating data in table "user_cholesterol_standards"
"""
input user_cholesterol_standards_set_input {
  diastolic_pressure: numeric
  id: uuid
  systolic_pressure: numeric
  user_id: String
}

"""aggregate stddev on columns"""
type user_cholesterol_standards_stddev_fields {
  diastolic_pressure: Float
  systolic_pressure: Float
}

"""aggregate stddev_pop on columns"""
type user_cholesterol_standards_stddev_pop_fields {
  diastolic_pressure: Float
  systolic_pressure: Float
}

"""aggregate stddev_samp on columns"""
type user_cholesterol_standards_stddev_samp_fields {
  diastolic_pressure: Float
  systolic_pressure: Float
}

"""
Streaming cursor of the table "user_cholesterol_standards"
"""
input user_cholesterol_standards_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: user_cholesterol_standards_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input user_cholesterol_standards_stream_cursor_value_input {
  diastolic_pressure: numeric
  id: uuid
  systolic_pressure: numeric
  user_id: String
}

"""aggregate sum on columns"""
type user_cholesterol_standards_sum_fields {
  diastolic_pressure: numeric
  systolic_pressure: numeric
}

"""
update columns of table "user_cholesterol_standards"
"""
enum user_cholesterol_standards_update_column {
  """column name"""
  diastolic_pressure

  """column name"""
  id

  """column name"""
  systolic_pressure

  """column name"""
  user_id
}

input user_cholesterol_standards_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: user_cholesterol_standards_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: user_cholesterol_standards_set_input

  """filter the rows which have to be updated"""
  where: user_cholesterol_standards_bool_exp!
}

"""aggregate var_pop on columns"""
type user_cholesterol_standards_var_pop_fields {
  diastolic_pressure: Float
  systolic_pressure: Float
}

"""aggregate var_samp on columns"""
type user_cholesterol_standards_var_samp_fields {
  diastolic_pressure: Float
  systolic_pressure: Float
}

"""aggregate variance on columns"""
type user_cholesterol_standards_variance_fields {
  diastolic_pressure: Float
  systolic_pressure: Float
}

"""用户的血糖标准表"""
type user_glucose_standards {
  id: uuid!
  max: numeric!
  min: numeric!
  title: String!
  type: Int!
  user_id: String!
}

"""
aggregated selection of "user_glucose_standards"
"""
type user_glucose_standards_aggregate {
  aggregate: user_glucose_standards_aggregate_fields
  nodes: [user_glucose_standards!]!
}

"""
aggregate fields of "user_glucose_standards"
"""
type user_glucose_standards_aggregate_fields {
  avg: user_glucose_standards_avg_fields
  count(columns: [user_glucose_standards_select_column!], distinct: Boolean): Int!
  max: user_glucose_standards_max_fields
  min: user_glucose_standards_min_fields
  stddev: user_glucose_standards_stddev_fields
  stddev_pop: user_glucose_standards_stddev_pop_fields
  stddev_samp: user_glucose_standards_stddev_samp_fields
  sum: user_glucose_standards_sum_fields
  var_pop: user_glucose_standards_var_pop_fields
  var_samp: user_glucose_standards_var_samp_fields
  variance: user_glucose_standards_variance_fields
}

"""aggregate avg on columns"""
type user_glucose_standards_avg_fields {
  max: Float
  min: Float
  type: Float
}

"""
Boolean expression to filter rows from the table "user_glucose_standards". All fields are combined with a logical 'AND'.
"""
input user_glucose_standards_bool_exp {
  _and: [user_glucose_standards_bool_exp!]
  _not: user_glucose_standards_bool_exp
  _or: [user_glucose_standards_bool_exp!]
  id: uuid_comparison_exp
  max: numeric_comparison_exp
  min: numeric_comparison_exp
  title: String_comparison_exp
  type: Int_comparison_exp
  user_id: String_comparison_exp
}

"""
unique or primary key constraints on table "user_glucose_standards"
"""
enum user_glucose_standards_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  user_glucose_standards_pkey
}

"""
input type for incrementing numeric columns in table "user_glucose_standards"
"""
input user_glucose_standards_inc_input {
  max: numeric
  min: numeric
  type: Int
}

"""
input type for inserting data into table "user_glucose_standards"
"""
input user_glucose_standards_insert_input {
  id: uuid
  max: numeric
  min: numeric
  title: String
  type: Int
  user_id: String
}

"""aggregate max on columns"""
type user_glucose_standards_max_fields {
  id: uuid
  max: numeric
  min: numeric
  title: String
  type: Int
  user_id: String
}

"""aggregate min on columns"""
type user_glucose_standards_min_fields {
  id: uuid
  max: numeric
  min: numeric
  title: String
  type: Int
  user_id: String
}

"""
response of any mutation on the table "user_glucose_standards"
"""
type user_glucose_standards_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [user_glucose_standards!]!
}

"""
on_conflict condition type for table "user_glucose_standards"
"""
input user_glucose_standards_on_conflict {
  constraint: user_glucose_standards_constraint!
  update_columns: [user_glucose_standards_update_column!]! = []
  where: user_glucose_standards_bool_exp
}

"""Ordering options when selecting data from "user_glucose_standards"."""
input user_glucose_standards_order_by {
  id: order_by
  max: order_by
  min: order_by
  title: order_by
  type: order_by
  user_id: order_by
}

"""primary key columns input for table: user_glucose_standards"""
input user_glucose_standards_pk_columns_input {
  id: uuid!
}

"""
select columns of table "user_glucose_standards"
"""
enum user_glucose_standards_select_column {
  """column name"""
  id

  """column name"""
  max

  """column name"""
  min

  """column name"""
  title

  """column name"""
  type

  """column name"""
  user_id
}

"""
input type for updating data in table "user_glucose_standards"
"""
input user_glucose_standards_set_input {
  id: uuid
  max: numeric
  min: numeric
  title: String
  type: Int
  user_id: String
}

"""aggregate stddev on columns"""
type user_glucose_standards_stddev_fields {
  max: Float
  min: Float
  type: Float
}

"""aggregate stddev_pop on columns"""
type user_glucose_standards_stddev_pop_fields {
  max: Float
  min: Float
  type: Float
}

"""aggregate stddev_samp on columns"""
type user_glucose_standards_stddev_samp_fields {
  max: Float
  min: Float
  type: Float
}

"""
Streaming cursor of the table "user_glucose_standards"
"""
input user_glucose_standards_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: user_glucose_standards_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input user_glucose_standards_stream_cursor_value_input {
  id: uuid
  max: numeric
  min: numeric
  title: String
  type: Int
  user_id: String
}

"""aggregate sum on columns"""
type user_glucose_standards_sum_fields {
  max: numeric
  min: numeric
  type: Int
}

"""
update columns of table "user_glucose_standards"
"""
enum user_glucose_standards_update_column {
  """column name"""
  id

  """column name"""
  max

  """column name"""
  min

  """column name"""
  title

  """column name"""
  type

  """column name"""
  user_id
}

input user_glucose_standards_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: user_glucose_standards_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: user_glucose_standards_set_input

  """filter the rows which have to be updated"""
  where: user_glucose_standards_bool_exp!
}

"""aggregate var_pop on columns"""
type user_glucose_standards_var_pop_fields {
  max: Float
  min: Float
  type: Float
}

"""aggregate var_samp on columns"""
type user_glucose_standards_var_samp_fields {
  max: Float
  min: Float
  type: Float
}

"""aggregate variance on columns"""
type user_glucose_standards_variance_fields {
  max: Float
  min: Float
  type: Float
}

"""
columns and relationships of "user_sso_identities"
"""
type user_sso_identities {
  created_at: timestamp!
  detail(
    """JSON select path"""
    path: String
  ): jsonb!
  id: String!
  identity_id: String!
  issuer: String!
  sso_connector_id: String!
  tenant_id: String!
  user_id: String!
}

"""
aggregated selection of "user_sso_identities"
"""
type user_sso_identities_aggregate {
  aggregate: user_sso_identities_aggregate_fields
  nodes: [user_sso_identities!]!
}

"""
aggregate fields of "user_sso_identities"
"""
type user_sso_identities_aggregate_fields {
  count(columns: [user_sso_identities_select_column!], distinct: Boolean): Int!
  max: user_sso_identities_max_fields
  min: user_sso_identities_min_fields
}

"""append existing jsonb value of filtered columns with new jsonb value"""
input user_sso_identities_append_input {
  detail: jsonb
}

"""
Boolean expression to filter rows from the table "user_sso_identities". All fields are combined with a logical 'AND'.
"""
input user_sso_identities_bool_exp {
  _and: [user_sso_identities_bool_exp!]
  _not: user_sso_identities_bool_exp
  _or: [user_sso_identities_bool_exp!]
  created_at: timestamp_comparison_exp
  detail: jsonb_comparison_exp
  id: String_comparison_exp
  identity_id: String_comparison_exp
  issuer: String_comparison_exp
  sso_connector_id: String_comparison_exp
  tenant_id: String_comparison_exp
  user_id: String_comparison_exp
}

"""
unique or primary key constraints on table "user_sso_identities"
"""
enum user_sso_identities_constraint {
  """
  unique or primary key constraint on columns "issuer", "identity_id", "tenant_id"
  """
  user_sso_identities__issuer__identity_id

  """
  unique or primary key constraint on columns "id"
  """
  user_sso_identities_pkey
}

"""
delete the field or element with specified path (for JSON arrays, negative integers count from the end)
"""
input user_sso_identities_delete_at_path_input {
  detail: [String!]
}

"""
delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
"""
input user_sso_identities_delete_elem_input {
  detail: Int
}

"""
delete key/value pair or string element. key/value pairs are matched based on their key value
"""
input user_sso_identities_delete_key_input {
  detail: String
}

"""
input type for inserting data into table "user_sso_identities"
"""
input user_sso_identities_insert_input {
  created_at: timestamp
  detail: jsonb
  id: String
  identity_id: String
  issuer: String
  sso_connector_id: String
  tenant_id: String
  user_id: String
}

"""aggregate max on columns"""
type user_sso_identities_max_fields {
  created_at: timestamp
  id: String
  identity_id: String
  issuer: String
  sso_connector_id: String
  tenant_id: String
  user_id: String
}

"""aggregate min on columns"""
type user_sso_identities_min_fields {
  created_at: timestamp
  id: String
  identity_id: String
  issuer: String
  sso_connector_id: String
  tenant_id: String
  user_id: String
}

"""
response of any mutation on the table "user_sso_identities"
"""
type user_sso_identities_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [user_sso_identities!]!
}

"""
on_conflict condition type for table "user_sso_identities"
"""
input user_sso_identities_on_conflict {
  constraint: user_sso_identities_constraint!
  update_columns: [user_sso_identities_update_column!]! = []
  where: user_sso_identities_bool_exp
}

"""Ordering options when selecting data from "user_sso_identities"."""
input user_sso_identities_order_by {
  created_at: order_by
  detail: order_by
  id: order_by
  identity_id: order_by
  issuer: order_by
  sso_connector_id: order_by
  tenant_id: order_by
  user_id: order_by
}

"""primary key columns input for table: user_sso_identities"""
input user_sso_identities_pk_columns_input {
  id: String!
}

"""prepend existing jsonb value of filtered columns with new jsonb value"""
input user_sso_identities_prepend_input {
  detail: jsonb
}

"""
select columns of table "user_sso_identities"
"""
enum user_sso_identities_select_column {
  """column name"""
  created_at

  """column name"""
  detail

  """column name"""
  id

  """column name"""
  identity_id

  """column name"""
  issuer

  """column name"""
  sso_connector_id

  """column name"""
  tenant_id

  """column name"""
  user_id
}

"""
input type for updating data in table "user_sso_identities"
"""
input user_sso_identities_set_input {
  created_at: timestamp
  detail: jsonb
  id: String
  identity_id: String
  issuer: String
  sso_connector_id: String
  tenant_id: String
  user_id: String
}

"""
Streaming cursor of the table "user_sso_identities"
"""
input user_sso_identities_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: user_sso_identities_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input user_sso_identities_stream_cursor_value_input {
  created_at: timestamp
  detail: jsonb
  id: String
  identity_id: String
  issuer: String
  sso_connector_id: String
  tenant_id: String
  user_id: String
}

"""
update columns of table "user_sso_identities"
"""
enum user_sso_identities_update_column {
  """column name"""
  created_at

  """column name"""
  detail

  """column name"""
  id

  """column name"""
  identity_id

  """column name"""
  issuer

  """column name"""
  sso_connector_id

  """column name"""
  tenant_id

  """column name"""
  user_id
}

input user_sso_identities_updates {
  """append existing jsonb value of filtered columns with new jsonb value"""
  _append: user_sso_identities_append_input

  """
  delete the field or element with specified path (for JSON arrays, negative integers count from the end)
  """
  _delete_at_path: user_sso_identities_delete_at_path_input

  """
  delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
  """
  _delete_elem: user_sso_identities_delete_elem_input

  """
  delete key/value pair or string element. key/value pairs are matched based on their key value
  """
  _delete_key: user_sso_identities_delete_key_input

  """prepend existing jsonb value of filtered columns with new jsonb value"""
  _prepend: user_sso_identities_prepend_input

  """sets the columns of the filtered rows to the given values"""
  _set: user_sso_identities_set_input

  """filter the rows which have to be updated"""
  where: user_sso_identities_bool_exp!
}

"""
columns and relationships of "users"
"""
type users {
  application_id: String
  avatar: String
  created_at: timestamptz!
  custom_data(
    """JSON select path"""
    path: String
  ): jsonb!
  id: String!
  identities(
    """JSON select path"""
    path: String
  ): jsonb!
  is_suspended: Boolean!
  last_sign_in_at: timestamptz
  logto_config(
    """JSON select path"""
    path: String
  ): jsonb!
  mfa_verifications(
    """JSON select path"""
    path: String
  ): jsonb!
  name: String
  password_encrypted: String
  password_encryption_method: users_password_encryption_method
  primary_email: String
  primary_phone: String
  tenant_id: String!
  username: String

  """An array relationship"""
  users_roles(
    """distinct select on columns"""
    distinct_on: [users_roles_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [users_roles_order_by!]

    """filter the rows returned"""
    where: users_roles_bool_exp
  ): [users_roles!]!

  """An aggregate relationship"""
  users_roles_aggregate(
    """distinct select on columns"""
    distinct_on: [users_roles_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [users_roles_order_by!]

    """filter the rows returned"""
    where: users_roles_bool_exp
  ): users_roles_aggregate!
}

"""
aggregated selection of "users"
"""
type users_aggregate {
  aggregate: users_aggregate_fields
  nodes: [users!]!
}

"""
aggregate fields of "users"
"""
type users_aggregate_fields {
  count(columns: [users_select_column!], distinct: Boolean): Int!
  max: users_max_fields
  min: users_min_fields
}

"""append existing jsonb value of filtered columns with new jsonb value"""
input users_append_input {
  custom_data: jsonb
  identities: jsonb
  logto_config: jsonb
  mfa_verifications: jsonb
}

"""
Boolean expression to filter rows from the table "users". All fields are combined with a logical 'AND'.
"""
input users_bool_exp {
  _and: [users_bool_exp!]
  _not: users_bool_exp
  _or: [users_bool_exp!]
  application_id: String_comparison_exp
  avatar: String_comparison_exp
  created_at: timestamptz_comparison_exp
  custom_data: jsonb_comparison_exp
  id: String_comparison_exp
  identities: jsonb_comparison_exp
  is_suspended: Boolean_comparison_exp
  last_sign_in_at: timestamptz_comparison_exp
  logto_config: jsonb_comparison_exp
  mfa_verifications: jsonb_comparison_exp
  name: String_comparison_exp
  password_encrypted: String_comparison_exp
  password_encryption_method: users_password_encryption_method_comparison_exp
  primary_email: String_comparison_exp
  primary_phone: String_comparison_exp
  tenant_id: String_comparison_exp
  username: String_comparison_exp
  users_roles: users_roles_bool_exp
  users_roles_aggregate: users_roles_aggregate_bool_exp
}

"""
unique or primary key constraints on table "users"
"""
enum users_constraint {
  """
  unique or primary key constraint on columns "primary_email", "tenant_id"
  """
  users__primary_email

  """
  unique or primary key constraint on columns "primary_phone", "tenant_id"
  """
  users__primary_phone

  """
  unique or primary key constraint on columns "username", "tenant_id"
  """
  users__username

  """
  unique or primary key constraint on columns "id"
  """
  users_pkey
}

"""
delete the field or element with specified path (for JSON arrays, negative integers count from the end)
"""
input users_delete_at_path_input {
  custom_data: [String!]
  identities: [String!]
  logto_config: [String!]
  mfa_verifications: [String!]
}

"""
delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
"""
input users_delete_elem_input {
  custom_data: Int
  identities: Int
  logto_config: Int
  mfa_verifications: Int
}

"""
delete key/value pair or string element. key/value pairs are matched based on their key value
"""
input users_delete_key_input {
  custom_data: String
  identities: String
  logto_config: String
  mfa_verifications: String
}

"""
input type for inserting data into table "users"
"""
input users_insert_input {
  application_id: String
  avatar: String
  created_at: timestamptz
  custom_data: jsonb
  id: String
  identities: jsonb
  is_suspended: Boolean
  last_sign_in_at: timestamptz
  logto_config: jsonb
  mfa_verifications: jsonb
  name: String
  password_encrypted: String
  password_encryption_method: users_password_encryption_method
  primary_email: String
  primary_phone: String
  tenant_id: String
  username: String
  users_roles: users_roles_arr_rel_insert_input
}

"""aggregate max on columns"""
type users_max_fields {
  application_id: String
  avatar: String
  created_at: timestamptz
  id: String
  last_sign_in_at: timestamptz
  name: String
  password_encrypted: String
  password_encryption_method: users_password_encryption_method
  primary_email: String
  primary_phone: String
  tenant_id: String
  username: String
}

"""aggregate min on columns"""
type users_min_fields {
  application_id: String
  avatar: String
  created_at: timestamptz
  id: String
  last_sign_in_at: timestamptz
  name: String
  password_encrypted: String
  password_encryption_method: users_password_encryption_method
  primary_email: String
  primary_phone: String
  tenant_id: String
  username: String
}

"""
response of any mutation on the table "users"
"""
type users_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [users!]!
}

"""
on_conflict condition type for table "users"
"""
input users_on_conflict {
  constraint: users_constraint!
  update_columns: [users_update_column!]! = []
  where: users_bool_exp
}

"""Ordering options when selecting data from "users"."""
input users_order_by {
  application_id: order_by
  avatar: order_by
  created_at: order_by
  custom_data: order_by
  id: order_by
  identities: order_by
  is_suspended: order_by
  last_sign_in_at: order_by
  logto_config: order_by
  mfa_verifications: order_by
  name: order_by
  password_encrypted: order_by
  password_encryption_method: order_by
  primary_email: order_by
  primary_phone: order_by
  tenant_id: order_by
  username: order_by
  users_roles_aggregate: users_roles_aggregate_order_by
}

scalar users_password_encryption_method

"""
Boolean expression to compare columns of type "users_password_encryption_method". All fields are combined with logical 'AND'.
"""
input users_password_encryption_method_comparison_exp {
  _eq: users_password_encryption_method
  _gt: users_password_encryption_method
  _gte: users_password_encryption_method
  _in: [users_password_encryption_method!]
  _is_null: Boolean
  _lt: users_password_encryption_method
  _lte: users_password_encryption_method
  _neq: users_password_encryption_method
  _nin: [users_password_encryption_method!]
}

"""primary key columns input for table: users"""
input users_pk_columns_input {
  id: String!
}

"""prepend existing jsonb value of filtered columns with new jsonb value"""
input users_prepend_input {
  custom_data: jsonb
  identities: jsonb
  logto_config: jsonb
  mfa_verifications: jsonb
}

"""
columns and relationships of "users_roles"
"""
type users_roles {
  id: String!

  """An object relationship"""
  role: roles!
  role_id: String!
  tenant_id: String!
  user_id: String!
}

"""
aggregated selection of "users_roles"
"""
type users_roles_aggregate {
  aggregate: users_roles_aggregate_fields
  nodes: [users_roles!]!
}

input users_roles_aggregate_bool_exp {
  count: users_roles_aggregate_bool_exp_count
}

input users_roles_aggregate_bool_exp_count {
  arguments: [users_roles_select_column!]
  distinct: Boolean
  filter: users_roles_bool_exp
  predicate: Int_comparison_exp!
}

"""
aggregate fields of "users_roles"
"""
type users_roles_aggregate_fields {
  count(columns: [users_roles_select_column!], distinct: Boolean): Int!
  max: users_roles_max_fields
  min: users_roles_min_fields
}

"""
order by aggregate values of table "users_roles"
"""
input users_roles_aggregate_order_by {
  count: order_by
  max: users_roles_max_order_by
  min: users_roles_min_order_by
}

"""
input type for inserting array relation for remote table "users_roles"
"""
input users_roles_arr_rel_insert_input {
  data: [users_roles_insert_input!]!

  """upsert condition"""
  on_conflict: users_roles_on_conflict
}

"""
Boolean expression to filter rows from the table "users_roles". All fields are combined with a logical 'AND'.
"""
input users_roles_bool_exp {
  _and: [users_roles_bool_exp!]
  _not: users_roles_bool_exp
  _or: [users_roles_bool_exp!]
  id: String_comparison_exp
  role: roles_bool_exp
  role_id: String_comparison_exp
  tenant_id: String_comparison_exp
  user_id: String_comparison_exp
}

"""
unique or primary key constraints on table "users_roles"
"""
enum users_roles_constraint {
  """
  unique or primary key constraint on columns "role_id", "user_id", "tenant_id"
  """
  users_roles__user_id_role_id

  """
  unique or primary key constraint on columns "id"
  """
  users_roles_pkey
}

"""
input type for inserting data into table "users_roles"
"""
input users_roles_insert_input {
  id: String
  role: roles_obj_rel_insert_input
  role_id: String
  tenant_id: String
  user_id: String
}

"""aggregate max on columns"""
type users_roles_max_fields {
  id: String
  role_id: String
  tenant_id: String
  user_id: String
}

"""
order by max() on columns of table "users_roles"
"""
input users_roles_max_order_by {
  id: order_by
  role_id: order_by
  tenant_id: order_by
  user_id: order_by
}

"""aggregate min on columns"""
type users_roles_min_fields {
  id: String
  role_id: String
  tenant_id: String
  user_id: String
}

"""
order by min() on columns of table "users_roles"
"""
input users_roles_min_order_by {
  id: order_by
  role_id: order_by
  tenant_id: order_by
  user_id: order_by
}

"""
response of any mutation on the table "users_roles"
"""
type users_roles_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [users_roles!]!
}

"""
on_conflict condition type for table "users_roles"
"""
input users_roles_on_conflict {
  constraint: users_roles_constraint!
  update_columns: [users_roles_update_column!]! = []
  where: users_roles_bool_exp
}

"""Ordering options when selecting data from "users_roles"."""
input users_roles_order_by {
  id: order_by
  role: roles_order_by
  role_id: order_by
  tenant_id: order_by
  user_id: order_by
}

"""primary key columns input for table: users_roles"""
input users_roles_pk_columns_input {
  id: String!
}

"""
select columns of table "users_roles"
"""
enum users_roles_select_column {
  """column name"""
  id

  """column name"""
  role_id

  """column name"""
  tenant_id

  """column name"""
  user_id
}

"""
input type for updating data in table "users_roles"
"""
input users_roles_set_input {
  id: String
  role_id: String
  tenant_id: String
  user_id: String
}

"""
Streaming cursor of the table "users_roles"
"""
input users_roles_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: users_roles_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input users_roles_stream_cursor_value_input {
  id: String
  role_id: String
  tenant_id: String
  user_id: String
}

"""
update columns of table "users_roles"
"""
enum users_roles_update_column {
  """column name"""
  id

  """column name"""
  role_id

  """column name"""
  tenant_id

  """column name"""
  user_id
}

input users_roles_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: users_roles_set_input

  """filter the rows which have to be updated"""
  where: users_roles_bool_exp!
}

"""
select columns of table "users"
"""
enum users_select_column {
  """column name"""
  application_id

  """column name"""
  avatar

  """column name"""
  created_at

  """column name"""
  custom_data

  """column name"""
  id

  """column name"""
  identities

  """column name"""
  is_suspended

  """column name"""
  last_sign_in_at

  """column name"""
  logto_config

  """column name"""
  mfa_verifications

  """column name"""
  name

  """column name"""
  password_encrypted

  """column name"""
  password_encryption_method

  """column name"""
  primary_email

  """column name"""
  primary_phone

  """column name"""
  tenant_id

  """column name"""
  username
}

"""
input type for updating data in table "users"
"""
input users_set_input {
  application_id: String
  avatar: String
  created_at: timestamptz
  custom_data: jsonb
  id: String
  identities: jsonb
  is_suspended: Boolean
  last_sign_in_at: timestamptz
  logto_config: jsonb
  mfa_verifications: jsonb
  name: String
  password_encrypted: String
  password_encryption_method: users_password_encryption_method
  primary_email: String
  primary_phone: String
  tenant_id: String
  username: String
}

"""
Streaming cursor of the table "users"
"""
input users_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: users_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input users_stream_cursor_value_input {
  application_id: String
  avatar: String
  created_at: timestamptz
  custom_data: jsonb
  id: String
  identities: jsonb
  is_suspended: Boolean
  last_sign_in_at: timestamptz
  logto_config: jsonb
  mfa_verifications: jsonb
  name: String
  password_encrypted: String
  password_encryption_method: users_password_encryption_method
  primary_email: String
  primary_phone: String
  tenant_id: String
  username: String
}

"""
update columns of table "users"
"""
enum users_update_column {
  """column name"""
  application_id

  """column name"""
  avatar

  """column name"""
  created_at

  """column name"""
  custom_data

  """column name"""
  id

  """column name"""
  identities

  """column name"""
  is_suspended

  """column name"""
  last_sign_in_at

  """column name"""
  logto_config

  """column name"""
  mfa_verifications

  """column name"""
  name

  """column name"""
  password_encrypted

  """column name"""
  password_encryption_method

  """column name"""
  primary_email

  """column name"""
  primary_phone

  """column name"""
  tenant_id

  """column name"""
  username
}

input users_updates {
  """append existing jsonb value of filtered columns with new jsonb value"""
  _append: users_append_input

  """
  delete the field or element with specified path (for JSON arrays, negative integers count from the end)
  """
  _delete_at_path: users_delete_at_path_input

  """
  delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
  """
  _delete_elem: users_delete_elem_input

  """
  delete key/value pair or string element. key/value pairs are matched based on their key value
  """
  _delete_key: users_delete_key_input

  """prepend existing jsonb value of filtered columns with new jsonb value"""
  _prepend: users_prepend_input

  """sets the columns of the filtered rows to the given values"""
  _set: users_set_input

  """filter the rows which have to be updated"""
  where: users_bool_exp!
}

scalar uuid

"""
Boolean expression to compare columns of type "uuid". All fields are combined with logical 'AND'.
"""
input uuid_comparison_exp {
  _eq: uuid
  _gt: uuid
  _gte: uuid
  _in: [uuid!]
  _is_null: Boolean
  _lt: uuid
  _lte: uuid
  _neq: uuid
  _nin: [uuid!]
}

"""
columns and relationships of "verification_statuses"
"""
type verification_statuses {
  created_at: timestamptz!
  id: String!
  tenant_id: String!
  user_id: String!
}

"""
aggregated selection of "verification_statuses"
"""
type verification_statuses_aggregate {
  aggregate: verification_statuses_aggregate_fields
  nodes: [verification_statuses!]!
}

"""
aggregate fields of "verification_statuses"
"""
type verification_statuses_aggregate_fields {
  count(columns: [verification_statuses_select_column!], distinct: Boolean): Int!
  max: verification_statuses_max_fields
  min: verification_statuses_min_fields
}

"""
Boolean expression to filter rows from the table "verification_statuses". All fields are combined with a logical 'AND'.
"""
input verification_statuses_bool_exp {
  _and: [verification_statuses_bool_exp!]
  _not: verification_statuses_bool_exp
  _or: [verification_statuses_bool_exp!]
  created_at: timestamptz_comparison_exp
  id: String_comparison_exp
  tenant_id: String_comparison_exp
  user_id: String_comparison_exp
}

"""
unique or primary key constraints on table "verification_statuses"
"""
enum verification_statuses_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  verification_statuses_pkey
}

"""
input type for inserting data into table "verification_statuses"
"""
input verification_statuses_insert_input {
  created_at: timestamptz
  id: String
  tenant_id: String
  user_id: String
}

"""aggregate max on columns"""
type verification_statuses_max_fields {
  created_at: timestamptz
  id: String
  tenant_id: String
  user_id: String
}

"""aggregate min on columns"""
type verification_statuses_min_fields {
  created_at: timestamptz
  id: String
  tenant_id: String
  user_id: String
}

"""
response of any mutation on the table "verification_statuses"
"""
type verification_statuses_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [verification_statuses!]!
}

"""
on_conflict condition type for table "verification_statuses"
"""
input verification_statuses_on_conflict {
  constraint: verification_statuses_constraint!
  update_columns: [verification_statuses_update_column!]! = []
  where: verification_statuses_bool_exp
}

"""Ordering options when selecting data from "verification_statuses"."""
input verification_statuses_order_by {
  created_at: order_by
  id: order_by
  tenant_id: order_by
  user_id: order_by
}

"""primary key columns input for table: verification_statuses"""
input verification_statuses_pk_columns_input {
  id: String!
}

"""
select columns of table "verification_statuses"
"""
enum verification_statuses_select_column {
  """column name"""
  created_at

  """column name"""
  id

  """column name"""
  tenant_id

  """column name"""
  user_id
}

"""
input type for updating data in table "verification_statuses"
"""
input verification_statuses_set_input {
  created_at: timestamptz
  id: String
  tenant_id: String
  user_id: String
}

"""
Streaming cursor of the table "verification_statuses"
"""
input verification_statuses_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: verification_statuses_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input verification_statuses_stream_cursor_value_input {
  created_at: timestamptz
  id: String
  tenant_id: String
  user_id: String
}

"""
update columns of table "verification_statuses"
"""
enum verification_statuses_update_column {
  """column name"""
  created_at

  """column name"""
  id

  """column name"""
  tenant_id

  """column name"""
  user_id
}

input verification_statuses_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: verification_statuses_set_input

  """filter the rows which have to be updated"""
  where: verification_statuses_bool_exp!
}